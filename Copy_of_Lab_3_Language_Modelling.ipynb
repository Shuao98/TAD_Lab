{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "generative_ai_disabled": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shuao98/TAD_Lab/blob/main/Copy_of_Lab_3_Language_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1suGewMzIKsC"
      },
      "source": [
        "# Text as Data Lab 3: Language Modelling\n",
        "\n",
        "In this week's lab, we'll explore basic techniques for language modelling.\n",
        "\n",
        "The aims of this lab are:\n",
        "*   Model the probability of generating language\n",
        "*   Evaluating the quality of language model using perplexity\n",
        "*   Understand and address issues of sparsity in language modelling\n",
        "*   Learn applications of language models in understanding text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Before you start, save a copy of this lab to your drive using \"File > Save a Copy in Drive\".** If you skip this step, you may lose progress that you have made (e.g., if you close the browser tab or your computer crashes)."
      ],
      "metadata": {
        "id": "hzZNFlTLit6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Colab may hide some of this lab by collapsing a section. You'd see something that says \"X cells hidden\" (like below). Click on it to expand that section of the lab."
      ],
      "metadata": {
        "id": "eSGmYYvKhzYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "uwNJI8gYhzxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the labtest function\n",
        "\n",
        "As with previous labs, we'll use a `labtest` function so that you can check your code. You need to install and load it with the code below."
      ],
      "metadata": {
        "id": "aH_of5OsGuii"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-FNU1G7Qt_v7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed599ea4-c6da-4ff7-f70e-784458ce3370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/jakelever/glasgowcs_labtest.git\n",
            "  Cloning https://github.com/jakelever/glasgowcs_labtest.git to /tmp/pip-req-build-9h6y_omx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jakelever/glasgowcs_labtest.git /tmp/pip-req-build-9h6y_omx\n",
            "  Resolved https://github.com/jakelever/glasgowcs_labtest.git to commit 7edf2b5d4adcba4c416164429c51c91f8dcffca9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: glasgowcs_labtest\n",
            "  Building wheel for glasgowcs_labtest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glasgowcs_labtest: filename=glasgowcs_labtest-1.1.6-py3-none-any.whl size=29960 sha256=9fb09fe267807deb8798984d08e2d634019a9efea5df9814ac95537860301425\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7pazbht_/wheels/27/45/83/9c571c652f4aea38d0e7e699c80ea5b6ea0920af424b55b640\n",
            "Successfully built glasgowcs_labtest\n",
            "Installing collected packages: glasgowcs_labtest\n",
            "Successfully installed glasgowcs_labtest-1.1.6\n"
          ]
        }
      ],
      "source": [
        "# Installs the labtest system and loads the tests for this specific lab\n",
        "\n",
        "!pip install -U git+https://github.com/jakelever/glasgowcs_labtest.git\n",
        "from glasgowcs_labtest.textasdata.lab3 import labtest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "napJywoXLO7u"
      },
      "source": [
        "## Loading the Reddit data\n",
        "\n",
        "We'll be using the same Reddit data from the previous labs. We will download it and tokenize it with [spaCy](https://spacy.io/) for later use.\n",
        "\n",
        "**This time, we are going to tokenize it a little differently.**\n",
        "\n",
        "First, let's download it:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O reddit_posts.json https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EY_R8Y7DkrxMqXGe-zlgeNkBdJU5ZNTf8FYrN2pqDwddMA?download=1"
      ],
      "metadata": {
        "id": "Ax-gRXfWIcVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2982aa1b-4fc7-4d4a-cfd0-486410473535"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-03 11:16:50--  https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EY_R8Y7DkrxMqXGe-zlgeNkBdJU5ZNTf8FYrN2pqDwddMA?download=1\n",
            "Resolving gla-my.sharepoint.com (gla-my.sharepoint.com)... 13.107.136.10, 13.107.138.10, 2620:1ec:8f8::10, ...\n",
            "Connecting to gla-my.sharepoint.com (gla-my.sharepoint.com)|13.107.136.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/_layouts/15/download.aspx?UniqueId=8ef1d18f92c34cbca9719efb396078d9 [following]\n",
            "--2026-02-03 11:16:51--  https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/_layouts/15/download.aspx?UniqueId=8ef1d18f92c34cbca9719efb396078d9\n",
            "Reusing existing connection to gla-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1279064 (1.2M) [application/json]\n",
            "Saving to: ‘reddit_posts.json’\n",
            "\n",
            "reddit_posts.json   100%[===================>]   1.22M  1.45MB/s    in 0.8s    \n",
            "\n",
            "2026-02-03 11:16:52 (1.45 MB/s) - ‘reddit_posts.json’ saved [1279064/1279064]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load in the posts:"
      ],
      "metadata": {
        "id": "lziRq9bixzuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('reddit_posts.json') as f:\n",
        "    posts = json.load(f)\n",
        "\n",
        "len(posts)"
      ],
      "metadata": {
        "id": "fe7eLDpzImYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695a87e6-097e-4c3f-a7bd-987752d8d377"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A reminder of what a post looks like:"
      ],
      "metadata": {
        "id": "6rqH8dC6x050"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "posts[0]"
      ],
      "metadata": {
        "id": "I5zzUtTSgcqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff61e607-1428-4ba3-ebb3-8469878a1583"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'subreddit': 'Soda',\n",
              " 'title': 'Anyone tried Irn Bru?',\n",
              " 'score': 8,\n",
              " 'id': 'ou5yp1',\n",
              " 'author': 'jackibhoy',\n",
              " 'body': 'It’s a Scottish drink and it’s banned some countries and I was wondering if anyone here has tried it. It has quite a unique taste and it’s not something you’d forget quickly. You either love it or hate it I think.'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternative parsing\n",
        "\n",
        "We're going to do a few things differently this time.\n",
        "\n",
        "1. We're going to use a slimmed down version of spaCy. This is to show that you can turn off bits of spaCy and make it **a lot** faster.\n",
        "2. We're going to keep stopwords this time\n",
        "3. We're not going to lemmatize, but we will still use the lowercase version of the token text\n",
        "\n",
        "We want to split the text into its tokens and not do anything special to them.\n",
        "\n",
        "Let's load in a slimmed down version of spaCy with a few things (e.g. tagger, parser, NER) turned off."
      ],
      "metadata": {
        "id": "RDEaWotax3Ju"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB1SEq_B1jYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a9311f-dd73-4216-e2f9-cdb9c9f189f1"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Load the small english model.\n",
        "# Disable the advanced NLP features in the pipeline for efficiency.\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
        "nlp.remove_pipe('tagger')\n",
        "nlp.remove_pipe('parser')\n",
        "nlp.remove_pipe('lemmatizer')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x79f6af26b510>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we'll define a modified version of the spaCy pipeline function from previous labs that doesn't throw away stopwords and gives the original text, not lemmas."
      ],
      "metadata": {
        "id": "D2LT0Y8nyeWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_pipeline_spacy_special(text):\n",
        "  tokens = []\n",
        "  doc = nlp(text)\n",
        "  for t in doc:\n",
        "    if not t.is_punct and not t.is_space: # what we removed: \"not t.is_stop and\"\n",
        "      tokens.append(t.text.lower()) # what we changed: t.text instead of t.lemma_\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "pbv8yE5LyeeV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now if we tokenize everything, it is much faster."
      ],
      "metadata": {
        "id": "jAV7cr_qywdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm # This provides a nice progress bar\n",
        "\n",
        "for post in tqdm(posts):\n",
        "    post['tokens'] = text_pipeline_spacy_special(post['title'] + '\\n' + post['body'])"
      ],
      "metadata": {
        "id": "Kl4nh7eKfe9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794657b2-6322-45dc-839a-74404673c86b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [00:17<00:00, 113.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flattening the tokens\n",
        "\n",
        "For this lab, we want to deal with the whole collection of posts as a single long list of tokens. We'll make one list and combine each post with a special token `<START>` at the beginning of each."
      ],
      "metadata": {
        "id": "qFse93LXy8DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "posts_flattened_tokens = []\n",
        "for post in posts:\n",
        "  posts_flattened_tokens += ['<START>'] + post['tokens']\n",
        "len(posts_flattened_tokens)"
      ],
      "metadata": {
        "id": "ivXZChNE0M3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8380771c-61e7-415e-e092-83fef704e9cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189428"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's quite a few tokens!"
      ],
      "metadata": {
        "id": "tQsFNGH2zSH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And again, we'll make a little mini corpus of sentences and create the same flattened list of tokens with the `<START>` special token before each sentence. This will be useful for a few places later."
      ],
      "metadata": {
        "id": "smF8x1ODzNcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mini_sentences = [\n",
        "    \"My favourite soft drink is Apple Tango, but I also love Irn Bru.\",\n",
        "    \"Irn Bru is a great drink.\",\n",
        "    \"I once found a can of Irn Bru in St Petersburg.\",\n",
        "    \"Irn Bru is a soft drink launched in 1901 by AG Barr.\",\n",
        "    \"IRN-BRU is made at AG Barr in Cumbernauld.\"\n",
        "]\n",
        "\n",
        "mini_flattened = []\n",
        "for x in mini_sentences:\n",
        "  mini_flattened += ['<START>'] + text_pipeline_spacy_special(x)\n",
        "\n",
        "print(mini_flattened)"
      ],
      "metadata": {
        "id": "kGXrr37Ohw3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46032ad3-6eaa-42e1-c99a-b564359ce9a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<START>', 'my', 'favourite', 'soft', 'drink', 'is', 'apple', 'tango', 'but', 'i', 'also', 'love', 'irn', 'bru', '<START>', 'irn', 'bru', 'is', 'a', 'great', 'drink', '<START>', 'i', 'once', 'found', 'a', 'can', 'of', 'irn', 'bru', 'in', 'st', 'petersburg', '<START>', 'irn', 'bru', 'is', 'a', 'soft', 'drink', 'launched', 'in', '1901', 'by', 'ag', 'barr', '<START>', 'irn', 'bru', 'is', 'made', 'at', 'ag', 'barr', 'in', 'cumbernauld']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78XpfWSHF9n6"
      },
      "source": [
        "## Unigram language model\n",
        "\n",
        "We're going to start with a unigram language model. This will provide the probability of each token occurring and has lots of uses.\n",
        "\n",
        "Recall that a unigram model treats each token independently and does not take any context (i.e. the previous tokens) into account.\n",
        "\n",
        "Before we calculate the unigram probabilities, we need to calculate the unigram counts. We'll use the [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) class again."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "posts_unigram_counts = Counter(posts_flattened_tokens)\n",
        "posts_unigram_N = len(posts_flattened_tokens) # also the same as sum(posts_unigram_counts.values())"
      ],
      "metadata": {
        "id": "Qno5picKWLy7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get the number of times that 'irn' appears in our posts:"
      ],
      "metadata": {
        "id": "KKdgmVnp01hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "posts_unigram_counts['irn']"
      ],
      "metadata": {
        "id": "UcyYMK5M05kJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ddd507-c004-44f0-b5dd-5c7cff0fb9da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now time to calculate unigram probabilities:\n",
        "\n",
        "**Exercise:** Write a function `unigram_token_prob` that given a token, the unigram counts and the total number of unigrams, returns the probability of that token\n"
      ],
      "metadata": {
        "id": "tf5-Ct4l1EOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unigram_token_prob(next_token, unigram_counts, unigram_N):\n",
        "   if unigram_counts[next_token] == 0:\n",
        "    return 0\n",
        "   return unigram_counts[next_token]/unigram_N\n",
        "\n",
        "  # your code!\n",
        "\n",
        "unigram_token_prob('irn', posts_unigram_counts, posts_unigram_N)"
      ],
      "metadata": {
        "id": "gcg8jO3gg0qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9523fe50-6ba0-4df6-e210-7d5477bbf778"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.279050615537302e-05"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that your function returns a probability of zero for a new unseen token."
      ],
      "metadata": {
        "id": "0nh7ZUQN1mBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_token_prob('totallynotatoken', posts_unigram_counts, posts_unigram_N)"
      ],
      "metadata": {
        "id": "UEUWJjvS1lQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f378a0c2-aba1-4a02-e9f0-6ba2cdd5f37c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now you can run the labtest function:"
      ],
      "metadata": {
        "id": "HwsD6NUi1xMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(unigram_token_prob)"
      ],
      "metadata": {
        "id": "Lr7FBJFI1DdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7333a8c4-5dc1-4c20-a7e0-c33bcab538db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('cup', {'cup': 2, 'spoon': 2, 'glass': 6, 'fork': 1}, 11). Running... \n",
            "Output: 0.18182\n",
            "OK.\n",
            "\n",
            "Input: ('plate', {'plate': 2, 'cup': 2, 'fork': 5, 'spoon': 5}, 14). Running... \n",
            "Output: 0.14286\n",
            "OK.\n",
            "\n",
            "Input: ('fork', {'bowl': 4, 'fork': 5, 'plate': 3, 'cup': 1}, 13). Running... \n",
            "Output: 0.38462\n",
            "OK.\n",
            "\n",
            "Input: ('cup', {'plate': 2, 'glass': 3, 'fork': 1, 'cup': 1}, 7). Running... \n",
            "Output: 0.14286\n",
            "OK.\n",
            "\n",
            "Input: ('glass', {'glass': 5, 'spoon': 3}, 8). Running... \n",
            "Output: 0.625\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use the individual token probabilities to calculate the probability of a whole sequence. Remember that the unigram probability of a sequence treats each token independently:\n",
        "\n",
        "$$ P(w_1, ... w_N) = \\prod_{i=1}^N \\hat{p}(w_i) $$\n",
        "\n",
        "**Exercise:** Write a function `unigram_sequence_prob` that given a sequence of tokens (and the unigram data), calculates the probability of the sequence.\n",
        "\n",
        "Remember that if a sequence contains a token that doesn't exist in the corpus, the probability of the sequence should be zero."
      ],
      "metadata": {
        "id": "lQFdSOO01-Co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unigram_sequence_prob(sequence, unigram_counts, unigram_N):\n",
        "  # your code!\n",
        "  prob=1\n",
        "  for x in sequence:\n",
        "    prob*=unigram_token_prob(x, unigram_counts,unigram_N)\n",
        "  return prob\n",
        "\n",
        "unigram_sequence_prob(['i', 'like', 'irn', 'bru'], posts_unigram_counts, posts_unigram_N)"
      ],
      "metadata": {
        "id": "7lUuyQjMWl7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b4a8f3c-bd42-46ff-f1e7-d6772f5c60ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.810905251121602e-13"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(unigram_sequence_prob)"
      ],
      "metadata": {
        "id": "6UfEUYoC3ObO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90be8767-4f4d-4dea-f2a1-8eac6763be47"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: (['glass', 'glass', 'glass', 'cup', 'cup'], {'cup': 2, 'spoon': 2, 'glass': 6, 'fork': 1}, 11). Running... \n",
            "Output: 0.00536\n",
            "OK.\n",
            "\n",
            "Input: (['spoon', 'spoon', 'fork'], {'fork': 1, 'spoon': 5}, 6). Running... \n",
            "Output: 0.11574\n",
            "OK.\n",
            "\n",
            "Input: (['fork', 'fork', 'cup', 'fork'], {'fork': 2, 'glass': 6, 'cup': 4}, 12). Running... \n",
            "Output: 0.00154\n",
            "OK.\n",
            "\n",
            "Input: (['glass', 'cup', 'fork', 'cup', 'cup'], {'cup': 5, 'glass': 3, 'fork': 1}, 9). Running... \n",
            "Output: 0.00635\n",
            "OK.\n",
            "\n",
            "Input: (['spoon', 'spoon', 'spoon', 'glass'], {'fork': 1, 'glass': 1, 'bowl': 6, 'spoon': 2}, 10). Running... \n",
            "Output: 0.0008\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For long sequences, we start multiplying by very small numbers. This is a very bad idea computationally. Computers only have a limited number of bits for a number and precision problems start happening when multiplying by lots of small numbers.\n",
        "\n",
        "A better idea is to do everything with logarithms. We'll work with log base 2 here. The above equation becomes:\n",
        "\n",
        "$$ LogP(w_1, ... w_N) = \\sum_{i=1}^N \\log_2 \\hat{p}(w_i) $$\n",
        "\n",
        "**Exercise:** Write a function `unigram_sequence_logprob` which is equivalent to the `unigram_sequence_prob` method but using log2 and summation as in the equation above."
      ],
      "metadata": {
        "id": "ubeEHwkk2yUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def unigram_sequence_logprob(sequence, unigram_counts, unigram_N):\n",
        "  # your code!\n",
        "  prob=0\n",
        "  for x in sequence:\n",
        "    prob+=math.log2(unigram_token_prob(x, unigram_counts,unigram_N))\n",
        "  return prob\n",
        "\n",
        "unigram_sequence_logprob(['i', 'like', 'irn', 'bru'], posts_unigram_counts, posts_unigram_N)"
      ],
      "metadata": {
        "id": "IY3hnAVYXbc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac3505b-5fa1-4be2-c452-8439ca45d551"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-40.64630230233775"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can sanity check that it's working by taking the log2 of the original function and seeing if we get the same result."
      ],
      "metadata": {
        "id": "_Vuv6YAN4FEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "math.log2(unigram_sequence_prob(['i', 'like', 'irn', 'bru'], posts_unigram_counts, posts_unigram_N))"
      ],
      "metadata": {
        "id": "7DXv003LXlvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e3fda3-2c14-4c43-d877-f61cde452a2f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-40.64630230233775"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(unigram_sequence_logprob)"
      ],
      "metadata": {
        "id": "0Nt2z8XZ4DSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f9a86b-5e8b-48c7-fdf2-e15801c6f35f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: (['glass', 'glass', 'glass', 'cup', 'cup'], {'cup': 2, 'spoon': 2, 'glass': 6, 'fork': 1}, 11). Running... \n",
            "Output: -7.54227\n",
            "OK.\n",
            "\n",
            "Input: (['spoon', 'spoon', 'fork'], {'fork': 1, 'spoon': 5}, 6). Running... \n",
            "Output: -3.11103\n",
            "OK.\n",
            "\n",
            "Input: (['fork', 'fork', 'cup', 'fork'], {'fork': 2, 'glass': 6, 'cup': 4}, 12). Running... \n",
            "Output: -9.33985\n",
            "OK.\n",
            "\n",
            "Input: (['glass', 'cup', 'fork', 'cup', 'cup'], {'cup': 5, 'glass': 3, 'fork': 1}, 9). Running... \n",
            "Output: -7.29888\n",
            "OK.\n",
            "\n",
            "Input: (['spoon', 'spoon', 'spoon', 'glass'], {'fork': 1, 'glass': 1, 'bowl': 6, 'spoon': 2}, 10). Running... \n",
            "Output: -10.28771\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ1mMO8jxD7W"
      },
      "source": [
        "Let's try computing the unigram probabilities of a few tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoRWLmmCwa4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca9c0bd-d899-4b8a-940e-6ffc8c4aba33"
      },
      "source": [
        "for token in ['the','game','defenenstrate']:\n",
        "  print(\"Pr(\",token,\"):\", unigram_token_prob(token, posts_unigram_counts, posts_unigram_N))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr( the ): 0.0327195557151002\n",
            "Pr( game ): 0.0038114745444179318\n",
            "Pr( defenenstrate ): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM6aSVrnzCOX"
      },
      "source": [
        "The probabilities should be about 3% for 'the', 0.4% for 'game' and 0 for 'defenestrate'.\n",
        "\n",
        "Now, try computing the probability of a sequence of tokens.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHIVlXHrxb9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab588a00-98ff-46bc-e3e7-67c4d14aea3e"
      },
      "source": [
        "probability = unigram_sequence_prob([\"the\", \"end\", \"of\", \"the\", \"world\", \"as\", \"we\", \"know\", \"it\"], posts_unigram_counts, posts_unigram_N)\n",
        "print('{:.40f}'.format(probability))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0000000000000000000010693914958728715991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFnlo0cSzsLP"
      },
      "source": [
        "This is already a very small number and most of the values in these sequence are large by typical probability values. This is the reason that we usually do the probability computation in log space in practice to avoid problems of underflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5igWwh7t5uLx"
      },
      "source": [
        "## Application: Spelling correction\n",
        "\n",
        "We can use this simple language model to build a spelling corrector.\n",
        "\n",
        "This builds on ideas of a [spelling corrector from code by Peter Norvig](http://norvig.com/spell-correct.html), a director of research at Google."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The objective\n",
        "\n",
        "For a given misspelled token, we want to find candidate tokens that it could be assuming that the real token is only a few edits away. With those candidate tokens, we will then calculate the most likely with our language model.\n"
      ],
      "metadata": {
        "id": "U20bFiEg5JxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Edit distance\n",
        "\n",
        "\n",
        "What do we mean by edits? Perhaps, we transposed two letters, accidentally added a letter, or deleted a letter, etc.\n",
        "\n",
        "We need a function that can generate a list of tokens that are a single edit away. For example 'go' is one edit away from 'lo'.\n",
        "\n",
        "Here is the `generate_edits1` function."
      ],
      "metadata": {
        "id": "QT49Ugk45zE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_edits1(token):\n",
        "  \"All edits that are one edit away from `token`.\"\n",
        "  letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "  splits     = [(token[:i], token[i:])  for i in range(len(token) + 1)]\n",
        "  deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "  transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "  replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "  inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "  return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "print(generate_edits1('irn'))"
      ],
      "metadata": {
        "id": "5VNdTveBY8Bn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08be2ed0-f8fd-4fd7-c247-c8a22029aa2c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'irn', 'isrn', 'ikrn', 'iro', 'ivn', 'yirn', 'idrn', 'inrn', 'iron', 'irv', 'irni', 'irnw', 'iun', 'iwrn', 'iwn', 'ird', 'irnj', 'inr', 'rin', 'iru', 'icrn', 'yrn', 'irnu', 'irnt', 'irin', 'zrn', 'birn', 'airn', 'irr', 'sirn', 'irkn', 'qirn', 'irno', 'irt', 'iren', 'hirn', 'ien', 'pirn', 'iri', 'ira', 'iirn', 'iln', 'girn', 'ijrn', 'imrn', 'irnz', 'irnc', 'iarn', 'mrn', 'eirn', 'rn', 'irnx', 'brn', 'irk', 'irpn', 'iry', 'drn', 'cirn', 'irnn', 'irng', 'irdn', 'lrn', 'iprn', 'trn', 'ian', 'ihrn', 'kirn', 'oirn', 'rirn', 'ion', 'ixn', 'idn', 'arn', 'irb', 'qrn', 'ihn', 'irna', 'irbn', 'iurn', 'mirn', 'irnl', 'crn', 'virn', 'irtn', 'in', 'iin', 'wirn', 'iyrn', 'isn', 'iqn', 'irsn', 'iern', 'ifrn', 'irvn', 'irnf', 'hrn', 'wrn', 'ipn', 'irh', 'iyn', 'krn', 'orn', 'iorn', 'irnr', 'frn', 'irnv', 'ifn', 'inn', 'xrn', 'irne', 'ire', 'irs', 'irmn', 'irwn', 'irl', 'ir', 'jrn', 'itn', 'igrn', 'iran', 'itrn', 'iryn', 'irln', 'irnb', 'ivrn', 'irgn', 'ircn', 'irw', 'irm', 'tirn', 'irp', 'ikn', 'irg', 'jirn', 'nirn', 'irnq', 'irc', 'lirn', 'irnp', 'irx', 'zirn', 'irf', 'irxn', 'irny', 'ilrn', 'irns', 'ibrn', 'urn', 'iqrn', 'rrn', 'nrn', 'irq', 'irj', 'irnd', 'ixrn', 'vrn', 'irun', 'xirn', 'ibn', 'ijn', 'irzn', 'grn', 'irz', 'icn', 'prn', 'dirn', 'irnk', 'srn', 'irjn', 'izrn', 'izn', 'ign', 'irhn', 'irnh', 'irrn', 'irnm', 'imn', 'uirn', 'firn', 'irfn', 'irqn', 'ern'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we may want to get tokens that are two edits away."
      ],
      "metadata": {
        "id": "ldsGqStOMMdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_edits2(token):\n",
        "  \"All edits that are two edits away from `token`.\"\n",
        "  return set(e2 for e1 in generate_edits1(token) for e2 in generate_edits1(e1))\n",
        "\n",
        "print(generate_edits2('irn'))"
      ],
      "metadata": {
        "id": "bJylYYJoZI1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d19c281-2443-49b9-bc24-c0151fa7617f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nron', 'sirr', 'iedn', 'iprxn', 'imrno', 'irnpz', 'iqrl', 'olirn', 'pirnc', 'rrnq', 'viun', 'ivrnq', 'inrx', 'mikn', 'sirnk', 'iarqn', 'ivrcn', 'grsn', 'xwn', 'irrqn', 'ornj', 'iuwn', 'ioni', 'fir', 'iyry', 'dgrn', 'iuun', 'qire', 'irrnn', 'ikrkn', 'irbon', 'tiren', 'irnjw', 'prnj', 'viprn', 'ijdn', 'isrkn', 'itkrn', 'uikrn', 'lisrn', 'ijxn', 'ircx', 'rni', 'kirb', 'iryyn', 'ivnk', 'irhrn', 'yirxn', 'irnjd', 'oirs', 'invn', 'icq', 'ibln', 'iror', 'frtn', 'ironc', 'inrna', 'rinb', 'mirno', 'drnn', 'mwrn', 'ivru', 'iqk', 'bdirn', 'pdn', 'prnz', 'wrnt', 'ro', 'irlj', 'idcn', 'riran', 'nirx', 'irxzn', 'pirny', 'kirmn', 'inzr', 'hrnc', 'iranq', 'mrirn', 'irwno', 'pirvn', 'irgrn', 'prxn', 'xrpn', 'ingrn', 'itrhn', 'lirun', 'iprr', 'tirnc', 'ioru', 'isrnz', 'ila', 'ircm', 'ierin', 'ifv', 'ibrj', 'irnij', 'icqn', 'ilrtn', 'tirln', 'irykn', 'irndl', 'irnnr', 'idrz', 'ivlrn', 'tkrn', 'shrn', 'ivrns', 'eivn', 'iknb', 'erzn', 'tikn', 'irnbx', 'qrirn', 'vnn', 'lirnd', 'ihnx', 'iurmn', 'irern', 'irnpg', 'nrqn', 'irys', 'iwno', 'iqnk', 'zrnh', 'dinn', 'irndb', 'iervn', 'irbng', 'ifrmn', 'iirdn', 'ircna', 'irnxe', 'lrr', 'wzrn', 'irsno', 'cvn', 'mtrn', 'uisn', 'iparn', 'ivrx', 'cidrn', 'ikrs', 'istn', 'irint', 'jrnu', 'ironk', 'iym', 'yirm', 'idrnq', 'imrmn', 'itm', 'irmmn', 'irnta', 'iirnx', 'trb', 'fhirn', 'srgn', 'grvn', 'birvn', 'irly', 'eiwrn', 'igrjn', 'yir', 'run', 'pinr', 'iudrn', 'ikri', 'ixrr', 'rigrn', 'arni', 'ziran', 'iyrnl', 'okn', 'drkn', 'irkm', 'irnd', 'liurn', 'tirnx', 'trm', 'iarsn', 'qrj', 'hdirn', 'ivrnj', 'irsnk', 'gri', 'siro', 'rgrn', 'hqn', 'dirnj', 'irpnn', 'oijn', 'ero', 'irlnh', 'yrw', 'linn', 'irxg', 'iramn', 'cijrn', 'irdnl', 'irfo', 'igu', 'ermn', 'irnjr', 'irnln', 'risrn', 'mire', 'tran', 'igin', 'idrnc', 'irvne', 'ifnrn', 'sifn', 'krno', 'qon', 'worn', 'dtrn', 'wicn', 'ihcrn', 'urnx', 'prgn', 'civrn', 'mrnt', 'xrhn', 'lird', 'iorln', 'xrne', 'imbrn', 'iprni', 'irin', 'irnww', 'jnn', 'pirqn', 'ykn', 'idrnb', 'virtn', 'irnvh', 'cirt', 'ikren', 'inni', 'igfn', 'imm', 'iyirn', 'iqrnp', 'iryln', 'ioern', 'fiorn', 'niirn', 'ernb', 'opn', 'sirfn', 'itns', 'sjn', 'ivf', 'inan', 'irmng', 'mirun', 'ifrp', 'wirni', 'evrn', 'itrh', 'vrnp', 'rirv', 'eirbn', 'irpgn', 'upirn', 'nrnr', 'yirj', 'tyirn', 'mrnr', 'kirjn', 'ikrb', 'irnyu', 'irupn', 'amn', 'lrnq', 'imvn', 'irnxi', 'iraw', 'ircne', 'lairn', 'irnsy', 'zrns', 'irld', 'irnat', 'irrh', 'iigrn', 'irrc', 'ers', 'xirnv', 'trin', 'iglrn', 'ixrnq', 'irrna', 'wgrn', 'idjn', 'yrnh', 'jrnw', 'iyrg', 'geirn', 'imrns', 'jsn', 'ifnq', 'fn', 'ibrv', 'iufn', 'ijurn', 'irkyn', 'dirdn', 'ignh', 'mrnk', 'ichrn', 'ibcn', 'eoirn', 'ilvrn', 'zkrn', 'virni', 'ipno', 'ihrrn', 'irfjn', 'irncs', 'innn', 'hra', 'irnwg', 'zrnz', 'irnxy', 'ilnl', 'isn', 'izk', 'whirn', 'url', 'imrnc', 'rnh', 'ivtn', 'ibnl', 'yixn', 'irqy', 'irvan', 'yqrn', 'idrmn', 'tiorn', 'hirt', 'iairn', 'iqnrn', 'irnhe', 'irxen', 'irtnf', 'ijxrn', 'irhi', 'aibn', 'mitn', 'icru', 'rrnz', 'ripn', 'ijns', 'jvn', 'ity', 'arnn', 'lrs', 'iirfn', 'gitrn', 'iebrn', 'kifrn', 'irhmn', 'irxnd', 'dirz', 'irp', 'iko', 'imrnd', 'idrg', 'airp', 'ixrny', 'oirx', 'igrm', 'iyurn', 'ihna', 'hrnt', 'rirf', 'ireq', 'aivn', 'irnqc', 'hiyrn', 'ddirn', 'ijrhn', 'innk', 'irnjp', 'ikfrn', 'irnwp', 'qiqn', 'zirun', 'yirf', 'ptn', 'srv', 'riri', 'iw', 'irdy', 'yrg', 'iwirn', 'iein', 'cirna', 'rirgn', 'irgtn', 'oprn', 'crcn', 'isrvn', 'idin', 'icrln', 'img', 'irocn', 'irfb', 'fran', 'hwrn', 'erni', 'ubn', 'irvgn', 'iruo', 'jicrn', 'yrnl', 'kqn', 'irsdn', 'iynrn', 'iprfn', 'wirj', 'prbn', 'ierg', 'ijhn', 'izrjn', 'bwrn', 'pirnh', 'ikxrn', 'iegrn', 'fjn', 'airnw', 'irmnr', 'oirh', 'yivrn', 'syirn', 'iprg', 'pirln', 'exn', 'irqsn', 'ibmn', 'iakn', 'firns', 'irfnt', 'iat', 'lprn', 'rircn', 'ibrnb', 'jrtn', 'ionh', 'ijne', 'jitrn', 'birnw', 'izurn', 'irnst', 'lrzn', 'iprnb', 'hgn', 'ijsrn', 'qirc', 'cuirn', 'ids', 'ibrgn', 'zirl', 'iarg', 'wiin', 'vicrn', 'firzn', 'airn', 'ifb', 'ibrh', 'ikrj', 'irnup', 'isrm', 'qbrn', 'imgn', 'iem', 'grnw', 'iscrn', 'iryfn', 'ivrf', 'irnut', 'joirn', 'ionc', 'lirny', 'iwnl', 'rirpn', 'ieon', 'urrn', 'irhnw', 'lrnh', 'jrpn', 'iurf', 'hrnf', 'imrtn', 'ibrkn', 'hirnf', 'wiri', 'viry', 'irsnr', 'uitrn', 'znn', 'virp', 'sxrn', 'ibrl', 'yqn', 'irzzn', 'xirw', 'qri', 'vircn', 'hiern', 'ijran', 'inrin', 'xun', 'pirkn', 'aiwn', 'kkn', 'imrz', 'vr', 'viln', 'iep', 'irnmj', 'crin', 'iorz', 'vjrn', 'yirna', 'irpnz', 'crf', 'ian', 'aon', 'miwn', 'qira', 'frcn', 'xgn', 'irhny', 'iur', 'iarmn', 'oirnf', 'irtnc', 'iekn', 'imrnn', 'irpi', 'irban', 'irnuj', 'icrdn', 'ioa', 'giyrn', 'irnbn', 'ifo', 'iarnl', 'zirnu', 'zrcn', 'imrb', 'ipern', 'ions', 'srkn', 'ircnq', 'firp', 'ivm', 'birnt', 'hrnu', 'ivrd', 'imnr', 'irnsa', 'ienx', 'tun', 'qsirn', 'qirv', 'irpns', 'iqrsn', 'krnj', 'yrpn', 'btn', 'imirn', 'irtsn', 'yrnc', 'srnm', 'irnmg', 'firnd', 'inrmn', 'iino', 'uxrn', 'irs', 'iarxn', 'siin', 'uxn', 'iirgn', 'ilrj', 'yrvn', 'xixn', 'jrnm', 'izrt', 'imdn', 'ren', 'nwn', 'minrn', 'izirn', 'vion', 'iuran', 'iwqn', 'pilrn', 'ianh', 'crxn', 'iddrn', 'irnvf', 'irnhf', 'isy', 'vrns', 'xrgn', 'ictrn', 'icng', 'yrng', 'lrno', 'iprm', 'igyrn', 'ifrnx', 'rinq', 'icryn', 'isrx', 'yan', 'gibrn', 'qvirn', 'ibj', 'ifc', 'crtn', 'jln', 'eirh', 'tern', 'hhirn', 'cre', 'hyrn', 'trnn', 'rirln', 'ius', 'udn', 'yiran', 'irfen', 'krc', 'irnia', 'liron', 'qra', 'drnq', 'jipn', 'irnba', 'isrz', 'irgne', 'iizn', 'bicrn', 'eifn', 'itdrn', 'irpq', 'ciron', 'iuwrn', 'pprn', 'lidrn', 'iari', 'irznx', 'irnhj', 'iznn', 'irutn', 'ikyrn', 'ecn', 'ihmn', 'dirn', 'mrvn', 'iprs', 'ifng', 'iprpn', 'irnkv', 'fgirn', 'lisn', 'vrne', 'irqpn', 'eircn', 'irmna', 'iprnm', 'irnky', 'irnwl', 'iwnh', 'isd', 'hirwn', 'frnc', 'firnw', 'iqr', 'crfn', 'ikrna', 'irhr', 'oirhn', 'iftrn', 'ionp', 'irjnh', 'uirf', 'itrnj', 'girjn', 'qrs', 'rrnb', 'iaqrn', 'icny', 'ircnc', 'brvn', 'iptn', 'iby', 'irnpp', 'itnl', 'ixrq', 'zrpn', 'iz', 'hirsn', 'orfn', 'firfn', 'zrkn', 'irfvn', 'iqnw', 'crna', 'iuna', 'irnzw', 'boirn', 'irnya', 'gen', 'ihrnr', 'irjt', 'txrn', 'wrnr', 'ivrun', 'inar', 'iuin', 'ifrb', 'ixrsn', 'iwrne', 'rne', 'irya', 'drnb', 'lhn', 'ijrnd', 'ibrun', 'birun', 'irmpn', 'irfz', 'rrjn', 'eiry', 'iux', 'civn', 'iernw', 'inxn', 'srg', 'irlnv', 'irfa', 'iorfn', 'ircnu', 'irunr', 'irwm', 'ikirn', 'irfhn', 'aimn', 'iadrn', 'swirn', 'irfsn', 'irhqn', 'gkirn', 'ornl', 'yrl', 'irnsg', 'mrne', 'iff', 'iah', 'xrf', 'irlin', 'izrl', 'pirfn', 'sihrn', 'igryn', 'ibbn', 'prwn', 'rir', 'piry', 'itnz', 'irij', 'irnxj', 'ibrmn', 'kdrn', 'burn', 'iunn', 'rrc', 'nrr', 'ixrc', 'ilrhn', 'irgan', 'idrh', 'yirnv', 'awrn', 'izrv', 'iqryn', 'jirln', 'icen', 'qkrn', 'irehn', 'icrnv', 'igry', 'ilyn', 'ifu', 'xrr', 'gron', 'izrnd', 'iernd', 'rmn', 'ixp', 'crnm', 'irnvy', 'yrtn', 'irbz', 'irnmq', 'irqxn', 'grin', 'irfnv', 'nkn', 'ikcn', 'uron', 'irorn', 'irzl', 'irge', 'irjln', 'iton', 'irep', 'imqn', 'irqcn', 'titrn', 'ixne', 'siqrn', 'ierzn', 'qrna', 'tikrn', 'kimn', 'timn', 'ebn', 'erb', 'irmen', 'iinz', 'rvin', 'sixrn', 'ilz', 'irnvo', 'icm', 'snrn', 'lgirn', 'wixrn', 'yern', 'mun', 'zifn', 'ozirn', 'crsn', 'firs', 'nnirn', 'arw', 'irnju', 'rgn', 'irpl', 'vign', 'gprn', 'icrnw', 'irfnr', 'ilnh', 'tirn', 'dinr', 'icrx', 'iqron', 'ntn', 'icrw', 'trq', 'ibre', 'iuurn', 'ittn', 'irddn', 'crwn', 'guirn', 'virvn', 'irpon', 'wsrn', 'idd', 'airnu', 'uiwrn', 'irnsv', 'han', 'birf', 'iara', 'iynr', 'ehirn', 'ignrn', 'ikra', 'xn', 'hrni', 'ijrnr', 'ijan', 'ixnrn', 'iak', 'iab', 'imrni', 'irvq', 'irnyt', 'ic', 'zrnd', 'nfrn', 'irrnb', 'irsi', 'frv', 'irhd', 'irxnt', 'ixs', 'iurnf', 'irnuw', 'sikrn', 'iphrn', 'ibtn', 'oirl', 'fnn', 'fikn', 'ieprn', 'rhirn', 'irbcn', 'irsq', 'nrni', 'ipin', 'vrt', 'lrln', 'gsirn', 'tiro', 'eirjn', 'sirnl', 'grln', 'irrj', 'isnh', 'irwd', 'itrv', 'ilr', 'ipgn', 'nirln', 'irnqx', 'hivn', 'xizn', 'dpn', 'icrn', 'aihrn', 'cirhn', 'kitn', 'dlrn', 'hiren', 'pnr', 'firln', 'icnf', 'brnb', 'virnq', 'ckirn', 'ifqrn', 'xiorn', 'nrnt', 'ifrfn', 'icrbn', 'wien', 'irci', 'irqg', 'iroyn', 'irle', 'idrnx', 'nrt', 'yirw', 'ircnz', 'xbrn', 'arnk', 'ziorn', 'zinn', 'lrnl', 'ziwn', 'ime', 'inq', 'itrbn', 'rijn', 'irnfj', 'liry', 'iapn', 'wirnn', 'irnz', 'sxn', 'irjm', 'grc', 'ilrns', 'irnaz', 'qmirn', 'prnw', 'irnim', 'zry', 'fizrn', 'eirqn', 'irsin', 'imk', 'sirnn', 'jrkn', 'ianq', 'iflrn', 'mnn', 'inrh', 'iskrn', 'irnib', 'jirnu', 'egirn', 'xxrn', 'ikg', 'ixon', 'eitrn', 'irdjn', 'iarnu', 'ssirn', 'yircn', 'inrnw', 'ilru', 'izern', 'oirn', 'rny', 'rirn', 'kibn', 'lrfn', 'irnof', 'dsrn', 'iamn', 'irwnq', 'irnkb', 'wpirn', 'trno', 'yiurn', 'brk', 'irnog', 'fxirn', 'irynj', 'hizrn', 'iruc', 'eirne', 'dirne', 'isrr', 'srnx', 'irzni', 'brno', 'dyirn', 'eirnx', 'prv', 'irqnw', 'miqrn', 'irnf', 'ixr', 'vivn', 'jgn', 'iritn', 'iihrn', 'iprc', 'icnk', 'imcrn', 'xihrn', 'irnds', 'idmrn', 'tirnw', 'irknt', 'irdnt', 'jrno', 'iong', 'len', 'irnhv', 'irnpl', 'qirnh', 'xrn', 'rnj', 'imrnq', 'minn', 'iryvn', 'eirnu', 'birx', 'zhn', 'sryn', 'ciqn', 'iqnm', 'iroa', 'niro', 'ibnp', 'oqrn', 'igri', 'iryn', 'iyq', 'irza', 'ikrk', 'iwro', 'yrnb', 'imrnx', 'lrbn', 'nrirn', 'irwns', 'iprl', 'irqa', 'irtns', 'isna', 'pipn', 'iqrx', 'ilrnx', 'itrnc', 'esirn', 'ivri', 'imbn', 'kiwrn', 'irnrb', 'ihrpn', 'mirb', 'aiyn', 'nian', 'bhirn', 'fqn', 'frs', 'icx', 'iqen', 'dirnf', 'irxno', 'ornk', 'iwnr', 'iarnz', 'igrz', 'biurn', 'grnm', 'cizrn', 'viqrn', 'iprcn', 'irysn', 'irnhg', 'ipm', 'itnt', 'mran', 'arnj', 'isln', 'mnirn', 'iaru', 'frzn', 'invrn', 'irda', 'irnbk', 'irmt', 'inj', 'iinu', 'iih', 'irtfn', 'ihrqn', 'irml', 'irniy', 'zun', 'jkn', 'irvc', 'ikrni', 'irur', 'cron', 'fdirn', 'pirsn', 'xirrn', 'ziri', 'ipzn', 'irmp', 'nrzn', 'khn', 'pran', 'iufrn', 'vru', 'irdnu', 'irxt', 'iuz', 'fbn', 'icnh', 'ibnx', 'ipro', 'rien', 'oivn', 'irnhz', 'ipkrn', 'yirr', 'ifwn', 'lwn', 'irikn', 'licrn', 'iwnd', 'iirun', 'moirn', 'irhna', 'xre', 'rini', 'ird', 'iyns', 'ikrtn', 'ircxn', 'pirnb', 'ibc', 'irpnv', 'tmrn', 'cfn', 'qirnc', 'inh', 'icrnp', 'mrni', 'jiwn', 'wirng', 'irxvn', 'cian', 'irjr', 'qpirn', 'zrnq', 'xirt', 'crp', 'hrin', 'iamrn', 'yirbn', 'iqnq', 'tiyn', 'erf', 'ircnm', 'airf', 'liun', 'irtny', 'iqarn', 'xirnh', 'crzn', 'irmw', 'imnk', 'zrnf', 'hirnr', 'iqlrn', 'brp', 'tiwrn', 'qirvn', 'crx', 'irnqb', 'eirnt', 'iornm', 'irpz', 'ivrdn', 'yien', 'qhn', 'iarnp', 'ilrr', 'ilrnm', 'niern', 'irnqy', 'ircng', 'ixz', 'qirnj', 'iben', 'isrcn', 'ijrnv', 'irnld', 'ispn', 'irnrn', 'dirnb', 'qrk', 'niqn', 'irnhw', 'brf', 'fivn', 'irben', 'ijh', 'crni', 'ivrnx', 'iwrgn', 'iqrnh', 'ivbn', 'irnap', 'hirj', 'iorhn', 'irans', 'ikrjn', 'irnon', 'irltn', 'diron', 'ihw', 'tirnf', 'firj', 'irnhq', 'ibg', 'irjx', 'xrwn', 'dirqn', 'nrnq', 'giqrn', 'rnw', 'irrtn', 'virjn', 'inrbn', 'hirpn', 'ifn', 'qn', 'hrnp', 'irnuh', 'itun', 'iqsn', 'irzf', 'zimn', 'mizn', 'irnwk', 'irxnv', 'iryw', 'itan', 'rrdn', 'iqrnc', 'prnt', 'ikrr', 'qirhn', 'asn', 'mfn', 'irnhs', 'itrnr', 'qiun', 'qirg', 'ifnv', 'kan', 'ilrp', 'icrrn', 'lilrn', 'mkrn', 'ernz', 'jrr', 'irnmt', 'iaorn', 'bxirn', 'cirpn', 'ilrkn', 'igrnm', 'icrb', 'vizn', 'icp', 'iyrnd', 'vfn', 'imnx', 'aijrn', 'irunh', 'gyn', 'zikn', 'ldrn', 'lrnu', 'efirn', 'ibrng', 'xiyrn', 'irnfh', 'igc', 'qnrn', 'pvn', 'xkn', 'tirns', 'iorc', 'irlnx', 'kjn', 'usn', 'aro', 'siyn', 'irjnk', 'izin', 'xirl', 'igro', 'anr', 'nrnu', 'irez', 'rrsn', 'ciren', 'dprn', 'ieurn', 'xifrn', 'firq', 'irdq', 'wixn', 'nrsn', 'ypirn', 'qorn', 'hxn', 'iir', 'yyirn', 'itvn', 'wihrn', 'hirjn', 'iea', 'izrna', 'iurh', 'ifl', 'firg', 'yira', 'irzm', 'mimn', 'ntirn', 'lijn', 'wurn', 'wirxn', 'ore', 'ihkn', 'irnj', 'dirk', 'irnjg', 'drnu', 'irsnw', 'iorj', 'ircdn', 'inns', 'iornf', 'iqxn', 'jiwrn', 'bwn', 'prq', 'imy', 'idnh', 'eirhn', 'fiyrn', 'ircu', 'brny', 'ixrvn', 'ugn', 'wrp', 'iryns', 'crnd', 'irgp', 'irjqn', 'qikn', 'iirnv', 'crnl', 'iqrno', 'idrv', 'ggrn', 'iotn', 'wnrn', 'ifrkn', 'crdn', 'nuirn', 'iwon', 'hjirn', 'rn', 'pirrn', 'gcirn', 'iene', 'rk', 'krnc', 'hrgn', 'eru', 'figrn', 'ikfn', 'inno', 'irnrc', 'itni', 'ireh', 'iwr', 'yirns', 'brz', 'igrd', 'irznj', 'gidrn', 'iiun', 'irnny', 'irnlr', 'biun', 'frnh', 'osrn', 'virns', 'girw', 'nitn', 'wra', 'ikrns', 'iqnf', 'bri', 'isern', 'lrx', 'crn', 'mrnu', 'urna', 'tirg', 'horn', 'icl', 'eirnv', 'irpu', 'irina', 'dirnh', 'iirxn', 'iji', 'jirun', 'irknu', 'irdon', 'icrcn', 'rifn', 'hrhn', 'irrb', 'uimrn', 'zbrn', 'ioron', 'irnui', 'ifnw', 'hinr', 'simn', 'pern', 'msrn', 'eirw', 'irtvn', 'gdrn', 'ijcn', 'ifry', 'siron', 'irand', 'irzun', 'girg', 'iltn', 'irmn', 'zirnt', 'wrnx', 'irii', 'idk', 'irdu', 'orno', 'ipdrn', 'iqt', 'grnv', 'idgrn', 'sdn', 'ziru', 'inhrn', 'irnsp', 'irndx', 'irntw', 'idrnt', 'irnfd', 'ivrna', 'girnp', 'imrpn', 'bifrn', 'ircni', 'oirnx', 'ijgrn', 'mixrn', 'irwgn', 'iwnj', 'irqzn', 'irnzn', 'isnv', 'ircun', 'qrng', 'iqqrn', 'mgrn', 'pimn', 'irzns', 'uirni', 'pfrn', 'idm', 'irjf', 'giorn', 'brg', 'ikrln', 'ivnrn', 'lsirn', 'iprng', 'krd', 'icnx', 'dwrn', 'iyrx', 'qrxn', 'lrqn', 'irot', 'sidn', 'irnrz', 'girh', 'irnkj', 'irnnz', 'lirpn', 'iuk', 'ivg', 'imi', 'xri', 'iwrhn', 'hrng', 'isrh', 'irbq', 'irxsn', 'gisrn', 'fyirn', 'zen', 'ilv', 'imng', 'vrgn', 'ioorn', 'icnr', 'qre', 'irjnz', 'irynw', 'ipo', 'ixrkn', 'irnjq', 'qhrn', 'qihrn', 'ikin', 'wirnz', 'ufn', 'firxn', 'iyxn', 'iqln', 'irjq', 'irnlg', 'hirfn', 'irncj', 'jifrn', 'sln', 'irrny', 'irnwq', 'iryi', 'irzyn', 'pwirn', 'jrhn', 'iow', 'zzirn', 'fiwn', 'irijn', 'wrnc', 'virnd', 'irve', 'ifz', 'jrni', 'xirbn', 'ibon', 'giarn', 'kri', 'irfg', 'mirzn', 'irnfq', 'inpr', 'piwrn', 'izsrn', 'irncv', 'irkn', 'qlrn', 'rirt', 'dibn', 'grny', 'eirsn', 'ivrj', 'birnc', 'iroz', 'irra', 'cikn', 'yon', 'einrn', 'ignv', 'qrno', 'ibxrn', 'irpzn', 'iukrn', 'icprn', 'ifurn', 'trnk', 'isrnv', 'iwrnc', 'irnc', 'prw', 'ihun', 'srny', 'xjn', 'irbb', 'irpd', 'itln', 'surn', 'ifrnh', 'irncq', 'kirx', 'iorq', 'irap', 'mri', 'irog', 'yirnc', 'irdl', 'virnu', 'vrnz', 'iyrw', 'iwrnm', 'ciran', 'ibgrn', 'irtin', 'xirnp', 'zrnb', 'jdirn', 'etrn', 'ilrl', 'urdn', 'ivj', 'irnyp', 'irnlj', 'ayrn', 'ikan', 'ijrqn', 'isrng', 'rint', 'aidrn', 'irnvb', 'ijhrn', 'irnig', 'iare', 'oiyrn', 'iorwn', 'ifre', 'jirh', 'ianu', 'sircn', 'sirdn', 'orh', 'zirsn', 'tire', 'iwh', 'ixrx', 'irnzo', 'hirnn', 'airna', 'irnlf', 'nirbn', 'irnrq', 'frjn', 'irbno', 'ifrg', 'fkrn', 'imnv', 'trne', 'iztrn', 'icnl', 'riru', 'isnp', 'ixrnx', 'ixrpn', 'zhrn', 'fitn', 'jirw', 'illrn', 'isri', 'isrtn', 'idrs', 'iumn', 'irnre', 'ciern', 'sirna', 'lirt', 'axrn', 'cirnc', 'infrn', 'ifro', 'ilnk', 'qidrn', 'ihqn', 'irpen', 'hrnv', 'iirnf', 'ifnt', 'qiri', 'hikn', 'irfun', 'yron', 'iccrn', 'gvn', 'irjin', 'idbn', 'iorm', 'qirnw', 'itxn', 'wrnd', 'cirh', 'giry', 'irdb', 'eirnf', 'irrz', 'irqdn', 'ernw', 'sirb', 'dien', 'hrkn', 'ivwrn', 'dircn', 'irngc', 'zpirn', 'ianrn', 'pirp', 'brnp', 'iann', 'yirnp', 'ixln', 'hirnl', 'irfn', 'irndu', 'idarn', 'irjne', 'hrnk', 'ihrnn', 'lidn', 'cren', 'ernt', 'ixg', 'ugrn', 'oirc', 'piren', 'poirn', 'irpkn', 'nfn', 'cirnq', 'xrzn', 'irunk', 'irnal', 'idkn', 'zbirn', 'trk', 'iram', 'irnhk', 'irnvj', 'mirg', 'isrhn', 'idro', 'urnw', 'isrnu', 'iqin', 'sitn', 'crz', 'riny', 'girmn', 'erno', 'fiarn', 'ilrnq', 'isa', 'oeirn', 'qrnf', 'erx', 'wzn', 'irkk', 'grtn', 'ivnb', 'iirnm', 'mrgn', 'jirnr', 'imrw', 'ircon', 'nihrn', 'ifrni', 'xitrn', 'qsrn', 'trnz', 'diarn', 'irnmf', 'ignq', 'ifrl', 'isrjn', 'idpn', 'irzfn', 'birsn', 'irbbn', 'iqnn', 'ierrn', 'sre', 'mirny', 'ijwrn', 'ioqrn', 'yirzn', 'irnum', 'mrm', 'wrln', 'irto', 'tiln', 'krni', 'irri', 'jlirn', 'xirnd', 'rf', 'irkgn', 'fzrn', 'iwrr', 'crqn', 'xibn', 'diry', 'iwrin', 'tirnv', 'itrnk', 'xiran', 'ikrdn', 'frmn', 'jarn', 'arnb', 'irkmn', 'irjgn', 'iwnf', 'ruirn', 'irjkn', 'xvirn', 'yrr', 'ernc', 'bon', 'mirn', 'girns', 'ixmn', 'nirnp', 'grni', 'nsirn', 'irbu', 'mrrn', 'zurn', 'imnf', 'irmgn', 'firk', 'vrmn', 'jixn', 'idnx', 'ibna', 'cir', 'ilrnt', 'sir', 'irtrn', 'lkrn', 'irxnh', 'kirt', 'atrn', 'dre', 'ifrns', 'itnv', 'irhz', 'wrw', 'irnrk', 'ice', 'irqm', 'ehrn', 'dkn', 'srnn', 'rinj', 'lhrn', 'inrnj', 'irbnb', 'iirp', 'onr', 'iunm', 'izrh', 'vkn', 'iyyrn', 'itnb', 'irhne', 'ijnk', 'giin', 'drj', 'iohn', 'orb', 'iurqn', 'irnbe', 'irmnq', 'ilrx', 'argn', 'irznq', 'irqun', 'prtn', 'ijrnn', 'ijin', 'brln', 'viwn', 'irbg', 'wirne', 'ifnu', 'giro', 'irxnf', 'mirnv', 'irniq', 'iwnz', 'ihf', 'snn', 'iqni', 'hdn', 'grmn', 'iknr', 'idnw', 'irnur', 'miirn', 'gpn', 'irdne', 'arny', 'irbt', 'vrm', 'ilrnr', 'eimn', 'iprbn', 'bijn', 'isdrn', 'irinu', 'irhq', 'isu', 'yimrn', 'ircnd', 'irnsd', 'iqd', 'dran', 'irft', 'drun', 'yirnh', 'iwra', 'ieyn', 'iban', 'iyon', 'ynirn', 'lbn', 'irnbl', 'irnwo', 'hijn', 'sri', 'icrun', 'drhn', 'qrq', 'krnn', 'ihnrn', 'jqirn', 'ihnr', 'nxirn', 'rtrn', 'uern', 'jirnz', 'kizn', 'mirx', 'thrn', 'chirn', 'riwrn', 'irnsl', 'irinj', 'kiyrn', 'irnuk', 'iyrmn', 'nrk', 'iww', 'ixrne', 'irn', 'oiwrn', 'irpdn', 'qprn', 'tidrn', 'iumrn', 'idqn', 'ilrwn', 'ridn', 'nizn', 'pirv', 'kipn', 'irnzd', 'dihn', 'nilrn', 'ernv', 'ierjn', 'ibro', 'inrj', 'eisn', 'ilpn', 'krmn', 'kiry', 'irmnx', 'ivrk', 'irynh', 'rrv', 'ilbn', 'qiirn', 'irynt', 'arnd', 'nirnv', 'iqu', 'irpnj', 'izd', 'frpn', 'brni', 'irzw', 'urnk', 'uirk', 'hiryn', 'ikon', 'hcirn', 'ira', 'irvr', 'itnm', 'isrnq', 'ive', 'uiorn', 'irms', 'iyp', 'irpw', 'ircwn', 'cinrn', 'nrnc', 'wirna', 'ilgn', 'iocn', 'irwwn', 'iksrn', 'whn', 'ifrnv', 'itz', 'iorno', 'irnxr', 'irpln', 'irqwn', 'irod', 'mrnd', 'irznd', 'trbn', 'smn', 'xirnt', 'ainn', 'irend', 'iqh', 'ixra', 'grk', 'mirs', 'ikq', 'qirxn', 'imsn', 'iyhn', 'icnz', 'zirna', 'jmirn', 'prf', 'izln', 'mrun', 'ivhrn', 'oirwn', 'ivxn', 'won', 'qrsn', 'xirnu', 'irnad', 'ihron', 'tifn', 'ortn', 'wsn', 'iaw', 'idns', 'trvn', 'irnhr', 'lnirn', 'irkf', 'ioxn', 'ciro', 'nirsn', 'iiq', 'iwfrn', 'arn', 'kien', 'ijrln', 'rnk', 'ircjn', 'irfx', 'diin', 'ienz', 'warn', 'kirm', 'wirq', 'iqrg', 'bpirn', 'ixbn', 'srwn', 'icns', 'qitrn', 'tirin', 'rdn', 'xhrn', 'iahrn', 'irinf', 'qrnk', 'hsn', 'ogirn', 'irkt', 'irntg', 'drb', 'iurnn', 'xinrn', 'irnnb', 'ihbn', 'ilrh', 'qun', 'gbrn', 'liern', 'ijrk', 'jigrn', 'mrno', 'ihrl', 'irens', 'icrjn', 'srnl', 'ijjrn', 'irynr', 'igzrn', 'uirnl', 'izdn', 'rbin', 'ifh', 'irnow', 'irnhm', 'ilnp', 'prx', 'uirdn', 'hsrn', 'giryn', 'irch', 'hirng', 'piprn', 'ercn', 'vrjn', 'pirnn', 'ncirn', 'iekrn', 'xcn', 'nrj', 'oirb', 'irgwn', 'iqi', 'irbnm', 'irxl', 'bivn', 'irvp', 'iruwn', 'itirn', 'urnh', 'xirs', 'srzn', 'bsrn', 'rjirn', 'uirnw', 'kirnw', 'irnbg', 'ieng', 'imyrn', 'egn', 'irjsn', 'izmn', 'pr', 'miprn', 'prfn', 'ikpn', 'xrnw', 'izrnv', 'urt', 'ibsrn', 'iona', 'uirnf', 'igrsn', 'cisn', 'zmirn', 'brqn', 'nikrn', 'iridn', 'ifi', 'ill', 'fln', 'nirtn', 'wern', 'krq', 'aikrn', 'sirnv', 'uryn', 'irnde', 'irent', 'irz', 'irxw', 'iggn', 'ein', 'iryna', 'ifrz', 'nirxn', 'iac', 'ijrnm', 'adrn', 'ibo', 'iotrn', 'psn', 'zrfn', 'grdn', 'igrwn', 'irbs', 'iyrnx', 'imp', 'onn', 'irnso', 'xirnz', 'pan', 'iunf', 'snirn', 'xhn', 'irdni', 'irlnl', 'viarn', 'vrnf', 'iwjn', 'liqn', 'wrnf', 'liro', 'irnqw', 'irlng', 'mibrn', 'icrng', 'iruk', 'yrna', 'isrnt', 'krt', 'inorn', 'ipren', 'firun', 'ziron', 'rmirn', 'itrnn', 'zirfn', 'ijlrn', 'iibrn', 'iernv', 'airdn', 'icjn', 'iqc', 'vzirn', 'irih', 'iqrwn', 'hiun', 'irlnb', 'rirp', 'ocn', 'irnyh', 'bitn', 'rlrn', 'visrn', 'rirtn', 'idyn', 'iwsrn', 'imrn', 'ura', 'irbny', 'idv', 'wvirn', 'itcn', 'jrdn', 'winr', 'igrne', 'ixnu', 'orun', 'jrg', 'ibdrn', 'irnit', 'wpn', 'firo', 'irkd', 'isrnm', 'viin', 'ioin', 'dwirn', 'lryn', 'wirnl', 'nirv', 'ijrnx', 'otirn', 'rno', 'irncx', 'irhnf', 'djirn', 'ilrk', 'inrnh', 'iarkn', 'irwb', 'ibfrn', 'biqn', 'vsn', 'yirnm', 'iwrvn', 'ironb', 'irrnp', 'sirrn', 'rim', 'irpnp', 'wizrn', 'ymn', 'iree', 'iryp', 'sirgn', 'ijb', 'irdnv', 'irnfa', 'yrq', 'airns', 'jiqn', 'yurn', 'gipn', 'uirs', 'kirnq', 'srrn', 'irmnz', 'irjnc', 'rinr', 'ikprn', 'jrne', 'ivrnd', 'zirno', 'gurn', 'jibrn', 'ivnd', 'ikbn', 'iwkrn', 'siren', 'irnlt', 'ibrzn', 'xicn', 'pqirn', 'iknp', 'brq', 'irngx', 'iprjn', 'ilrf', 'ekirn', 'irnom', 'prirn', 'iuen', 'rpirn', 'iycrn', 'grnz', 'nzn', 'xrq', 'mrmn', 'orsn', 'irnfi', 'oirnp', 'airi', 'rrna', 'virj', 'irznt', 'idnrn', 'irxd', 'icbn', 'ifdn', 'irhu', 'ierno', 'irrt', 'ilun', 'irsnp', 'qirzn', 'irxr', 'ijrgn', 'ilrn', 'skrn', 'irren', 'iexn', 'irndm', 'irnvi', 'wrkn', 'hibn', 'isrrn', 'icdn', 'imrun', 'birnu', 'rxrn', 'uir', 'ijv', 'irnwa', 'rnp', 'ikcrn', 'yry', 'imen', 'rfirn', 'jpn', 'airtn', 'ijrnj', 'iynw', 'hzirn', 'eln', 'iprnh', 'pird', 'ied', 'ewirn', 'icrnh', 'ireno', 'jqn', 'wian', 'irnlm', 'cbn', 'wrj', 'ihvn', 'ienb', 'imv', 'irotn', 'iwrnf', 'itrnu', 'iqno', 'finr', 'irubn', 'iek', 'ihnj', 'iranh', 'drdn', 'iiv', 'irrk', 'cirtn', 'ipbrn', 'irsjn', 'imrf', 'iryd', 'birnp', 'irnag', 'iix', 'idrin', 'kitrn', 'cirni', 'irfr', 'iqcrn', 'iyren', 'urv', 'ilwrn', 'ilsn', 'birzn', 'irncy', 'iury', 'prnc', 'irgnx', 'uirzn', 'kiwn', 'irmo', 'yrm', 'zzrn', 'bir', 'jrx', 'ixe', 'forn', 'ixun', 'trl', 'eyirn', 'irpmn', 'lirh', 'ilran', 'aiern', 'eidrn', 'liyn', 'higrn', 'viru', 'irevn', 'wkirn', 'rirnx', 'iyrnn', 'irnht', 'arr', 'grnu', 'iert', 'vinn', 'irmtn', 'irwtn', 'irvjn', 'dizn', 'ixvn', 'irjh', 'uirb', 'mirnm', 'irnrv', 'iyrb', 'iprin', 'ikrnx', 'igwn', 'phirn', 'iyrnp', 'qifrn', 'irune', 'iiry', 'izb', 'ienl', 'urm', 'iprnd', 'mdirn', 'ivkn', 'irnie', 'oru', 'jron', 'grng', 'zron', 'iwrzn', 'riyrn', 'idrni', 'eixn', 'izrln', 'irunc', 'jiyrn', 'mcn', 'anirn', 'keirn', 'igwrn', 'uitn', 'eirl', 'ikrc', 'biryn', 'inrny', 'irznu', 'irnzt', 'irndi', 'qvrn', 'njn', 'igsn', 'yirx', 'ciyrn', 'irnte', 'oiri', 'brnj', 'ibrcn', 'lcirn', 'yirnn', 'iirnt', 'qiyrn', 'oirnz', 'oirnc', 'iorxn', 'irhin', 'wirnh', 'irjrn', 'drnr', 'eicrn', 'igrnv', 'iqrz', 'dsn', 'milrn', 'iks', 'cirx', 'sn', 'qrkn', 'irdqn', 'ielrn', 'ircmn', 'irnnx', 'irecn', 'irnbd', 'icnb', 'irpin', 'arvn', 'ryn', 'iiarn', 'ignl', 'ernr', 'ihrln', 'tihn', 'rivn', 'ivrkn', 'iunr', 'oipn', 'elirn', 'dbrn', 'bkn', 'pryn', 'pnn', 'erd', 'ilqn', 'ipe', 'irnvd', 'ipnn', 'wcrn', 'irnby', 'virrn', 'iprt', 'oairn', 'vinrn', 'iruno', 'niru', 'hibrn', 'eirnl', 'bln', 'vron', 'ria', 'iknk', 'girnv', 'irow', 'aairn', 'sidrn', 'ycn', 'zvrn', 'yrbn', 'drna', 'sirnc', 'yxirn', 'irnhi', 'irlb', 'invr', 'hjrn', 'ijna', 'ikm', 'ivi', 'diru', 'krr', 'cri', 'iurnz', 'ihtrn', 'iirh', 'irjd', 'ihren', 'iyrnq', 'itin', 'irpe', 'isnm', 'irxh', 'iwk', 'crm', 'ikrnn', 'bvn', 'irgl', 'pidn', 'igrp', 'prn', 'biru', 'iarng', 'imrqn', 'iosrn', 'jrln', 'uirrn', 'irqn', 'nirna', 'ierv', 'iirnn', 'izarn', 'yirg', 'mrkn', 'hri', 'irlne', 'ivn', 'iznt', 'irtu', 'xiren', 'jirs', 'srtn', 'firdn', 'iranr', 'irum', 'trnd', 'irfne', 'irhsn', 'imrln', 'irpvn', 'ixx', 'imo', 'iwrdn', 'esn', 'ianj', 'cqrn', 'ibnd', 'iena', 'qtn', 'vsrn', 'irai', 'ornh', 'tiran', 'trhn', 'ifrwn', 'isprn', 'apn', 'inz', 'ivon', 'niarn', 'iswrn', 'qrnl', 'srsn', 'jidn', 'ivarn', 'ipk', 'igdrn', 'inrzn', 'eryn', 'ahn', 'iwrwn', 'iprmn', 'irhfn', 'mir', 'irumn', 'irry', 'irpnr', 'kirny', 'iruzn', 'irndj', 'iqra', 'izq', 'biarn', 'iprnz', 'hirni', 'irjj', 'iph', 'yrsn', 'iruw', 'wrcn', 'zgn', 'iqyn', 'birr', 'mrcn', 'igron', 'ivsn', 'frm', 'irzc', 'drny', 'iffrn', 'zern', 'jiurn', 'zrgn', 'irmny', 'ixrg', 'sfrn', 'ixj', 'ven', 'ijrjn', 'sgirn', 'isi', 'ijra', 'ilprn', 'irtr', 'fixn', 'irwy', 'irdin', 'iordn', 'pirw', 'irnev', 'drjn', 'iue', 'ilen', 'vifrn', 'srj', 'inryn', 'birln', 'irpy', 'injn', 'imj', 'jrny', 'inrm', 'iircn', 'prb', 'giun', 'ifrno', 'vivrn', 'oirmn', 'oiirn', 'iynb', 'lirln', 'nirr', 'gitn', 'ivrtn', 'icrt', 'tian', 'sirun', 'xzrn', 'frq', 'grb', 'rvrn', 'trnx', 'irnjn', 'itryn', 'riarn', 'bikn', 'irsp', 'irnbv', 'irnjt', 'idna', 'iroh', 'wirnm', 'srxn', 'siprn', 'irbnx', 'ijtn', 'izcrn', 'irnjf', 'urnq', 'picn', 'wvn', 'pira', 'ikbrn', 'yirvn', 'igrcn', 'ninr', 'tvirn', 'ifru', 'siurn', 'jwn', 'icrno', 'hiirn', 'gmirn', 'ilrna', 'irkg', 'ifnj', 'eirnb', 'jisn', 'ith', 'iersn', 'itrun', 'irny', 'iurnc', 'jirgn', 'irxs', 'irnmk', 'id', 'izkn', 'irfnm', 'iprnv', 'bgrn', 'trnw', 'rsrn', 'feirn', 'rfin', 'icrhn', 'ldn', 'irhw', 'mirpn', 'irptn', 'ikern', 'iczrn', 'ikrnj', 'ipz', 'ido', 'irnkg', 'ionf', 'uirj', 'inrw', 'mrbn', 'irwnl', 'isg', 'irnni', 'hihrn', 'ljn', 'yyn', 'jirt', 'ibni', 'uirtn', 'lirr', 'rion', 'idhrn', 'iung', 'sorn', 'aizrn', 'irtx', 'iyy', 'wiran', 'firh', 'kpn', 'virnk', 'eprn', 'hoirn', 'frnf', 'mirnb', 'irnzy', 'izrno', 'hrnh', 'imrny', 'ivrxn', 'ihra', 'ife', 'ircen', 'irncf', 'izrq', 'iadn', 'irxnp', 'iraxn', 'irkj', 'ivna', 'eirnh', 'zipn', 'lirrn', 'irvnz', 'olrn', 'bcn', 'sirs', 'irhp', 'ironi', 'jrfn', 'niryn', 'eirmn', 'lihn', 'yirs', 'kxrn', 'ifarn', 'bbrn', 'kign', 'itwrn', 'itrni', 'izrnt', 'oun', 'ireen', 'irsa', 'ivno', 'ipvrn', 'ipun', 'irckn', 'ibnq', 'iirl', 'nkirn', 'kmn', 'qrgn', 'airan', 'qirgn', 'ilrgn', 'yzrn', 'irnpm', 'isrnr', 'ifa', 'ilm', 'nirk', 'airsn', 'innt', 'viren', 'psirn', 'jrnj', 'iurm', 'tyrn', 'inprn', 'airnn', 'gqirn', 'ihrzn', 'itgn', 'irnwn', 'ial', 'irnvg', 'irnyx', 'pmirn', 'iqurn', 'ibrrn', 'ioirn', 'ivnf', 'irnri', 'ione', 'zcrn', 'irfl', 'riun', 'ion', 'iyc', 'mfirn', 'hiwrn', 'birin', 'irryn', 'irnhd', 'irxln', 'iidrn', 'irntk', 'ejirn', 'iruyn', 'oirnb', 'iorf', 'yilrn', 'irnda', 'airnh', 'pikn', 'kikn', 'iwnn', 'giren', 'irtd', 'unr', 'arnw', 'irnjb', 'irenz', 'airnc', 'ijrg', 'izi', 'izan', 'ihbrn', 'rrnk', 'ivren', 'kirs', 'ixrnj', 'firt', 'jivn', 'ilan', 'oiln', 'ifran', 'xrnv', 'irnvc', 'tnrn', 'nrln', 'irrnm', 'iirtn', 'zirt', 'irzxn', 'ijrz', 'afirn', 'ccn', 'vir', 'qrne', 'iqran', 'lifrn', 'irl', 'ixnh', 'bwirn', 'wirnx', 'birny', 'icrin', 'xrb', 'rwn', 'rirr', 'jrns', 'jrbn', 'ixm', 'iuqrn', 'itrne', 'hitn', 'itrnl', 'irfd', 'irizn', 'dro', 'iwnk', 'izng', 'qirns', 'zan', 'irpnt', 'jnr', 'nirc', 'irnoe', 'xirnf', 'ilrfn', 'lrdn', 'ifzrn', 'ismrn', 'rirnv', 'iriy', 'grnr', 'cwrn', 'tirxn', 'arzn', 'igh', 'rln', 'imrnw', 'crnj', 'lon', 'iuhrn', 'eizrn', 'iwryn', 'irou', 'irlw', 'iqrgn', 'mxn', 'kuirn', 'irsu', 'irunt', 'mirnz', 'nrjn', 'girnn', 'nirgn', 'ornu', 'ark', 'iky', 'zqrn', 'bkirn', 'fisrn', 'icxn', 'jro', 'igv', 'tro', 'kirnn', 'rh', 'igrnq', 'ixrl', 'izrn', 'iwrnp', 'uivn', 'qiwrn', 'zion', 'qisrn', 'sgrn', 'aitrn', 'irua', 'ignp', 'nrf', 'irdnw', 'xizrn', 'gire', 'irwk', 'ivrl', 'vidn', 'iryin', 'pkirn', 'zsirn', 'ilrun', 'iqng', 'cirnb', 'irtv', 'yirpn', 'iori', 'ibren', 'izrbn', 'kirsn', 'wibrn', 'rx', 'iurdn', 'icro', 'ipns', 'irgbn', 'iynt', 'irnzj', 'anrn', 'ziarn', 'cigrn', 'iriln', 'yrn', 'jrnc', 'ilrrn', 'xirnk', 'kizrn', 'idrw', 'iwrjn', 'nixn', 'ibrny', 'ihin', 'ikxn', 'digrn', 'rgirn', 'ihrmn', 'girp', 'idrns', 'irsnl', 'irwnf', 'clirn', 'wirt', 'xrsn', 'qirkn', 'iurin', 'xirh', 'wuirn', 'fra', 'iyrwn', 'ninrn', 'izrf', 'hifrn', 'mirns', 'pirmn', 'lircn', 'idfn', 'irdnk', 'zicrn', 'irbdn', 'ork', 'orx', 'lirnb', 'iqa', 'arg', 'irszn', 'dkrn', 'iuq', 'ertn', 'ik', 'iqrk', 'xirnl', 'ziqn', 'idrnn', 'vern', 'irnfe', 'irbnn', 'hrnq', 'nirj', 'irts', 'virnh', 'cyn', 'ximrn', 'iiirn', 'firnp', 'ziro', 'giqn', 'mrnb', 'drnx', 'ban', 'iarfn', 'kiran', 'noirn', 'igon', 'lrny', 'irzne', 'irovn', 'qcirn', 'hixrn', 'xrmn', 'urnf', 'itrmn', 'iiny', 'jrmn', 'inro', 'ios', 'dirns', 'irma', 'tirwn', 'imnh', 'irnir', 'iyrrn', 'ipan', 'niin', 'spn', 'tirv', 'irkne', 'irvn', 'irnkl', 'irntp', 'girrn', 'irlo', 'iexrn', 'ivny', 'iewn', 'jcrn', 'ii', 'irhh', 'irwnr', 'iwxrn', 'irix', 'irnec', 'idx', 'irnmb', 'bien', 'iyrna', 'zrj', 'tiru', 'piarn', 'ircs', 'suirn', 'innrn', 'ipre', 'itrin', 'ibrfn', 'win', 'ijprn', 'rzin', 'irznb', 'lirkn', 'imkn', 'nirm', 'ivnw', 'are', 'irm', 'arb', 'xrng', 'zjirn', 'oren', 'nimn', 'ifrcn', 'irmnu', 'irngs', 'irnak', 'sirng', 'igrkn', 'imrnz', 'xirhn', 'irtm', 'irrkn', 'jgrn', 'ra', 'girnq', 'duirn', 'zrz', 'ipxn', 'rirj', 'ernu', 'iunp', 'disn', 'ipri', 'wkn', 'ixnf', 'iant', 'fwirn', 'nirpn', 'eirnr', 'ikno', 'ijx', 'unrn', 'irskn', 'irndk', 'jbrn', 'irmj', 'iernu', 'iinc', 'qcn', 'jtrn', 'yiro', 'xtirn', 'ibvn', 'qitn', 'ixi', 'lrnb', 'llrn', 'pirnd', 'yrnu', 'sicrn', 'oiorn', 'ixrnz', 'viron', 'imdrn', 'irrnc', 'ijnz', 'iisn', 'eien', 'nryn', 'ica', 'lirna', 'oirin', 'xirng', 'mrh', 'irndt', 'ioqn', 'iia', 'izrs', 'ivrrn', 'izpn', 'irnsb', 'grrn', 'irnaj', 'bipn', 'ifrdn', 'ixrwn', 'iprno', 'ilnj', 'irnnn', 'virwn', 'ierz', 'irfqn', 'iryq', 'yirnj', 'bsirn', 'ornx', 'grnt', 'ocrn', 'ihrnd', 'rrkn', 'imwrn', 'icd', 'irnpv', 'ifen', 'ciun', 'igrx', 'zihn', 'lqrn', 'xvn', 'yrnn', 'erbn', 'upn', 'ornv', 'iifn', 'ilj', 'ijrv', 'stn', 'prmn', 'rre', 'ornc', 'zirnd', 'iprkn', 'diqrn', 'tgrn', 'rorn', 'wrnb', 'ajn', 'onrn', 'bilrn', 'hiyn', 'irbgn', 'qirna', 'wgn', 'nirnr', 'irlnz', 'kxirn', 'ujn', 'yirgn', 'bisn', 'ibq', 'irxyn', 'ipru', 'dijrn', 'irgjn', 'immn', 'ivrnz', 'ygirn', 'hiron', 'uirno', 'irnfs', 'bhn', 'jinr', 'irzy', 'irlln', 'idon', 'ekrn', 'oiry', 'ibrr', 'cra', 'icjrn', 'imurn', 'ewrn', 'iabn', 'lifn', 'irxan', 'qrn', 'zqn', 'ivnn', 'izun', 'fiern', 'imrgn', 'mrns', 'izw', 'iet', 'yirnx', 'izs', 'jirin', 'gra', 'zrne', 'iroo', 'inrnz', 'nicrn', 'qirk', 'fairn', 'iyr', 'kisn', 'birs', 'irnue', 'micn', 'irme', 'urny', 'ipa', 'zifrn', 'jryn', 'nirng', 'irbo', 'ierj', 'iyzrn', 'jrqn', 'iirnl', 'iprq', 'rirny', 'irqnl', 'oirnu', 'yrx', 'pivn', 'err', 'irkzn', 'xrw', 'isrns', 'yirno', 'crb', 'oirt', 'orln', 'irnvx', 'nisn', 'uirkn', 'iwp', 'xzirn', 'oivrn', 'idrwn', 'irdmn', 'igrl', 'hrt', 'inrk', 'icrvn', 'pgrn', 'ivcrn', 'iire', 'wirmn', 'irner', 'iqrs', 'airen', 'lrne', 'irzrn', 'ifrnd', 'irknp', 'igfrn', 'qinrn', 'qiprn', 'irntm', 'kdirn', 'iyjn', 'irane', 'iirm', 'hbirn', 'xairn', 'idran', 'prni', 'irnew', 'lrnx', 'imin', 'igj', 'ioo', 'irniu', 'owirn', 'irvnq', 'eilrn', 'zfrn', 'roin', 'yren', 'irpj', 'diqn', 'imnq', 'tirmn', 'izx', 'ihrjn', 'ij', 'icarn', 'srn', 'irfkn', 'oirnn', 'wbirn', 'grnh', 'sen', 'kirna', 'nrnw', 'arin', 'irnob', 'irtni', 'ibrq', 'mcrn', 'irrw', 'ikrxn', 'irmnd', 'iyra', 'idrn', 'xra', 'irdfn', 'mirj', 'itzn', 'irneg', 'xien', 'irnyv', 'irlr', 'irnop', 'ioh', 'irmnm', 'ixrns', 'igorn', 'zikrn', 'iknx', 'iey', 'cihrn', 'izrzn', 'irenl', 'irzb', 'qrp', 'iepn', 'rsin', 'iwrfn', 'iunz', 'irtnl', 'ilx', 'irugn', 'irnvl', 'iyrh', 'intrn', 'ifrln', 'orni', 'zirw', 'tjrn', 'ijrh', 'iqz', 'lrd', 'irjjn', 'isarn', 'rirnr', 'rrnv', 'nvn', 'krwn', 'ifnd', 'iwmn', 'yifn', 'idri', 'airk', 'jrvn', 'itrt', 'irnna', 'irqnr', 'ssn', 'arnr', 'tirq', 'ienk', 'een', 'cirny', 'igjrn', 'idrnu', 'gairn', 'ifrx', 'hiarn', 'ijrzn', 'wrny', 'isqn', 'iznk', 'iryo', 'drsn', 'irtdn', 'irbqn', 'irpn', 'iornv', 'iwrnx', 'itorn', 'irnym', 'ihrz', 'lign', 'airni', 'pijn', 'erln', 'iurd', 'tgirn', 'ghn', 'zijrn', 'iqrtn', 'ivrnp', 'irrng', 'iprdn', 'idrnd', 'grf', 'miln', 'iurz', 'ibjrn', 'ltirn', 'iabrn', 'aird', 'irbm', 'iwrnv', 'niln', 'irhnl', 'irnmx', 'irdk', 'vdrn', 'iznw', 'xorn', 'rirqn', 'btrn', 'irsvn', 'ixrnd', 'dqirn', 'aipn', 'brrn', 'arnq', 'piri', 'irxb', 'izrz', 'lre', 'pirj', 'imnc', 'irlrn', 'qeirn', 'oirni', 'yrcn', 'iurrn', 'irlun', 'irpcn', 'itrwn', 'ibrnw', 'ncrn', 'obn', 'irqp', 'zlrn', 'hpn', 'ltrn', 'wxn', 'ivirn', 'ikry', 'irnlb', 'inrhn', 'gidn', 'gikrn', 'zdrn', 'dtirn', 'mru', 'iarm', 'iwarn', 'uirin', 'irut', 'xr', 'hhn', 'ihrw', 'irtxn', 'pyn', 'gnn', 'cikrn', 'airr', 'urgn', 'irnjo', 'iznr', 'iorns', 'irnyb', 'iehn', 'ifln', 'sion', 'itr', 'iwo', 'ivprn', 'virfn', 'ornp', 'silrn', 'ipnx', 'brpn', 'ixvrn', 'iwrna', 'krp', 'ibbrn', 'ilnr', 'yiru', 'ixurn', 'xsn', 'hrbn', 'irndd', 'utn', 'yizrn', 'mrhn', 'iej', 'wrt', 'irsfn', 'oyirn', 'irqnk', 'irdh', 'prl', 'irnkz', 'iay', 'hirxn', 'irann', 'hrdn', 'iqrni', 'ikrnb', 'ijy', 'iknq', 'igrnu', 'drnh', 'ibn', 'ianm', 'iorny', 'irzny', 'irntz', 'irftn', 'iujrn', 'iyrnc', 'ihnf', 'irmd', 'irsny', 'iurns', 'vren', 'iejrn', 'ihln', 'irnas', 'hvirn', 'lrtn', 'ih', 'piun', 'jirns', 'jirzn', 'iro', 'hrq', 'yjn', 'ernd', 'ipwn', 'hrun', 'unn', 'ibrsn', 'ierd', 'pixrn', 'cn', 'cixn', 'ihrq', 'iqnd', 'grnx', 'uirnv', 'rrp', 'iurnd', 'iznl', 'irnzp', 'ikv', 'ikryn', 'itgrn', 'iurzn', 'ircnn', 'irkz', 'mrf', 'mrt', 'rrnf', 'er', 'orr', 'tirdn', 'eirt', 'ihsn', 'qixrn', 'ienj', 'sirkn', 'irnwv', 'iymrn', 'irywn', 'icvrn', 'iqkrn', 'iznz', 'ierq', 'urns', 'itrp', 'iryy', 'irnbp', 'nirnz', 'isr', 'oen', 'iojrn', 'eirun', 'ibhrn', 'iugn', 'crt', 'ilnq', 'iqrnl', 'drin', 'pirl', 'aijn', 'irgnf', 'isk', 'dirnk', 'usirn', 'irzmn', 'cixrn', 'irhnd', 'birpn', 'ajirn', 'ifrny', 'srt', 'viro', 'airyn', 'irwcn', 'ienc', 'lirnm', 'riern', 'bqrn', 'iyern', 'zjn', 'ijd', 'oirdn', 'odrn', 'irnru', 'iurno', 'ixn', 'pian', 'dimn', 'viirn', 'eirnd', 'oirnh', 'rtn', 'iurn', 'ini', 'lwirn', 'kirln', 'virx', 'nqn', 'riv', 'iuu', 'iuw', 'zcirn', 'bra', 'nirh', 'irsn', 'zrp', 'ifbrn', 'pirbn', 'irbc', 'irrhn', 'vrrn', 'ijrnw', 'girwn', 'shn', 'cign', 'vre', 'brirn', 'hqirn', 'born', 'cirnx', 'ibran', 'ireo', 'tivrn', 'crnv', 'ixrgn', 'irzln', 'irbk', 'cpn', 'nrnj', 'yinrn', 'igrr', 'iosn', 'iurnk', 'bizrn', 'dhirn', 'cirnk', 'cirnj', 'uilrn', 'rdin', 'biyrn', 'kirnd', 'icrne', 'igmrn', 'irty', 'afrn', 'ersn', 'okirn', 'itt', 'idprn', 'ihnp', 'ixrj', 'isnn', 'eurn', 'mirsn', 'grgn', 'hirkn', 'girt', 'irgnw', 'irnq', 'sizrn', 'tpirn', 'piin', 'iynz', 'irwnx', 'ibprn', 'irnzs', 'irnyi', 'rirrn', 'liren', 'iryun', 'mirq', 'ibrn', 'uirr', 'iqnt', 'irtjn', 'iriun', 'ici', 'irvnr', 'pisn', 'ihgn', 'drs', 'kirz', 'lkn', 'iqrcn', 'izrnr', 'ihrtn', 'ijnv', 'qrjn', 'bryn', 'dird', 'hrc', 'wnirn', 'flrn', 'firnv', 'yin', 'ivx', 'ihrhn', 'wimrn', 'firv', 'ciin', 'irnfy', 'uicn', 'irvy', 'kjrn', 'ierbn', 'bivrn', 'iyrnr', 'jirpn', 'imn', 'ixtn', 'iwdrn', 'kgrn', 'vitn', 'iranf', 'dirni', 'ikrne', 'xrnm', 'pigrn', 'irmnp', 'nibn', 'prj', 'qlirn', 'icrj', 'ihrnj', 'firna', 'frin', 'xprn', 'frno', 'dian', 'iarvn', 'crnb', 'hyirn', 'iyv', 'ijk', 'iayn', 'jprn', 'vwirn', 'ihp', 'wran', 'iuxn', 'arp', 'lyrn', 'ienw', 'ijq', 'yrns', 'iirnk', 'iyrun', 'liqrn', 'iqun', 'nibrn', 'irnvp', 'iruq', 'izo', 'irnok', 'iyf', 'vrbn', 'ijnr', 'knn', 'nifn', 'igrb', 'pirn', 'irer', 'prne', 'igo', 'vijrn', 'iraq', 'ciirn', 'wigrn', 'grfn', 'ijrcn', 'iprd', 'ivern', 'vrirn', 'uibrn', 'ibrhn', 'airo', 'ibv', 'xirna', 'kion', 'ori', 'igd', 'idrnp', 'rirz', 'dirnd', 'tiwn', 'ironr', 'flirn', 'inrnx', 'hrk', 'ilurn', 'irxe', 'sizn', 'ijrvn', 'izron', 'wircn', 'ihcn', 'ijarn', 'iom', 'irfon', 'zrun', 'ihprn', 'igrzn', 'kirr', 'rirjn', 'rirun', 'isp', 'vrcn', 'izj', 'ikvn', 'ilrni', 'irdhn', 'pirr', 'aiirn', 'orq', 'kwrn', 'ihrnk', 'wkrn', 'irgni', 'grna', 'ilrno', 'sirnb', 'iharn', 'ilrcn', 'girnx', 'wirgn', 'imrna', 'qqn', 'lnr', 'binn', 'zsn', 'iornb', 'iero', 'iis', 'xivrn', 'bzrn', 'hrj', 'giru', 'xrfn', 'qwn', 'sbirn', 'ialrn', 'uidrn', 'ijirn', 'iorcn', 'iarz', 'br', 'wifrn', 'xirnm', 'ire', 'pirhn', 'irfnx', 'jirtn', 'iljrn', 'irwun', 'iion', 'irlt', 'hign', 'ijc', 'idrq', 'zirm', 'ikrh', 'rrb', 'irjpn', 'hirg', 'ijrnc', 'iywrn', 'cyrn', 'iarne', 'oirln', 'irhzn', 'nrng', 'irpne', 'wirf', 'krln', 'izryn', 'iyprn', 'iind', 'eairn', 'nrhn', 'virm', 'irmnh', 'irnwd', 'tivn', 'yhn', 'iazn', 'iyrfn', 'oxn', 'igurn', 'igkrn', 'ihrne', 'itnq', 'rrn', 'lzrn', 'inqn', 'xirnq', 'irsng', 'krl', 'iarnd', 'rirh', 'ytrn', 'iyro', 'rain', 'rij', 'aqirn', 'ibyn', 'drfn', 'ivns', 'birm', 'riu', 'iikn', 'irmx', 'irnka', 'ring', 'lirvn', 'qoirn', 'irnqe', 'fibrn', 'cro', 'ign', 'fvirn', 'irnll', 'irnkm', 'zir', 'irjnq', 'riry', 'irknq', 'ikny', 'isrnc', 'ita', 'uirgn', 'ijen', 'gzrn', 'vrxn', 'iand', 'pirb', 'iinj', 'jien', 'irngl', 'qirl', 'igqrn', 'erxn', 'irfmn', 'ipjrn', 'oarn', 'lsrn', 'dnn', 'tan', 'isq', 'oiro', 'irbr', 'yirnd', 'ipd', 'cirrn', 'iyrr', 'idrf', 'icrwn', 'irnnm', 'wizn', 'jimrn', 'brv', 'orhn', 'kian', 'qrl', 'eirln', 'iqrdn', 'ivnz', 'iaq', 'urc', 'jiren', 'lern', 'nqrn', 'brnz', 'xqirn', 'ivrb', 'dirnr', 'xign', 'itp', 'pyirn', 'ixry', 'agrn', 'wirin', 'jsirn', 'irnpk', 'hinn', 'prjn', 'iao', 'frnw', 'ijl', 'ritn', 'irnmz', 'xiyn', 'jiprn', 'irtg', 'tijrn', 'diwn', 'uwn', 'gin', 'brnl', 'eirfn', 'iorb', 'mrg', 'ihm', 'xrv', 'nrb', 'ifhn', 'xisn', 'irkon', 'cira', 'innb', 'iybrn', 'qrfn', 'inqrn', 'irgj', 'birnr', 'rirw', 'vrny', 'mirln', 'qirt', 'kro', 'sirnu', 'brj', 'itrpn', 'idwrn', 'inrkn', 'iirnq', 'mirnd', 'irgqn', 'iddn', 'uinrn', 'ijvn', 'irzv', 'jyirn', 'irznh', 'vrnh', 'wirz', 'oien', 'oyn', 'zirs', 'ibrno', 'irnor', 'wrl', 'cirnv', 'jpirn', 'ifon', 'isny', 'limrn', 'jwirn', 'igl', 'oirzn', 'brh', 'trt', 'irwe', 'ikwn', 'nirw', 'irnws', 'ihjn', 'irok', 'iobn', 'imrt', 'iyvrn', 'ric', 'qien', 'rirm', 'ibqn', 'qrnw', 'eun', 'tdirn', 'iprgn', 'ivrno', 'ijt', 'irnub', 'ilri', 'tirjn', 'fzn', 'iwrny', 'idxn', 'piirn', 'irrnw', 'ihnm', 'ebrn', 'hgirn', 'firgn', 'ixron', 'irwnt', 'irsln', 'ixfrn', 'vgn', 'irnzc', 'irus', 'sitrn', 'iorun', 'irjb', 'jnrn', 'ribn', 'ijni', 'iryu', 'tqirn', 'imrdn', 'xern', 'nirwn', 'ainr', 'vprn', 'irnkn', 'igx', 'hbn', 'ivnu', 'ixre', 'irrnh', 'rrnj', 'dirj', 'finn', 'rind', 'hrrn', 'innq', 'iyqrn', 'irze', 'oiin', 'irxnj', 'irncm', 'crnk', 'irqi', 'brnr', 'irvzn', 'irbx', 'irfnb', 'igran', 'ironw', 'iric', 'irnk', 'irsni', 'izrni', 'zrqn', 'izp', 'issn', 'irpnu', 'virr', 'irwq', 'rinp', 'girny', 'arqn', 'uiren', 'ivrin', 'imvrn', 'dorn', 'vpn', 'ikx', 'irzt', 'irvo', 'isjn', 'irbi', 'hiri', 'kirnx', 'isvn', 'ins', 'pien', 'icpn', 'oorn', 'wilrn', 'ifryn', 'irpng', 'iorvn', 'qirnd', 'iqre', 'irmwn', 'irnrr', 'igzn', 'ipny', 'eirny', 'iktn', 'virnc', 'vpirn', 'iijn', 'ihnd', 'iurna', 'wrhn', 'irxv', 'irngo', 'itcrn', 'qircn', 'iarrn', 'srd', 'iqvrn', 'iins', 'armn', 'frl', 'sirnh', 'qirmn', 'izwn', 'zirg', 'oirp', 'irnce', 'ipb', 'irnkf', 'iwrc', 'drg', 'irhnn', 'ifne', 'iri', 'ias', 'uirjn', 'frxn', 'irnrg', 'ivnc', 'trkn', 'nrnh', 'vitrn', 'biin', 'iln', 'irco', 'ienh', 'ierhn', 'iik', 'ixng', 'xqn', 'srf', 'dfirn', 'irnwy', 'isnz', 'irfno', 'irown', 'irnyq', 'irnzv', 'ddrn', 'zirh', 'jjrn', 'fijrn', 'jrwn', 'jizn', 'iorni', 'zirnf', 'zirnm', 'igrin', 'irnvz', 'rid', 'rrqn', 'ivrnt', 'don', 'qisn', 'irbxn', 'afn', 'yirq', 'irhnh', 'iwrnq', 'sirnw', 'irqon', 'qiryn', 'irljn', 'biern', 'drqn', 'irxo', 'bran', 'yrb', 'irdno', 'beirn', 'miyn', 'tirnp', 'ily', 'ikrzn', 'irnsn', 'arkn', 'irnlu', 'nirnf', 'niprn', 'winn', 'pmrn', 'ia', 'yarn', 'cgn', 'pirtn', 'pirnv', 'izrnh', 'tinr', 'sirxn', 'virq', 'orn', 'irwz', 'ilu', 'irien', 'ikrm', 'vrni', 'eiri', 'irabn', 'aiorn', 'iroc', 'ijnrn', 'ikrd', 'iinm', 'hlirn', 'isx', 'iovrn', 'yirng', 'rcn', 'irind', 'ribrn', 'dirtn', 'iyran', 'iynj', 'birkn', 'ijrpn', 'uiqn', 'irbf', 'giern', 'ciryn', 'irfwn', 'cilrn', 'iyre', 'rnr', 'irnxx', 'ifrnj', 'ipnrn', 'hrp', 'irub', 'itran', 'lixn', 'irfnh', 'uro', 'ilt', 'zirz', 'hidn', 'inxr', 'zxrn', 'ilrz', 'irjhn', 'irntl', 'iarc', 'orns', 'iqxrn', 'ifkrn', 'iirnj', 'qfn', 'irong', 'rirxn', 'innj', 'mirw', 'irnab', 'cihn', 'kirdn', 'iqrb', 'krnb', 'iqrne', 'irlnq', 'iruon', 'izv', 'iyrm', 'iiron', 'iemn', 'ickrn', 'ikrnl', 'ueirn', 'xihn', 'brng', 'wion', 'ivz', 'ifw', 'cirj', 'wgirn', 'irngd', 'rign', 'qijrn', 'idrkn', 'qrcn', 'iwry', 'orny', 'vqn', 'rirno', 'iraf', 'irfrn', 'ivrw', 'rirq', 'irtnb', 'rprn', 'sirnz', 'irswn', 'irtnn', 'irnsj', 'drmn', 'rrfn', 'nrd', 'irnqo', 'icwn', 'irnoq', 'ihng', 'irmf', 'izyn', 'zn', 'uirne', 'ixrnp', 'tkirn', 'irbln', 'iqrpn', 'irnwx', 'icrnk', 'lrq', 'rixn', 'icdrn', 'ikd', 'airt', 'urp', 'zrbn', 'ihrnc', 'irqin', 'igrk', 'rirnk', 'irwi', 'itrnx', 'frx', 'kdn', 'tirrn', 'qrnm', 'iurtn', 'mrnc', 'idsn', 'qidn', 'ifd', 'irain', 'iarcn', 'wiwn', 'ibrnx', 'zkirn', 'irenm', 'icrv', 'grcn', 'yrs', 'imrnt', 'dru', 'wirl', 'icrk', 'iczn', 'ighrn', 'irnjk', 'ron', 'uidn', 'irsgn', 'ironz', 'hirun', 'riirn', 'ierny', 'inwrn', 'arpn', 'ziprn', 'igbrn', 'irngg', 'iunq', 'zrxn', 'kinrn', 'kirg', 'nnr', 'uran', 'ians', 'ijrn', 'ipcrn', 'prnn', 'irntn', 'irha', 'idy', 'erc', 'tizn', 'ipqrn', 'mrn', 'nrh', 'frf', 'irnno', 'irjni', 'rinu', 'irjg', 'eern', 'kiin', 'idrln', 'lirnt', 'irlan', 'izrnu', 'tbirn', 'oitn', 'irnav', 'iim', 'imzn', 'srz', 'rinf', 'nyrn', 'izg', 'irnge', 'yxrn', 'irhtn', 'liwrn', 'jrnf', 'ikqn', 'ixkrn', 'jiron', 'iryny', 'hiwn', 'xrm', 'airwn', 'irex', 'cirsn', 'itnj', 'uirhn', 'iwdn', 'irxdn', 'irrln', 'igny', 'infr', 'irtnm', 'irsnv', 'czrn', 'drnp', 'nrvn', 'irgnq', 'iyn', 'virnf', 'iornn', 'ciru', 'isrb', 'impn', 'iqdrn', 'furn', 'irql', 'iorx', 'irunu', 'nrs', 'dirzn', 'rry', 'lipn', 'oron', 'iref', 'iruj', 'irmnb', 'ibfn', 'sisn', 'irpna', 'pjrn', 'irxnq', 'yra', 'biwn', 'irfgn', 'frj', 'iyqn', 'gvirn', 'aru', 'frt', 'krnm', 'cipn', 'dirnn', 'iary', 'pinrn', 'irdvn', 'jin', 'oilrn', 'igrnf', 'irldn', 'isrnw', 'rs', 'uin', 'irlnc', 'hsirn', 'lirbn', 'irgnk', 'jrb', 'ziryn', 'lirn', 'ynn', 'irim', 'irojn', 'hirns', 'irmfn', 'jrq', 'iratn', 'kirw', 'zirr', 'iqnu', 'dirsn', 'yfn', 'irol', 'yqirn', 'iano', 'irfnw', 'zrg', 'bifn', 'zmn', 'eirtn', 'jian', 'irbrn', 'kirq', 'ijsn', 'igr', 'uzn', 'airc', 'qcrn', 'aiqrn', 'mrnx', 'iprx', 'wry', 'isrxn', 'kyirn', 'pin', 'hirqn', 'iarnr', 'xirns', 'piru', 'iprwn', 'norn', 'irnys', 'zyn', 'hron', 'irepn', 'qnirn', 'mrnp', 'iryb', 'iogrn', 'rif', 'erwn', 'irnmw', 'irchn', 'iryx', 'izrm', 'oirm', 'virng', 'irmh', 'biprn', 'itri', 'inrnv', 'eirf', 'ornr', 'erg', 'tijn', 'ern', 'iforn', 'irnxo', 'hrz', 'prc', 'kir', 'irwr', 'pirdn', 'hcn', 'iornl', 'irfnq', 'iortn', 'txn', 'sirnd', 'idun', 'icnn', 'jrxn', 'okrn', 'inrrn', 'tipn', 'qign', 'xzn', 'ikj', 'ihrnb', 'ircnr', 'urd', 'wisn', 'ibkrn', 'irox', 'iuprn', 'irrni', 'lrun', 'vyn', 'irscn', 'iirnr', 'inrg', 'oirno', 'urfn', 'irnbi', 'giprn', 'uirpn', 'irngu', 'ririn', 'mmn', 'ihrwn', 'isnrn', 'girnz', 'drz', 'qikrn', 'irkpn', 'irenn', 'firr', 'ujrn', 'fizn', 'uirna', 'ibrdn', 'wrnw', 'jinrn', 'ibcrn', 'iriq', 'irnqz', 'iracn', 'ixrp', 'siarn', 'biln', 'ipq', 'lrcn', 'irinv', 'cen', 'qirrn', 'vrvn', 'iqrhn', 'eikn', 'sirwn', 'sire', 'isrpn', 'yijn', 'irgin', 'ihrcn', 'irnxu', 'oirnt', 'lrnz', 'bircn', 'zirnn', 'iranx', 'iorin', 'ipzrn', 'tfirn', 'iqrnr', 'ics', 'vrdn', 'ibzn', 'riorn', 'girnk', 'yjirn', 'irct', 'nirnt', 'iyrvn', 'ctirn', 'irnrd', 'iscn', 'irvz', 'ixnn', 'grnj', 'ipvn', 'irjbn', 'wqirn', 'isrfn', 'igrnc', 'ecirn', 'liran', 'wiurn', 'idrhn', 'aryn', 'hinrn', 'iuvrn', 'hrf', 'ifrd', 'ijnp', 'icron', 'iaun', 'lirl', 'bgirn', 'irea', 'tixn', 'mrnn', 'qrnj', 'prp', 'irndv', 'lrnm', 'girtn', 'kira', 'ikrnq', 'pnirn', 'vrx', 'iwmrn', 'firnl', 'agn', 'irsd', 'rirc', 'irnfx', 'irznk', 'itnu', 'ixdrn', 'idrnv', 'xqrn', 'iqwrn', 'arln', 'iarin', 'rirzn', 'hiqrn', 'hin', 'irnsx', 'irmqn', 'birnn', 'jrun', 'atn', 'vixn', 'krxn', 'ikjrn', 'aron', 'oinr', 'xidn', 'rwrn', 'aln', 'darn', 'ijrnq', 'yeirn', 'tron', 'ivron', 'qiran', 'oirng', 'yrfn', 'phrn', 'nire', 'dirnt', 'korn', 'icrl', 'izrsn', 'iiz', 'dirw', 'itbn', 'irnlx', 'hmirn', 'kn', 'srx', 'uirnd', 'itx', 'prvn', 'fpn', 'nrne', 'iprln', 'irnbw', 'izrnq', 'hiran', 'ironv', 'ibrnd', 'ibqrn', 'inrz', 'irokn', 'krcn', 'iev', 'irnef', 'izqrn', 'ijrna', 'irndn', 'rirg', 'ftrn', 'isbrn', 'eirvn', 'airjn', 'tigrn', 'zdn', 'gion', 'ifin', 'mirnx', 'irnrx', 'ugirn', 'jyn', 'yirt', 'itrr', 'hvrn', 'xifn', 'idrtn', 'lun', 'yirnz', 'xivn', 'iyu', 'irug', 'acrn', 'irwa', 'itnr', 'irde', 'grt', 'earn', 'qrnn', 'itq', 'ikrnw', 'seirn', 'hiln', 'ircnk', 'irkcn', 'iynh', 'iwrf', 'irnga', 'fbirn', 'irnuv', 'adn', 'sern', 'cifn', 'imsrn', 'qirn', 'tirni', 'irnpy', 'fipn', 'cien', 'wirwn', 'icon', 'fircn', 'kilrn', 'uihrn', 'frnz', 'imrm', 'jrnl', 'sikn', 'ilq', 'ifzn', 'irnem', 'irlnn', 'iai', 'izf', 'qnn', 'irwx', 'ircnj', 'irnse', 'imra', 'girdn', 'irnqk', 'ildn', 'hiry', 'ziyn', 'dirnz', 'dxn', 'ierpn', 'ipne', 'ikun', 'iknw', 'imrnp', 'ars', 'krv', 'imnj', 'mjirn', 'nirvn', 'iurw', 'ibrp', 'irnyn', 'irnuf', 'irgnd', 'riprn', 'nion', 'iqnb', 'ixrng', 'nran', 'wikrn', 'igrnk', 'ihrgn', 'xon', 'irdnp', 'prun', 'ima', 'qgrn', 'hrxn', 'inurn', 'jiorn', 'iarq', 'iront', 'imna', 'ihdn', 'nrin', 'ivjn', 'iwrl', 'brnm', 'xrqn', 'jirnl', 'irenx', 'ilmrn', 'jzn', 'irhhn', 'ivt', 'irup', 'eifrn', 'iprf', 'isrne', 'kiyn', 'irnle', 'ipsrn', 'ind', 'ifhrn', 'ikrhn', 'own', 'lirng', 'birmn', 'dxirn', 'qirin', 'icre', 'pairn', 'irnfv', 'iroqn', 'frne', 'irah', 'qirf', 'girnb', 'miry', 'mvirn', 'rrnl', 'ilnv', 'iunl', 'iwc', 'ixrnt', 'tirnk', 'hirnh', 're', 'yirin', 'biron', 'irls', 'ionz', 'irion', 'ican', 'ytn', 'tirun', 'nisrn', 'yiyrn', 'kiqn', 'oirna', 'issrn', 'wqrn', 'ihrna', 'kvn', 'srr', 'iropn', 'ionw', 'eiln', 'bvirn', 'ikro', 'iranu', 'ihnt', 'brzn', 'goirn', 'erfn', 'zrwn', 'arm', 'ip', 'irnrh', 'fiin', 'irnjj', 'ricrn', 'iirnz', 'irhbn', 'irbnr', 'irnct', 'qpn', 'ifrw', 'tirnz', 'irgr', 'drwn', 'iruun', 'iwrnj', 'srne', 'mrv', 'rnn', 'thn', 'nmn', 'hrnj', 'sra', 'mnrn', 'iwt', 'xrirn', 'wjn', 'dixrn', 'ijyrn', 'tirnl', 'inrd', 'innz', 'igvn', 'iaurn', 'xidrn', 'von', 'innf', 'inrf', 'irba', 'pirnj', 'ireni', 'ibrin', 'iprhn', 'girnf', 'ift', 'crnr', 'dirh', 'rkn', 'crk', 'icfrn', 'iorgn', 'rrun', 'micrn', 'gyrn', 'iriu', 'zcn', 'inr', 'airb', 'igt', 'iqri', 'irhy', 'ienq', 'ili', 'ijrp', 'ycrn', 'erz', 'irunw', 'ixgn', 'ianl', 'irte', 'xtrn', 'otrn', 'ewn', 'vfirn', 'ibru', 'irczn', 'icrzn', 'bion', 'irdf', 'ara', 'giurn', 'iprvn', 'irnve', 'irdln', 'uixn', 'irfpn', 'iyi', 'irvl', 'adirn', 'lrgn', 'ilfrn', 'isrqn', 'icgn', 'oirgn', 'niorn', 'ujirn', 'irnfp', 'zwn', 'yln', 'ilrng', 'iwi', 'irnkc', 'iwng', 'firkn', 'trp', 'zian', 'irkq', 'irnpf', 'ixyn', 'izrin', 'iksn', 'ojirn', 'wrne', 'qirfn', 'ironp', 'irbvn', 'igrrn', 'mirin', 'xrl', 'icrg', 'ipnt', 'iiyrn', 'icv', 'ixrrn', 'xijn', 'cjirn', 'wiirn', 'igru', 'zrnt', 'isrnj', 'iyl', 'ixdn', 'rgin', 'icmn', 'ubirn', 'iryj', 'tirpn', 'irvv', 'tirsn', 'circ', 'ierw', 'irwen', 'ihjrn', 'rnb', 'iqrnv', 'ijrw', 'rik', 'birdn', 'inbrn', 'oirny', 'frln', 'irsz', 'irtn', 'yprn', 'inrvn', 'firin', 'lirv', 'iwm', 'irknr', 'ihu', 'irksn', 'grkn', 'irmcn', 'irxnb', 'auirn', 'itrnt', 'qrvn', 'ezrn', 'tpn', 'iu', 'iurnj', 'iugrn', 'vrwn', 'arcn', 'sarn', 'ianb', 'irnux', 'htirn', 'svirn', 'iradn', 'yirnf', 'eirng', 'irtnq', 'zirp', 'wrnz', 'efn', 'yyrn', 'iskn', 'irnto', 'ivrm', 'ivzrn', 'ihzrn', 'irrnd', 'fry', 'igrnt', 'idrfn', 'mrs', 'frnd', 'irnlc', 'wrqn', 'rurn', 'virhn', 'pirk', 'eiyrn', 'iit', 'bprn', 'ihj', 'lyirn', 'dijn', 'irnth', 'ilnu', 'zwirn', 'tirnj', 'ibrnj', 'izrj', 'irfyn', 'siri', 'ikrz', 'irndz', 'trqn', 'ixbrn', 'iunx', 'sian', 'firjn', 'nrn', 'ivrp', 'ikrnt', 'dibrn', 'ireyn', 'irit', 'mkn', 'qrqn', 'irnpe', 'krqn', 'irqq', 'iocrn', 'eren', 'pzn', 'irdpn', 'irrun', 'iltrn', 'ofrn', 'irnye', 'irqc', 'eiqrn', 'irino', 'iraan', 'irnfn', 'irsj', 'brtn', 'jirvn', 'jrj', 'irunp', 'izro', 'zimrn', 'iearn', 'irney', 'ilren', 'isfn', 'drnz', 'irps', 'tkn', 'irnkr', 'ida', 'ieru', 'siqn', 'irji', 'trjn', 'imrs', 'oern', 'yirn', 'airg', 'trs', 'firnu', 'gigrn', 'kiun', 'qiarn', 'tinrn', 'imrhn', 'enirn', 'hren', 'zirpn', 'iaro', 'xin', 'hrln', 'tirnm', 'iuron', 'qirqn', 'isrv', 'irzpn', 'irvnx', 'ornt', 'irpnq', 'kirl', 'ioln', 'ibne', 'irzjn', 'xirg', 'itrny', 'qr', 'ivtrn', 'iwxn', 'igrq', 'aikn', 'rrnc', 'irnry', 'ibrni', 'hirn', 'irurn', 'eird', 'ixrnf', 'ilrnp', 'yrnf', 'jhn', 'pimrn', 'irnov', 'iogn', 'wir', 'firnc', 'ienrn', 'ijwn', 'eihn', 'irnxb', 'irbnd', 'cirnm', 'irunv', 'idvn', 'cairn', 'iyrnv', 'ffirn', 'ijri', 'isrwn', 'ihry', 'vira', 'n', 'lrhn', 'idg', 'gorn', 'irqhn', 'ijrfn', 'krny', 'kqirn', 'iynl', 'dicn', 'pwrn', 'oikn', 'iyron', 'irzk', 'izrnw', 'girf', 'urni', 'ipirn', 'ixrun', 'ipnf', 'iyw', 'ziry', 'iznp', 'veirn', 'yro', 'ippn', 'irfh', 'sirqn', 'qirm', 'gre', 'igcn', 'irena', 'npn', 'omn', 'pivrn', 'iag', 'lin', 'aign', 'oiru', 'rran', 'piurn', 'grr', 'virgn', 'iywn', 'ailn', 'xirkn', 'ijno', 'izre', 'zyirn', 'irdc', 'urno', 'iou', 'virnz', 'ktirn', 'isnd', 'birl', 'icnq', 'gryn', 'ifkn', 'zri', 'lgrn', 'irbnv', 'iyin', 'wrnk', 'nrz', 'irobn', 'rr', 'sira', 'wirnw', 'diirn', 'imrnv', 'mirjn', 'aurn', 'irnet', 'inre', 'irhe', 'birnd', 'phn', 'jirni', 'qihn', 'irnoz', 'iee', 'rng', 'xlrn', 'dihrn', 'irhnz', 'xcrn', 'ivng', 'xrk', 'izrnn', 'irnoh', 'irusn', 'ipna', 'iril', 'brjn', 'ilg', 'ihre', 'irrnt', 'svrn', 'ixjrn', 'tirnn', 'krnt', 'brt', 'irwnz', 'iernk', 'uoirn', 'yion', 'irnod', 'irinq', 'ari', 'qrnu', 'mihn', 'irnhn', 'irzj', 'icgrn', 'drf', 'ixhn', 'ivrnl', 'irqs', 'irj', 'irhf', 'rqn', 'iqrnz', 'srin', 'isrt', 'iraon', 'ibpn', 'ick', 'tqrn', 'wirnv', 'iqb', 'infn', 'ipnq', 'iprnt', 'wrwn', 'irtf', 'itra', 'hipn', 'tion', 'qirln', 'lru', 'girfn', 'ibrtn', 'islrn', 'wbn', 'cjn', 'irlnr', 'ivrgn', 'irirn', 'iurq', 'ierr', 'irenr', 'pirc', 'uhrn', 'irvpn', 'wirvn', 'sro', 'iuyn', 'psrn', 'irene', 'imrk', 'iynp', 'ten', 'uivrn', 'yjrn', 'inc', 'ihrny', 'iztn', 'ibrg', 'iqs', 'iwrn', 'wrx', 'irfng', 'istrn', 'siry', 'ihon', 'dir', 'firpn', 'iwrp', 'tlrn', 'jirnq', 'riw', 'irynp', 'icsrn', 'xmrn', 'uiran', 'ikrvn', 'xirk', 'irbnu', 'irxni', 'ovrn', 'izcn', 'birc', 'rire', 'mprn', 'rirnd', 'iarj', 'orng', 'ixrs', 'hicn', 'irnkq', 'irnxw', 'hprn', 'wirx', 'irnjm', 'irgs', 'kran', 'ien', 'rnz', 'urx', 'fpirn', 'eirrn', 'irnax', 'iqmrn', 'iynq', 'bbirn', 'lr', 'nien', 'ipra', 'izrc', 'sirns', 'birnv', 'ihurn', 'itrnw', 'ionu', 'irznn', 'wirnc', 'qirsn', 'dqn', 'icrd', 'bbn', 'irtzn', 'arhn', 'irrcn', 'barn', 'irfnk', 'ijrx', 'grirn', 'eirp', 'scrn', 'ixsrn', 'hirnw', 'birni', 'krhn', 'xryn', 'yikrn', 'iken', 'wirsn', 'irlnd', 'irmu', 'icr', 'irhkn', 'mrw', 'irttn', 'irqnh', 'ixw', 'irvny', 'difn', 'uiryn', 'ircyn', 'isnj', 'irtnw', 'irkr', 'iien', 'xwrn', 'frvn', 'ulrn', 'quirn', 'isng', 'inrnp', 'mrq', 'dyrn', 'cirzn', 'qan', 'kln', 'iafrn', 'irwnm', 'orv', 'eiorn', 'irnwt', 'irnaf', 'wirfn', 'nru', 'urnz', 'irkh', 'irnfu', 'vizrn', 'ilrd', 'pirng', 'tfn', 'pidrn', 'urirn', 'ifm', 'irfny', 'rjrn', 'crne', 'hnr', 'aidn', 'ery', 'irtqn', 'ilrnc', 'hicrn', 'xrnk', 'tn', 'irgen', 'urin', 'ernq', 'uirnt', 'ihan', 'irznr', 'icqrn', 'hru', 'thirn', 'mmrn', 'wrf', 'uixrn', 'airkn', 'bjirn', 'irghn', 'zrsn', 'pcn', 'jrnx', 'irsrn', 'ihnc', 'xirnx', 'qirx', 'ikrfn', 'irtkn', 'itsn', 'witrn', 'qipn', 'ieh', 'rirnq', 'axn', 'iyrin', 'ditn', 'tiern', 'ytirn', 'iqrn', 'sbn', 'ernj', 'imrnu', 'imren', 'vrnn', 'inirn', 'qryn', 'zarn', 'pirnz', 'azrn', 'nrl', 'bijrn', 'irnoa', 'ivnv', 'ihi', 'qtirn', 'irknh', 'oizn', 'zrzn', 'oira', 'iriqn', 'iznu', 'yrj', 'itrna', 'tnr', 'pln', 'gwirn', 'iriny', 'cinn', 'rnd', 'xiern', 'iiu', 'itwn', 'nirhn', 'ihy', 'irpnl', 'qen', 'irtnz', 'ixns', 'jibn', 'dirun', 'icy', 'iei', 'uirc', 'niry', 'oinrn', 'irtnh', 'ihrin', 'pirnt', 'iirnp', 'ornq', 'crng', 'iqrna', 'imrnm', 'iermn', 'vvn', 'wiqn', 'iars', 'cijn', 'uirsn', 'ialn', 'yimn', 'qion', 'iqrjn', 'ihnv', 'foirn', 'qrhn', 'virnb', 'oixrn', 'irhni', 'iza', 'irnzh', 'iuorn', 'zrv', 'jirz', 'ihxrn', 'ipfrn', 'gizn', 'ieyrn', 'ijr', 'fon', 'wirnr', 'iqnh', 'ikln', 'itjrn', 'ton', 'hirgn', 'igrns', 'iiqn', 'hen', 'inrln', 'ikrw', 'zrnv', 'irnzl', 'ijrkn', 'yrnw', 'ibnc', 'icun', 'ixnc', 'iatrn', 'kirnh', 'vurn', 'irefn', 'mirfn', 'zirq', 'jiin', 'sirtn', 'irnme', 'irhg', 'ihrnw', 'ifrnb', 'uzirn', 'itrsn', 'irnml', 'itrxn', 'ixnz', 'imnw', 'mitrn', 'yrnj', 'iznb', 'nyirn', 'rern', 'jran', 'ibrnr', 'lirqn', 'nbn', 'yuirn', 'nrcn', 'dirnx', 'inl', 'isrj', 'uairn', 'imrrn', 'irnmr', 'lrwn', 'ipi', 'ilrnu', 'iwna', 'hurn', 'arsn', 'iurvn', 'irrno', 'iikrn', 'rbirn', 'irsnn', 'isni', 'oihrn', 'iira', 'lirg', 'irwdn', 'itmn', 'irbn', 'mirxn', 'wrzn', 'eirr', 'igjn', 'isgrn', 'eiprn', 'idfrn', 'gwn', 'iirnd', 'hirln', 'jrrn', 'aiarn', 'itren', 'liwn', 'lirz', 'ztn', 'nkrn', 'iernf', 'qirnl', 'irvd', 'txirn', 'irmr', 'uiri', 'iaran', 'jiry', 'aorn', 'hrnw', 'inrns', 'iarhn', 'irvln', 'innm', 'irst', 'iirng', 'ipj', 'sun', 'nairn', 'hircn', 'zwrn', 'avirn', 'uiron', 'ijpn', 'irxun', 'lizn', 'cirkn', 'hro', 'vidrn', 'ionl', 'irei', 'hiin', 'dirrn', 'im', 'firnk', 'irnmh', 'ircpn', 'wirdn', 'ijnj', 'icna', 'irmni', 'inen', 'iyrno', 'irzng', 'wyn', 'yfrn', 'rinl', 'rirni', 'oigrn', 'imns', 'ihsrn', 'jirb', 'irqo', 'ihri', 'arx', 'ilnt', 'ignb', 'ikhrn', 'yirun', 'tdn', 'irpno', 'igvrn', 'mpn', 'isnr', 'urj', 'vjirn', 'ilre', 'irinn', 'xuirn', 'xpirn', 'zeirn', 'ivxrn', 'lrnv', 'tirnd', 'visn', 'zpn', 'nrnl', 'wmirn', 'zin', 'xnn', 'cjrn', 'dirnp', 'einr', 'irnqn', 'ilkn', 'ixb', 'iofrn', 'riwn', 'irofn', 'irgnn', 'wfirn', 'irew', 'ipfn', 'iilrn', 'ihrm', 'iyvn', 'airj', 'vihn', 'drd', 'indrn', 'jiun', 'idrvn', 'ocirn', 'ben', 'arwn', 'dirr', 'ibzrn', 'miyrn', 'iyrnj', 'ibrs', 'ivnq', 'iwin', 'ixqn', 'arq', 'lrng', 'izrnp', 'irnif', 'onirn', 'igtrn', 'irxnm', 'igrnw', 'ironh', 'irnnh', 'izrne', 'zizrn', 'krsn', 'tirvn', 'irrpn', 'qrni', 'icf', 'oirnm', 'zrng', 'qjn', 'dpirn', 'virh', 'oirk', 'irnpb', 'yre', 'uirbn', 'inrxn', 'brkn', 'lan', 'uyrn', 'irrp', 'birxn', 'ild', 'ipsn', 'i', 'riin', 'innx', 'irwyn', 'izon', 'xeirn', 'scn', 'ornw', 'van', 'icu', 'fvrn', 'ipu', 'airv', 'kirgn', 'dirkn', 'ernx', 'ienr', 'ditrn', 'sgn', 'ivrsn', 'irtw', 'irnzr', 'mre', 'hirzn', 'nirni', 'yvirn', 'irvt', 'iriwn', 'rirnu', 'irsnb', 'dyn', 'cfrn', 'irwln', 'io', 'irjnv', 'firz', 'irvwn', 'ijln', 'ry', 'irndo', 'ironn', 'msirn', 'nln', 'iaprn', 'eqrn', 'lra', 'virnv', 'iklrn', 'irhpn', 'itna', 'krnd', 'birbn', 'ibri', 'isj', 'iarni', 'irek', 'ircfn', 'diro', 'ilnrn', 'irsv', 'imu', 'fiwrn', 'dhn', 'jcirn', 'ifvrn', 'iqrng', 'xrxn', 'pirs', 'iorzn', 'ienm', 'biro', 'iorn', 'irsun', 'mwn', 'oirg', 'ionrn', 'itrb', 'isrnp', 'icc', 'pjn', 'ixcrn', 'diorn', 'nira', 'bikrn', 'rine', 'ilrin', 'srvn', 'inrq', 'ircnf', 'ir', 'vdirn', 'linrn', 'rzrn', 'tren', 'ioryn', 'irnty', 'inv', 'icj', 'xikn', 'iehrn', 'xirvn', 'iujn', 'il', 'rrns', 'qirne', 'tjirn', 'oirnd', 'pizrn', 'prnx', 'airqn', 'tiry', 'iqrrn', 'irnau', 'irnou', 'arirn', 'lirns', 'igxrn', 'jirm', 'iwnq', 'vrnv', 'ttrn', 'grg', 'zoirn', 'iuy', 'jirnv', 'uzrn', 'irlnk', 'irbhn', 'rnu', 'wrq', 'mrb', 'iprns', 'ibrbn', 'nvirn', 'irnpi', 'trcn', 'iwri', 'irrmn', 'isrk', 'virzn', 'orw', 'ixrk', 'xrnb', 'jirnt', 'qbirn', 'wire', 'lirm', 'ironj', 'jirj', 'pirzn', 'orin', 'reirn', 'isns', 'irro', 'itnrn', 'zirns', 'hirm', 'iayrn', 'ivnr', 'mron', 'iopn', 'ikk', 'irfxn', 'yen', 'yikn', 'eirj', 'ibrnv', 'kirqn', 'frd', 'qarn', 'itnx', 'irhn', 'irvu', 'irnwj', 'rinx', 'ymirn', 'igrvn', 'iranv', 'ornf', 'irine', 'birnj', 'iorpn', 'isrn', 'ilarn', 'krk', 'ijorn', 'rrnr', 'dirnw', 'icra', 'oion', 'ie', 'uirnn', 'irlzn', 'pirna', 'ifprn', 'iyrq', 'qrz', 'irqkn', 'kixn', 'icnd', 'irmkn', 'ieirn', 'xirf', 'pirns', 'irqnn', 'isrgn', 'xrnd', 'lrni', 'jfirn', 'idern', 'r', 'irnqu', 'irnjy', 'frnj', 'ilrt', 'ieun', 'iecn', 'rivrn', 'irpnf', 'firne', 'ihh', 'irtnt', 'irixn', 'iqnl', 'grp', 'imrr', 'wrz', 'igrnr', 'fsn', 'innr', 'ietrn', 'srnh', 'iroin', 'drni', 'ghirn', 'iuzrn', 'ihrj', 'icnw', 'iirnb', 'tgn', 'hrne', 'ijjn', 'irey', 'yirdn', 'airnz', 'irnkd', 'yijrn', 'bimrn', 'hirnc', 'ianz', 'iirsn', 'xiun', 'irvx', 'iurfn', 'irqk', 'ihb', 'iyno', 'uiyn', 'irlfn', 'giwn', 'iornd', 'kyn', 'ayirn', 'iwrnt', 'iqrny', 'ibgn', 'idnj', 'irxne', 'ln', 'urun', 'fsirn', 'mirnw', 'irjk', 'birnf', 'ircbn', 'itfn', 'xlirn', 'irpk', 'umn', 'nirt', 'bxrn', 'gxrn', 'ihrc', 'iknd', 'irev', 'crvn', 'yirp', 'kmrn', 'ikt', 'izhrn', 'htn', 'irnwe', 'itrnb', 'pirnx', 'irynn', 'itng', 'irynb', 'ipon', 'zixn', 'irrnv', 'hrqn', 'ionm', 'iernc', 'crv', 'crbn', 'irmq', 'mirgn', 'sairn', 'iwrh', 'uipn', 'srng', 'rrcn', 'yhirn', 'irnxs', 'oirtn', 'isre', 'zmrn', 'wirns', 'varn', 'irhnb', 'ivrjn', 'iqrin', 'hirne', 'iarbn', 'ilhn', 'nirqn', 'ddn', 'kirfn', 'idb', 'irkin', 'krnz', 'iyny', 'ard', 'lirp', 'irnbs', 'ahrn', 'irdm', 'vipn', 'huirn', 'ernn', 'iarf', 'fri', 'xrdn', 'iprun', 'nirnk', 'iqrp', 'irw', 'iynv', 'uvrn', 'vlirn', 'irppn', 'nrns', 'erh', 'ikrsn', 'irop', 'arnz', 'iqrc', 'fren', 'wrin', 'idrd', 'ilrnb', 'imron', 'ircno', 'irlv', 'irnsw', 'iucrn', 'iyrc', 'pirnw', 'ivdn', 'ixni', 'airq', 'ifrqn', 'jvrn', 'srk', 'hran', 'igrnd', 'gisn', 'vilrn', 'ssrn', 'wun', 'zvn', 'inwn', 'girnl', 'iornq', 'igrnh', 'zirx', 'trni', 'ibrxn', 'tibrn', 'ihrkn', 'ccirn', 'cirwn', 'pra', 'imzrn', 'qirpn', 'ihnn', 'ihzn', 'mmirn', 'iyarn', 'irncb', 'njirn', 'injr', 'jikn', 'iprnn', 'inrun', 'irwu', 'hirnz', 'irvnw', 'inxrn', 'airpn', 'pibn', 'ija', 'irjtn', 'irnze', 'irnqi', 'isrf', 'inin', 'iukn', 'xrjn', 'qran', 'rcrn', 'iwrnl', 'xirpn', 'arnc', 'rra', 'lirx', 'xdirn', 'fyrn', 'ifrhn', 'irnen', 'iarnt', 'lirnp', 'irue', 'irenv', 'izsn', 'inrnf', 'iwre', 'oiprn', 'ixnp', 'ivrz', 'nrnf', 'xiron', 'iypn', 'zirni', 'irhnc', 'ierun', 'irlnf', 'irnlp', 'ixfn', 'xsirn', 'irdnz', 'vrs', 'irgpn', 'cirm', 'fimn', 'zrtn', 'gilrn', 'irrv', 'ihz', 'virny', 'idzrn', 'ttn', 'ffrn', 'yrun', 'erjn', 'rirnh', 'piyrn', 'iarn', 'pir', 'irdgn', 'yirk', 'iesn', 'rirnf', 'irqd', 'iorr', 'prpn', 'ienp', 'mrc', 'irknf', 'wirr', 'iyrns', 'mon', 'iurxn', 'oiurn', 'grzn', 'tidn', 'itrcn', 'ishrn', 'iwrb', 'cirv', 'vrnx', 'girno', 'airmn', 'izy', 'ircnb', 'jijrn', 'qmrn', 'hrh', 'iva', 'nlrn', 'urkn', 'wrns', 'zirk', 'iffn', 'fimrn', 'ezirn', 'icrz', 'uijn', 'irbnq', 'xrvn', 'jirbn', 'vrpn', 'irwnp', 'wrbn', 'vmirn', 'izlrn', 'ishn', 'iynf', 'iqon', 'ryirn', 'sivrn', 'iqns', 'diyrn', 'dvirn', 'drk', 'rirnt', 'lvirn', 'pirm', 'sron', 'iwyn', 'iaxrn', 'dgn', 'iqjn', 'jr', 'imnn', 'kirin', 'vikrn', 'fro', 'inron', 'ivne', 'jri', 'irgng', 'birrn', 'gun', 'irvno', 'idrnr', 'qivrn', 'idnp', 'iezn', 'iroxn', 'irnzz', 'mrqn', 'idj', 'irrf', 'qrw', 'virna', 'isrny', 'irnam', 'rrl', 'iryrn', 'igtn', 'srqn', 'frnn', 'iyyn', 'kvirn', 'ieo', 'amrn', 'kr', 'idnk', 'qrnx', 'imrbn', 'iwurn', 'irfk', 'uirg', 'ilrjn', 'uiru', 'irxnk', 'qiron', 'frc', 'inri', 'ury', 'orp', 'ieri', 'narn', 'ifrnc', 'nurn', 'zlirn', 'jxrn', 'iprnq', 'lrp', 'ixh', 'irwvn', 'ckn', 'jirv', 'irenw', 'irrrn', 'ixrno', 'iht', 'zitrn', 'isgn', 'mird', 'rig', 'cqirn', 'hirc', 'iwrnd', 'liarn', 'krnr', 'iqhrn', 'viurn', 'litn', 'asirn', 'icorn', 'rirsn', 'rirnl', 'riln', 'irgt', 'rz', 'lry', 'kirng', 'vrno', 'xirv', 'irdw', 'irznm', 'trnu', 'niri', 'kibrn', 'ireg', 'drnm', 'irsnd', 'irund', 'iew', 'imre', 'rirvn', 'grn', 'irinr', 'ihrfn', 'irob', 'azn', 'iuc', 'ize', 'irvna', 'giron', 'iruf', 'sirsn', 'ired', 'ihrg', 'kirtn', 'xkirn', 'virsn', 'ibrnl', 'ifrs', 'irhon', 'inqr', 'iprsn', 'hryn', 'ijon', 'pign', 'idren', 'irznf', 'zrnc', 'tirh', 'aun', 'kirbn', 'irmun', 'idtrn', 'irbnh', 'airbn', 'ibnrn', 'ipurn', 'irlqn', 'osirn', 'girj', 'prqn', 'irdp', 'kirns', 'arnf', 'ykirn', 'ecrn', 'irnku', 'igrt', 'iwrno', 'iurnt', 'krnh', 'gizrn', 'wiren', 'iqren', 'iqzrn', 'ciurn', 'irsnq', 'irnff', 'iren', 'dirmn', 'cicrn', 'hirnt', 'crnf', 'iyrnt', 'igrmn', 'iragn', 'aicrn', 'lrv', 'jilrn', 'irvvn', 'mirz', 'irhx', 'rirnw', 'trnl', 'idnf', 'iygrn', 'isryn', 'zru', 'imrc', 'jrirn', 'irngb', 'irae', 'virc', 'irnrw', 'girnu', 'itnk', 'xrp', 'ierln', 'isrnh', 'siln', 'iredn', 'hirz', 'irnuc', 'isvrn', 'isno', 'iian', 'bdn', 'irng', 'iudn', 'firnm', 'izren', 'icno', 'ikmn', 'siern', 'rarn', 'ibrnn', 'iyrcn', 'ircnp', 'ardn', 'imln', 'irntf', 'girna', 'erhn', 'irzin', 'urz', 'hrfn', 'wro', 'vrfn', 'ybrn', 'idrnl', 'iezrn', 'fiqrn', 'yorn', 'ikhn', 'ivrwn', 'kirkn', 'iuns', 'iwan', 'irndc', 'birnk', 'ikjn', 'irnci', 'ihrnl', 'igrw', 'hmrn', 'zdirn', 'rirnc', 'yiqrn', 'jirjn', 'idrpn', 'birnb', 'oicrn', 'widrn', 'nrdn', 'abrn', 'icbrn', 'isran', 'iruna', 'iwren', 'irnfz', 'wiern', 'igna', 'iml', 'grnp', 'oirqn', 'vrb', 'jimn', 'qinn', 'ifrbn', 'krirn', 'airhn', 'ilnw', 'ivp', 'iora', 'airy', 'mirr', 'siru', 'trln', 'irfs', 'irnlo', 'yiry', 'birnh', 'kinn', 'zrf', 'iup', 'irhl', 'ixsn', 'irmjn', 'irnvr', 'oirbn', 'iyx', 'ihni', 'irnvs', 'nirne', 'irnjx', 'firbn', 'ivnj', 'wiyn', 'inrr', 'itrs', 'uinr', 'irdxn', 'uvirn', 'urq', 'airnk', 'hr', 'iprz', 'ilmn', 'iang', 'zirv', 'ignc', 'irnoi', 'irul', 'cirxn', 'zirb', 'irucn', 'iwrns', 'izt', 'rrwn', 'icrxn', 'igm', 'zirny', 'irivn', 'ifpn', 'irfzn', 'irnxg', 'grnb', 'hikrn', 'zrdn', 'isnx', 'isb', 'jirk', 'egrn', 'cibn', 'irenu', 'fidn', 'rirwn', 'irknz', 'bitrn', 'pirjn', 'ievrn', 'urxn', 'mbn', 'iign', 'wtirn', 'irnxz', 'ixkn', 'lhirn', 'kigrn', 'brx', 'dirno', 'bmrn', 'icrm', 'xkrn', 'nirnj', 'lzn', 'firny', 'iruhn', 'ejn', 'dirnm', 'orzn', 'inrnb', 'iyrz', 'xrns', 'fprn', 'srun', 'ikrx', 'yrne', 'irnh', 'irnbq', 'xrj', 'wwirn', 'mairn', 'irjp', 'mirp', 'nird', 'firc', 'uorn', 'grqn', 'idrno', 'lrg', 'irdsn', 'jwrn', 'irkkn', 'irnsc', 'trh', 'firnb', 'idra', 'irbmn', 'iwrrn', 'ivrnr', 'irkfn', 'irnfk', 'srnp', 'vcn', 'iozn', 'dcirn', 'iwn', 'irajn', 'ihro', 'irmnt', 'ilrnh', 'girnw', 'fiqn', 'drno', 'irht', 'grm', 'cgrn', 'iring', 'irgu', 'erirn', 'wirb', 'inmn', 'pihrn', 'wbrn', 'irxk', 'qrg', 'ervn', 'krx', 'cdn', 'iwrkn', 'birjn', 'iha', 'igq', 'irten', 'ifnh', 'sirq', 'nirnu', 'iznrn', 'igrxn', 'iuri', 'drnt', 'girb', 'iryz', 'iggrn', 'qqrn', 'ibs', 'virln', 'iqrnd', 'dern', 'irlsn', 'icirn', 'oire', 'zirxn', 'qjirn', 'sirnf', 'irnwz', 'ivvrn', 'rirnz', 'nrwn', 'tisrn', 'imro', 'oan', 'imrxn', 'itqrn', 'aizn', 'nirjn', 'igrnj', 'mirm', 'pirwn', 'miun', 'srnc', 'fijn', 'eizn', 'igrh', 'ilrln', 'icnm', 'iryl', 'irhvn', 'grd', 'ifp', 'qirdn', 'irtt', 'cr', 'jirny', 'ilron', 'irimn', 'irsx', 'wirny', 'cmn', 'icln', 'iqn', 'irton', 'irnph', 'iedrn', 'risn', 'irvs', 'izrkn', 'virdn', 'dirs', 'vhrn', 'diun', 'frn', 'inf', 'sirnx', 'irsmn', 'iruh', 'irxrn', 'znr', 'akn', 'ixrnc', 'irnko', 'ipjn', 'ikni', 'irnng', 'srbn', 'ikorn', 'nun', 'mirnh', 'iirmn', 'iycn', 'irva', 'qirnf', 'wrng', 'isro', 'vin', 'birw', 'inrdn', 'iyrv', 'loirn', 'ipnh', 'ihq', 'gdn', 'virnr', 'jircn', 'ipnl', 'ireon', 'irlp', 'lrl', 'srdn', 'iohrn', 'iqrnn', 'jirn', 'xirxn', 'frk', 'xrg', 'on', 'ihrsn', 'irgd', 'cifrn', 'irjv', 'ydn', 'brw', 'lrmn', 'irggn', 'iurr', 'ilrxn', 'ibns', 'irntd', 'ixrna', 'qiern', 'dirwn', 'iriyn', 'ndirn', 'dzirn', 'irnhy', 'ijrun', 'irmrn', 'ihrno', 'ydrn', 'idrnh', 'zirbn', 'bre', 'inrb', 'ijrsn', 'lro', 'iqp', 'ireng', 'qro', 'icrkn', 'ihrk', 'idf', 'ifrng', 'nign', 'pfirn', 'ihrns', 'iwrpn', 'iunrn', 'miwrn', 'inyr', 'zrnk', 'iefn', 'ifan', 'irnla', 'irtun', 'ifsn', 'eipn', 'itlrn', 'krkn', 'iorng', 'irndg', 'sinrn', 'srhn', 'qrtn', 'fcirn', 'irnaq', 'innv', 'iubn', 'rsirn', 'vrnq', 'ygn', 'nyn', 'jign', 'ityrn', 'frkn', 'ipgrn', 'iyhrn', 'irpa', 'dire', 'iwrj', 'irqln', 'iaan', 'rnf', 'ixrnv', 'irkna', 'irfin', 'frp', 'ilsrn', 'oirkn', 'iomrn', 'iok', 'ilrc', 'ptirn', 'nfirn', 'irdun', 'innh', 'tirbn', 'irxcn', 'ibnm', 'irxi', 'jrin', 'irnca', 'iwrd', 'rrs', 'frgn', 'kcrn', 'glirn', 'himn', 'wjrn', 'ru', 'iqny', 'imrnf', 'ailrn', 'irdt', 'icrp', 'iyd', 'pxrn', 'viri', 'ihne', 'mirnu', 'tiin', 'kfn', 'tien', 'qicrn', 'ibnw', 'zrln', 'hisn', 'irqnb', 'hrtn', 'ingn', 'vuirn', 'iraj', 'birgn', 'irken', 'gbn', 'irgns', 'rro', 'ijrni', 'rru', 'isqrn', 'gsrn', 'zirnx', 'irpo', 'sran', 'ivrnv', 'xxn', 'arv', 'zhirn', 'irnzq', 'iink', 'ixu', 'lrn', 'girnj', 'eiirn', 'gird', 'mdn', 'jrgn', 'zren', 'irbpn', 'irib', 'grhn', 'firf', 'itmrn', 'uln', 'ictn', 'kirun', 'airvn', 'inrs', 'irdnn', 'ziqrn', 'aion', 'himrn', 'voirn', 'rrnn', 'irisn', 'ipnv', 'yrzn', 'ikrnk', 'uiern', 'irnkh', 'ibrna', 'hrn', 'orpn', 'irsnm', 'pirni', 'xijrn', 'ybn', 'ircgn', 'ibrf', 'irbni', 'krpn', 'tirnh', 'wrni', 'can', 'ixzn', 'ijrmn', 'qiru', 'ivfn', 'ikrny', 'qilrn', 'iax', 'irsw', 'mzirn', 'imjrn', 'bru', 'igbn', 'inrnq', 'ihrnt', 'mzrn', 'idirn', 'son', 'rrm', 'eixrn', 'uiyrn', 'iqnx', 'irnps', 'ywn', 'jrw', 'iery', 'nirin', 'irnbj', 'vrnl', 'vrq', 'irntx', 'igni', 'nmrn', 'erkn', 'irpx', 'hiqn', 'igrpn', 'ikc', 'irgv', 'qrmn', 'iernx', 'lrc', 'crmn', 'uiwn', 'xvrn', 'uiarn', 'ionk', 'uyirn', 'fwn', 'itk', 'mqn', 'iprk', 'ircan', 'vxrn', 'iyrqn', 'yifrn', 'orc', 'prnr', 'ouirn', 'ilc', 'iaxn', 'obirn', 'yrv', 'iwd', 'odirn', 'tisn', 'limn', 'iqrxn', 'ixru', 'frrn', 'irwnw', 'srnt', 'iqe', 'ifrnf', 'iremn', 'izn', 'ionn', 'ig', 'iknf', 'rizrn', 'ircf', 'ixrnb', 'irdnr', 'ircj', 'irnkk', 'ilqrn', 'iyrt', 'jrng', 'lir', 'ikkn', 'ernh', 'zre', 'iytn', 'isjrn', 'turn', 'pvirn', 'fkirn', 'brc', 'ihnb', 'dirnc', 'pvrn', 'sisrn', 'birfn', 'oran', 'vrhn', 'bcirn', 'ipl', 'gqn', 'ircvn', 'firl', 'ilxrn', 'irqtn', 'iuro', 'nrtn', 'iav', 'yrwn', 'idnz', 'aiqn', 'xcirn', 'xrkn', 'iavrn', 'irknv', 'ihnk', 'jkirn', 'pbn', 'zrnw', 'irqf', 'oirxn', 'prg', 'iyrf', 'ordn', 'nzrn', 'kiron', 'oqn', 'irww', 'vibrn', 'cimrn', 'eri', 'rijrn', 'eon', 'nijn', 'ivb', 'irku', 'immrn', 'dr', 'irmm', 'iifrn', 'bire', 'zrl', 'irdzn', 'grxn', 'irks', 'eiran', 'airu', 'brn', 'wrsn', 'arnu', 'diurn', 'iirv', 'inrnl', 'isurn', 'irznp', 'ijnb', 'ilxn', 'wiro', 'cpirn', 'irjnm', 'inun', 'irsb', 'tirnq', 'irxmn', 'ibl', 'qimrn', 'yicn', 'tuirn', 'yiron', 'irthn', 'irxj', 'irffn', 'idlrn', 'irnhu', 'jivrn', 'ireun', 'icrni', 'ilf', 'iirw', 'srs', 'irynz', 'irynv', 'arnm', 'pirnu', 'lijrn', 'citn', 'idtn', 'trnf', 'iyrn', 'dirq', 'ijern', 'imb', 'ifrnk', 'illn', 'icnrn', 'curn', 'trdn', 'iif', 'ivrnu', 'ierk', 'xiwrn', 'irntu', 'yirsn', 'ibin', 'icnj', 'ibvrn', 'gicn', 'jdrn', 'cfirn', 'mibn', 'irnmy', 'qirun', 'ifrsn', 'irkng', 'iean', 'murn', 'zrnu', 'irnyz', 'irncw', 'ijrng', 'ichn', 'xrnq', 'iroi', 'irwg', 'wirk', 'imun', 'wrnv', 'irvhn', 'krne', 'ipp', 'lpirn', 'irnuu', 'ist', 'iof', 'inren', 'icfn', 'ihrxn', 'nirn', 'ciwn', 'dbirn', 'lirnz', 'irjwn', 'wri', 'nrp', 'igrdn', 'szn', 'sirjn', 'ivkrn', 'yiryn', 'irneh', 'miurn', 'trfn', 'ndrn', 'tsn', 'tarn', 'iirnw', 'rbn', 'bidn', 'irqe', 'brnw', 'ifrj', 'wrnm', 'cirnp', 'rnrn', 'irlns', 'ier', 'finrn', 'irohn', 'irrdn', 'vyrn', 'iirj', 'cirk', 'lirnj', 'lyn', 'jirnf', 'ihnu', 'urnj', 'tln', 'imrkn', 'tirm', 'qrnr', 'frnm', 'nrnp', 'cion', 'wrdn', 'ierfn', 'xinn', 'nirfn', 'sirm', 'irnwi', 'sinn', 'gr', 'livn', 'itpn', 'brsn', 'iyri', 'zro', 'orj', 'iark', 'iorkn', 'gkn', 'xirq', 'iwqrn', 'ixrqn', 'itnw', 'eirwn', 'firn', 'igrfn', 'rkin', 'irse', 'ikrt', 'irfcn', 'qirno', 'ionj', 'irzr', 'irjnl', 'irwny', 'izno', 'orna', 'irkan', 'utrn', 'jre', 'iuj', 'iwgrn', 'tiirn', 'ihrvn', 'ldirn', 'crny', 'erj', 'hrny', 'eyrn', 'ircin', 'ixnv', 'idzn', 'yicrn', 'mern', 'irnii', 'jeirn', 'niyn', 'iqry', 'inrt', 'iwrcn', 'midn', 'ifrgn', 'ilrnj', 'gqrn', 'gimrn', 'irngz', 'irnft', 'ibhn', 'vrnb', 'airxn', 'ykrn', 'lian', 'ilrnv', 'rian', 'iprzn', 'gihrn', 'sixn', 'igra', 'irnun', 'irmg', 'eirno', 'irvon', 'ornm', 'iknu', 'jtirn', 'iryjn', 'virin', 'irss', 'jmn', 'irkx', 'irrs', 'xitn', 'ioxrn', 'irbv', 'ibrjn', 'grne', 'idan', 'ibron', 'ivrc', 'xiarn', 'inmr', 'crun', 'zrx', 'qxn', 'ipmn', 'iftn', 'eirx', 'firtn', 'un', 'qimn', 'urvn', 'irzd', 'irsnx', 'irhnp', 'iub', 'hisrn', 'xrnh', 'irvmn', 'iraun', 'ihrn', 'iae', 'jira', 'dirt', 'qirs', 'urnc', 'miarn', 'pry', 'ixv', 'ijcrn', 'xrun', 'ierp', 'eibrn', 'yirnq', 'prin', 'irnxc', 'irnsf', 'iurk', 'idrb', 'ydirn', 'sirv', 'qgirn', 'irsnc', 'frb', 'vvrn', 'irmz', 'gtirn', 'irlgn', 'dqrn', 'nhrn', 'imrsn', 'iornc', 'ifrnt', 'kirnc', 'uri', 'ihe', 'mirnl', 'grns', 'prnm', 'pgn', 'inrwn', 'dizrn', 'irfan', 'isl', 'hrg', 'ivrqn', 'pkn', 'lrkn', 'ifnb', 'lirgn', 'uirmn', 'ixrln', 'sru', 'it', 'zrjn', 'ivdrn', 'rw', 'nirkn', 'ourn', 'irth', 'toirn', 'iinf', 'cirnw', 'tru', 'nen', 'yrny', 'igern', 'iwtn', 'iergn', 'itxrn', 'iinb', 'iknv', 'ixny', 'iodrn', 'cidn', 'rink', 'iqfn', 'irnrs', 'ijzn', 'iiro', 'oirnl', 'ikrrn', 'zircn', 'tixrn', 'wrv', 'trnj', 'ihns', 'qsn', 'ihrnv', 'nirg', 'icrh', 'irbwn', 'hirbn', 'frnk', 'mirv', 'ijnd', 'iranw', 'irtk', 'eiyn', 'iwrv', 'isrs', 'lirni', 'iornu', 'jiro', 'irvi', 'irgx', 'irnol', 'iihn', 'lixrn', 'jtn', 'man', 'ieny', 'ziln', 'urnp', 'kkirn', 'idkrn', 'iaarn', 'imrne', 'qizrn', 'irnsz', 'ikrbn', 'crkn', 'arf', 'kiarn', 'tira', 'iarb', 'wijn', 'iel', 'eiren', 'mirnt', 'ieern', 'uirnp', 'irzg', 'xnrn', 'nrnx', 'qbn', 'ikrg', 'iunv', 'firrn', 'firqn', 'irmon', 'tirc', 'dxrn', 'lirk', 'xirtn', 'ixrjn', 'jinn', 'giirn', 'bisrn', 'atirn', 'brnc', 'lfrn', 'zihrn', 'swrn', 'iriw', 'irqne', 'yrk', 'izry', 'sirnq', 'prnf', 'irnac', 'ibng', 'kin', 'ignk', 'irprn', 'irlm', 'cvirn', 'tirqn', 'iborn', 'irknb', 'ilrq', 'uiro', 'kkrn', 'irvnk', 'yiorn', 'zrk', 'ixnr', 'eidn', 'icry', 'iyrtn', 'ryrn', 'irxa', 'idnc', 'rairn', 'kre', 'mirna', 'prt', 'eirns', 'ftirn', 'prnp', 'dnrn', 'wifn', 'irdng', 'ief', 'izrng', 'jrl', 'itrgn', 'tlirn', 'girc', 'utirn', 'pnrn', 'ernk', 'kird', 'siorn', 'xrnj', 'ioj', 'ieqrn', 'ivnh', 'cnr', 'izgrn', 'ghrn', 'irntv', 'brnd', 'rrgn', 'irsxn', 'isnk', 'drn', 'isrd', 'ximn', 'ixo', 'ifxrn', 'nprn', 'irnpr', 'grj', 'erng', 'ilnf', 'urf', 'srfn', 'urng', 'iirbn', 'ipf', 'zirnv', 'yrhn', 'xrnf', 'igrtn', 'vlrn', 'xirsn', 'mrd', 'ioq', 'irjc', 'irgfn', 'iqrj', 'rkirn', 'ixrnm', 'irnep', 'izns', 'irsl', 'iyrgn', 'kirxn', 'pirnp', 'miryn', 'tirng', 'diren', 'nrxn', 'girnm', 'izprn', 'iznf', 'irnyl', 'rrtn', 'gira', 'imrl', 'irnpa', 'sirp', 'lirnv', 'zra', 'ijs', 'liryn', 'igp', 'ifqn', 'irvw', 'iwhn', 'oimn', 'ftn', 'oikrn', 'imnb', 'dirm', 'pren', 'irbe', 'oidrn', 'firnt', 'ihwrn', 'exrn', 'inur', 'ttirn', 'iyng', 'rhin', 'ikrun', 'gircn', 'rirhn', 'iwnrn', 'ibjn', 'icrnr', 'hrzn', 'irodn', 'uirnu', 'fifrn', 'irwkn', 'jirnm', 'lirnn', 'iqrnj', 'bhrn', 'mrp', 'ihxn', 'iryng', 'irio', 'iernj', 'urk', 'vgirn', 'frr', 'iya', 'dgirn', 'ord', 'iyb', 'wairn', 'hfirn', 'iyrng', 'dirnl', 'ixrni', 'ieron', 'ivgn', 'hirp', 'airnb', 'brdn', 'jiirn', 'vrn', 'crc', 'ixro', 'bcrn', 'prz', 'tirp', 'oirsn', 'rrirn', 'ironq', 'ijkn', 'iprnx', 'cyirn', 'ibnr', 'xfirn', 'ijrnh', 'blrn', 'firvn', 'ijn', 'yr', 'ifwrn', 'irkp', 'iofn', 'emrn', 'iqx', 'ijnh', 'biyn', 'ifvn', 'urne', 'ijbrn', 'irpan', 'ilrw', 'irgyn', 'ivrnk', 'iryv', 'hijrn', 'bro', 'imrin', 'qirnn', 'ioz', 'xirwn', 'kirnm', 'erne', 'frnp', 'xiro', 'wirrn', 'eqn', 'tr', 'fnr', 'srnw', 'mion', 'lirfn', 'irlnu', 'jhirn', 'iwrng', 'irqgn', 'icrc', 'fidrn', 'irnnd', 'hrwn', 'ivwn', 'oird', 'idrnw', 'ernl', 'nrnd', 'nre', 'qrun', 'vqrn', 'ibrwn', 'rv', 'irpsn', 'iqrnw', 'iera', 'irqni', 'kern', 'xircn', 'ivmrn', 'oian', 'irnyg', 'irzi', 'ix', 'fian', 'ifnl', 'yrqn', 'grnc', 'ide', 'idz', 'qhirn', 'misrn', 'irvb', 'irtnj', 'iirf', 'xoirn', 'rrz', 'irfj', 'virz', 'kirnb', 'itfrn', 'hrm', 'iyrdn', 'nern', 'irnbh', 'airng', 'frnu', 'ibnn', 'hitrn', 'fcn', 'irqns', 'birh', 'ivrt', 'iecrn', 'wirhn', 'xiurn', 'corn', 'udrn', 'iqnj', 'ignt', 'irvnm', 'isra', 'pifn', 'icnc', 'qirnk', 'grh', 'vrnm', 'ifrin', 'ipdn', 'tzn', 'chn', 'irnes', 'trtn', 'ihnh', 'epirn', 'irnlk', 'iwlrn', 'qrm', 'ficrn', 'xrz', 'yxn', 'ifs', 'irjna', 'urnm', 'iau', 'fiyn', 'nirno', 'iuno', 'ipkn', 'ixxn', 'oirnj', 'iirq', 'yirnt', 'tprn', 'inkr', 'qrf', 'irhdn', 'iurb', 'irozn', 'sfirn', 'brun', 'uirx', 'lrin', 'eirni', 'zirnq', 'virne', 'sird', 'sirnj', 'xipn', 'irnr', 'iwrnz', 'tiurn', 'iusrn', 'zrnl', 'eiarn', 'incrn', 'irhs', 'iourn', 'uirt', 'ikdn', 'iort', 'svn', 'men', 'esrn', 'eirz', 'rirs', 'iymn', 'iruy', 'irypn', 'asrn', 'gimn', 'nxrn', 'isorn', 'qian', 'iinr', 'ijnx', 'drnd', 'wrd', 'ijmn', 'grnq', 'inln', 'iti', 'zkn', 'xan', 'rbrn', 'rit', 'iras', 'qrnt', 'iys', 'uimn', 'iroen', 'irnjv', 'xrnt', 'irgnm', 'yhrn', 'irye', 'jiln', 'irws', 'irmnv', 'iriz', 'avrn', 'hirhn', 'iurnx', 'yfirn', 'irwpn', 'kirwn', 'yiarn', 'wlirn', 'arne', 'srmn', 'viwrn', 'cird', 'uxirn', 'rlirn', 'irhun', 'xru', 'ixhrn', 'irko', 'wrc', 'eitn', 'irwv', 'ernp', 'ulirn', 'ilnb', 'inrtn', 'ibun', 'zirln', 'iard', 'ismn', 'izrfn', 'kzirn', 'xirin', 'ivjrn', 'oign', 'jizrn', 'cirl', 'xikrn', 'irekn', 'zirnw', 'ikgn', 'kry', 'irnzx', 'irhnt', 'irzs', 'nbirn', 'irgnh', 'sirg', 'gien', 'ihnz', 'prnb', 'inrn', 'rrw', 'ieqn', 'deirn', 'irni', 'uirnb', 'ohn', 'wirun', 'ijry', 'kurn', 'iorbn', 'iqnz', 'ibnj', 'fan', 'jhrn', 'iwrni', 'xilrn', 'eiqn', 'rm', 'wrvn', 'irkbn', 'oifn', 'ignn', 'orxn', 'irynk', 'igrny', 'edrn', 'gign', 'wrirn', 'brnx', 'rrx', 'trmn', 'rjin', 'vyirn', 'gpirn', 'rren', 'ipnr', 'inrc', 'ilrdn', 'ivrhn', 'iryno', 'irmhn', 'ijrnl', 'oirpn', 'fhrn', 'erns', 'ilrnw', 'prdn', 'irwon', 'ioe', 'zirnc', 'artn', 'ohrn', 'hifn', 'iinx', 'iynx', 'nwirn', 'irnx', 'iorl', 'frng', 'iricn', 'art', 'iany', 'ibt', 'siun', 'irvtn', 'vn', 'urnt', 'tdrn', 'iki', 'jsrn', 'itrd', 'imtn', 'firy', 'xrnz', 'iyrxn', 'irkv', 'irxnz', 'jiyn', 'izrhn', 'srnf', 'iornr', 'girnt', 'itl', 'irndy', 'drxn', 'evn', 'mgirn', 'vnrn', 'nrg', 'rimrn', 'xirjn', 'irzh', 'irdnx', 'izrnb', 'icran', 'iso', 'ibrm', 'ilbrn', 'iin', 'iarpn', 'iranj', 'qrwn', 'isw', 'tiqrn', 'vrf', 'irdtn', 'wirno', 'imrnr', 'aisrn', 'iync', 'inrnk', 'airzn', 'ctn', 'izgn', 'drnv', 'aiurn', 'ibry', 'akirn', 'cwirn', 'xirp', 'irxnc', 'inrv', 'ircr', 'oirnr', 'ixren', 'tirs', 'yign', 'peirn', 'ircq', 'itqn', 'ixy', 'eirkn', 'riqrn', 'irtl', 'yiprn', 'ornz', 'irncg', 'idrk', 'irnhp', 'ihrng', 'ilny', 'iwrtn', 'imd', 'iwbrn', 'jfrn', 'ifnr', 'irnmu', 'xirnn', 'krtn', 'xigrn', 'izrnm', 'urnl', 'cxn', 'frny', 'iwny', 'irnoy', 'niwn', 'irwnn', 'izu', 'uwirn', 'irlg', 'irrbn', 'ihgrn', 'frsn', 'ifrvn', 'rwirn', 'ibx', 'idng', 'iroon', 'tvrn', 'irnpu', 'irvnv', 'irbtn', 'rinn', 'iird', 'imrd', 'linr', 'kicrn', 'qzn', 'yirne', 'ierm', 'jiryn', 'irzn', 'virno', 'irnai', 'irnwm', 'gfn', 'iov', 'irpwn', 'aren', 'urs', 'birnq', 'vrnu', 'qrr', 'iorqn', 'qren', 'ijre', 'yihn', 'izrw', 'erk', 'irngp', 'lirdn', 'ijqn', 'ips', 'irdbn', 'zrvn', 'irnbb', 'izyrn', 'bzirn', 'ijg', 'prny', 'izjrn', 'irnoc', 'zirng', 'irynd', 'irvng', 'xgrn', 'xirfn', 'nirnl', 'irnu', 'ironu', 'arng', 'isrna', 'ihrr', 'lrirn', 'ijrnt', 'irynx', 'qurn', 'itrf', 'iden', 'plrn', 'zsrn', 'irsnz', 'kiqrn', 'iunw', 'irgln', 'xyn', 'iurnb', 'bron', 'irnxk', 'uikn', 'ilb', 'irnuz', 'iarp', 'izbrn', 'iysrn', 'iurnw', 'iursn', 'cun', 'icrnj', 'iwb', 'kirp', 'divn', 'jurn', 'acirn', 'mqrn', 'izqn', 'sqrn', 'lcn', 'iwru', 'erm', 'irqrn', 'irxu', 'irbun', 'zuirn', 'iga', 'irngt', 'irxns', 'wijrn', 'prm', 'ionq', 'isne', 'fien', 'fdrn', 'imcn', 'mirnr', 'uun', 'wira', 'mirmn', 'ine', 'ajrn', 'iitrn', 'iwwrn', 'trna', 'mrln', 'ihmrn', 'trsn', 'irncc', 'ikrwn', 'lirin', 'iyne', 'irunb', 'csrn', 'irgb', 'kxn', 'iwz', 'iuyrn', 'irrnx', 'ticn', 'vimn', 'iina', 'firw', 'ibwrn', 'biorn', 'itprn', 'iprnp', 'isrsn', 'irvf', 'iyrnh', 'wru', 'izrun', 'yzirn', 'kprn', 'zirf', 'irhan', 'iqrnu', 'qicn', 'iornt', 'idc', 'trns', 'iokn', 'iqrm', 'irwan', 'wivn', 'iqg', 'iyrnb', 'ibwn', 'ivrnn', 'icnp', 'yrmn', 'uirnx', 'xrnp', 'biran', 'hrnd', 'inn', 'ixnq', 'irne', 'ircd', 'ifrna', 'iryne', 'iresn', 'imru', 'erp', 'iran', 'ginr', 'lrw', 'xbirn', 'ib', 'irvnh', 'irngj', 'vvirn', 'itd', 'akrn', 'eirnm', 'ukn', 'irnbz', 'ibrnq', 'aixrn', 'yird', 'ikn', 'kzn', 'ireb', 'ril', 'fru', 'ipen', 'hirrn', 'fgn', 'inw', 'qiry', 'kfrn', 'qvn', 'eira', 'irom', 'ojrn', 'iucn', 'trnq', 'krj', 'pircn', 'ieen', 'xibrn', 'ipc', 'yitn', 'wiry', 'iroq', 'irnvt', 'rhrn', 'vry', 'irqt', 'irlhn', 'irngv', 'diprn', 'imnz', 'irgsn', 'cirnu', 'rrpn', 'airnx', 'wirjn', 'birq', 'irzbn', 'ilrg', 'vkirn', 'isrin', 'irexn', 'viqn', 'eirna', 'prhn', 'wrmn', 'qirb', 'ibrnt', 'qirtn', 'idt', 'ifrf', 'ioran', 'mrpn', 'itrg', 'virmn', 'irxhn', 'zln', 'eirpn', 'idrx', 'ifgrn', 'iurj', 'irbnc', 'ilrnl', 'ixmrn', 'nidn', 'ehn', 'irsen', 'ibyrn', 'yiwrn', 'prln', 'iap', 'ich', 'ibxn', 'brns', 'irky', 'inrnu', 'iib', 'irvnl', 'qiro', 'hiro', 'ibsn', 'uen', 'irzz', 'uigrn', 'airz', 'irag', 'irgxn', 'abn', 'ijrnp', 'ifrv', 'iwrt', 'yrf', 'igdn', 'ircp', 'rnx', 'frnt', 'irtna', 'minr', 'iornk', 'ixrh', 'itnp', 'itrln', 'irnyd', 'hkrn', 'zrni', 'qrnb', 'birg', 'rcin', 'vln', 'qiin', 'nrv', 'iyrd', 'rix', 'xirz', 'irhv', 'ijng', 'brne', 'oirne', 'iryen', 'ibdn', 'ihx', 'wirs', 'igre', 'iernz', 'irnhh', 'nsn', 'izdrn', 'yirqn', 'inrl', 'sjrn', 'irnfc', 'izrnc', 'hyn', 'irjs', 'iutn', 'irgi', 'irux', 'kirk', 'qibn', 'iwl', 'irona', 'ixf', 'inra', 'wyrn', 'ijvrn', 'irfnl', 'iyo', 'fin', 'wirnf', 'prnd', 'irsf', 'ium', 'irync', 'irnha', 'cirmn', 'yidn', 'hirx', 'irbnt', 'imx', 'tnirn', 'iqgn', 'ibrnc', 'irnlz', 'ivrnf', 'sbrn', 'irrnq', 'ywrn', 'yrc', 'nrkn', 'nikn', 'wirnu', 'wisrn', 'imnu', 'irnqq', 'igi', 'uirwn', 'ixrz', 'imr', 'irju', 'irnbu', 'arno', 'uircn', 'virg', 'izh', 'irakn', 'irnls', 'rrnd', 'idne', 'iyrp', 'irtpn', 'urw', 'niran', 'krs', 'irgzn', 'iruin', 'irynq', 'inrnd', 'iwran', 'ieq', 'irdwn', 'sijn', 'xirln', 'qiurn', 'ors', 'iprb', 'idny', 'ioy', 'iruz', 'drtn', 'qird', 'vikn', 'isfrn', 'ibb', 'irunj', 'irqb', 'uirxn', 'ijnm', 'inrp', 'iornw', 'jvirn', 'vwrn', 'birno', 'irdan', 'dirnq', 'irnud', 'rirdn', 'ihrnx', 'igrno', 'irln', 'iwrnb', 'lrb', 'ianf', 'jitn', 'idrgn', 'slrn', 'soirn', 'iirns', 'lfn', 'trnm', 'iirt', 'iornz', 'ivurn', 'inran', 'xry', 'rfrn', 'irgw', 'iruu', 'firsn', 'fiurn', 'uirnq', 'zrw', 'mirdn', 'irmzn', 'igrg', 'imprn', 'ifx', 'irhns', 'brxn', 'rryn', 'ijru', 'eirin', 'irnlh', 'iiryn', 'ifrnp', 'oirw', 'ilni', 'ivrr', 'hihn', 'ieln', 'ijrxn', 'iqtn', 'iysn', 'ibny', 'iqrr', 'iqo', 'iqsrn', 'itrnq', 'eorn', 'cry', 'bmirn', 'aifn', 'irqno', 'itern', 'brnh', 'iornx', 'mro', 'ipbn', 'hcrn', 'xirn', 'tjn', 'itrq', 'iytrn', 'izjn', 'rrhn', 'ikqrn', 'didrn', 'ibrd', 'bsn', 'birqn', 'inlr', 'iqjrn', 'jirf', 'ikru', 'jrsn', 'orcn', 'iunt', 'iygn', 'irnm', 'ivnt', 'irxm', 'rrk', 'irwzn', 'irmin', 'irgun', 'ikrl', 'icren', 'xnr', 'iryqn', 'ivln', 'mihrn', 'klirn', 'irnpd', 'ikrnp', 'ycirn', 'izmrn', 'ivrq', 'aisn', 'iura', 'birns', 'igun', 'niun', 'bin', 'iwwn', 'virkn', 'uiqrn', 'its', 'brs', 'birnl', 'ikrcn', 'irr', 'iyjrn', 'uijrn', 'irnxa', 'lirnw', 'syrn', 'isxn', 'isen', 'irenh', 'izz', 'frqn', 'irinp', 'ixprn', 'rib', 'rdirn', 'iip', 'icyrn', 'iwsn', 'iyln', 'zrm', 'didn', 'nrw', 'mirne', 'ierni', 'vrqn', 'iipn', 'irwp', 'qirz', 'csn', 'fre', 'rnt', 'kijn', 'ilon', 'vhirn', 'iarnx', 'ucirn', 'irk', 'ilk', 'mlrn', 'igprn', 'rie', 'airnt', 'iyni', 'girne', 'xrnr', 'qtrn', 'xbn', 'zrmn', 'cicn', 'jirnd', 'oicn', 'ikrv', 'irkb', 'kivrn', 'hvn', 'wiorn', 'mbirn', 'zigrn', 'pihn', 'zirdn', 'izrxn', 'qjrn', 'yirh', 'rrni', 'irje', 'iryxn', 'uirl', 'yirhn', 'ogrn', 'trx', 'wibn', 'irkhn', 'jrzn', 'urnu', 'bn', 'luirn', 'ixirn', 'ijj', 'aihn', 'iburn', 'ikrf', 'wrr', 'ivsrn', 'woirn', 'zrnj', 'kirhn', 'imern', 'ifrk', 'gijn', 'irhnx', 'ierx', 'iy', 'ierwn', 'hrnz', 'iune', 'oitrn', 'lmirn', 'ikyn', 'pbirn', 'ityn', 'circn', 'irbyn', 'lrk', 'irxnr', 'irsnj', 'irxnw', 'jihn', 'irlh', 'nnrn', 'ihhrn', 'irzqn', 'sirc', 'iwj', 'oiwn', 'ibmrn', 'iurnu', 'iswn', 'irkno', 'wfn', 'iurnv', 'wdn', 'ivw', 'imc', 'idcrn', 'gern', 'crrn', 'spirn', 'ithn', 'irnis', 'siirn', 'irnb', 'zrin', 'uhirn', 'irnxl', 'ivrn', 'mirni', 'irxjn', 'iuny', 'ioprn', 'iicn', 'oinn', 'nixrn', 'irafn', 'ifr', 'irnek', 'yran', 'ifjn', 'gran', 'crs', 'xran', 'ygrn', 'iajn', 'airny', 'irmnl', 'itrnm', 'girs', 'lbrn', 'filn', 'xrh', 'skn', 'ibu', 'airnf', 'isrno', 'urcn', 'gro', 'niyrn', 'idni', 'iszrn', 'ibirn', 'iqrnq', 'irnvu', 'tihrn', 'yrln', 'iend', 'qrh', 'ijrnu', 'ihirn', 'iund', 'irzen', 'ixzrn', 'kirnz', 'firan', 'sirmn', 'aeirn', 'ikw', 'xyirn', 'dun', 'rirnj', 'iqrnx', 'hirin', 'iryr', 'iydn', 'irrn', 'ivcn', 'uirns', 'imry', 'tsirn', 'eicn', 'isf', 'ianr', 'lqirn', 'imfrn', 'cbirn', 'uiln', 'iunb', 'irsna', 'ivro', 'lirs', 'qrin', 'dirna', 'izorn', 'irso', 'ryin', 'qwrn', 'clrn', 'hwirn', 'iyrbn', 'iss', 'iegn', 'wrm', 'dri', 'irwnj', 'irnez', 'midrn', 'ireln', 'zidn', 'kiryn', 'cirnl', 'zrn', 'lxirn', 'iturn', 'itro', 'irmk', 'ifnc', 'eiryn', 'qry', 'iqrf', 'xrnc', 'iprj', 'wirnj', 'frnx', 'irngh', 'hrnn', 'birna', 'fvn', 'yidrn', 'ilrsn', 'airm', 'tre', 'irsg', 'srjn', 'irjnt', 'qir', 'pikrn', 'xirnr', 'xirx', 'imxn', 'dairn', 'irxna', 'irasn', 'iryg', 'irntc', 'lira', 'lirq', 'irnyc', 'iyrl', 'lrnf', 'irnuq', 'iirr', 'irqan', 'irron', 'sirnr', 'rirmn', 'idl', 'edn', 'lirne', 'ibe', 'fikrn', 'irrzn', 'yrxn', 'ihern', 'pri', 'njrn', 'nr', 'jirp', 'ircnx', 'iqrbn', 'cirln', 'ircrn', 'nsrn', 'wtrn', 'crl', 'irrg', 'riren', 'irpnx', 'ijrdn', 'rino', 'tirw', 'irndf', 'ivyn', 'irewn', 'ijny', 'aigrn', 'iirnu', 'irjz', 'kiprn', 'pirf', 'ignd', 'arh', 'irwin', 'irkl', 'eiern', 'itw', 'trxn', 'ixc', 'iors', 'yrnk', 'ilrzn', 'irmvn', 'irvqn', 'pirnm', 'irla', 'grq', 'irhnr', 'irgh', 'irknx', 'icrr', 'tzrn', 'irgn', 'idrjn', 'iqqn', 'qru', 'irlpn', 'wirv', 'irfw', 'inrnm', 'ijm', 'ikr', 'srnb', 'irnpn', 'ierf', 'ikz', 'rsn', 'inzn', 'irf', 'iqgrn', 'giyn', 'hry', 'irnuy', 'ioyn', 'iorne', 'imrfn', 'irnsi', 'iarnw', 'ppn', 'rri', 'vrk', 'sibn', 'nitrn', 'ijnu', 'jirnn', 'ipx', 'pinn', 'ucrn', 'aivrn', 'zrny', 'ihpn', 'qrnv', 'inwr', 'yivn', 'iefrn', 'firmn', 'orf', 'xren', 'jiru', 'qifn', 'ireqn', 'drns', 'jirnh', 'irtcn', 'icrna', 'ris', 'mbrn', 'brb', 'yrh', 'vun', 'chrn', 'rirb', 'urg', 'xdn', 'iraa', 'irpny', 'irphn', 'irzna', 'iaryn', 'iqrfn', 'irrm', 'iorsn', 'zijn', 'ibrne', 'qgn', 'srcn', 'icrnc', 'jqrn', 'eirnk', 'inny', 'pre', 'dln', 'ixrnr', 'irjxn', 'rin', 'icin', 'irdyn', 'izrwn', 'rrnx', 'ihqrn', 'nirun', 'kjirn', 'vri', 'irjnr', 'xirr', 'yizn', 'iroe', 'oircn', 'girhn', 'irnbo', 'irein', 'idbrn', 'wirnb', 'oirf', 'arl', 'trirn', 'ict', 'irtz', 'zirnp', 'rnirn', 'pifrn', 'qrx', 'itrnh', 'innu', 'brna', 'itj', 'eigrn', 'ntrn', 'irdny', 'igrc', 'hirnm', 'mnr', 'likn', 'ikrpn', 'airnp', 'irfdn', 'irnbm', 'iyrnf', 'iknm', 'wiln', 'zibn', 'iens', 'ikrnd', 'icrpn', 'imrv', 'iurv', 'wirnq', 'irtno', 'airnr', 'ipqn', 'sirvn', 'igrj', 'bun', 'irnxh', 'iprh', 'iwrqn', 'icrnz', 'cxrn', 'mirnj', 'frun', 'yrdn', 'iyen', 'jikrn', 'usrn', 'krb', 'qirnt', 'irbzn', 'erl', 'mrnl', 'tqn', 'tcrn', 'giwrn', 'firnn', 'isru', 'zirnj', 'brnu', 'brnv', 'airw', 'drc', 'ur', 'iykrn', 'eikrn', 'frns', 'iiri', 'firnr', 'iad', 'crnn', 'zqirn', 'eirv', 'irnqv', 'nivrn', 'hzrn', 'kirno', 'eirg', 'iernr', 'eran', 'ieu', 'iatn', 'zryn', 'swn', 'mign', 'ixen', 'igs', 'innp', 'itnf', 'hion', 'irtgn', 'ibrb', 'crjn', 'iiurn', 'irnmc', 'inyrn', 'zire', 'xirno', 'qrt', 'ibern', 'cirfn', 'ipxrn', 'idnq', 'irmv', 'eihrn', 'gnr', 'airrn', 'wipn', 'ilra', 'iqdn', 'hirtn', 'nirnm', 'irarn', 'ianx', 'iwnx', 'idnm', 'dirhn', 'rdrn', 'yirv', 'iagrn', 'uqn', 'vmn', 'pkrn', 'nrbn', 'irlmn', 'oidn', 'urnv', 'xisrn', 'jrs', 'girxn', 'ixno', 'orwn', 'irhk', 'pisrn', 'krun', 'irnro', 'ifren', 'iuren', 'irlnp', 'jirfn', 'lln', 'irwl', 'mirkn', 'iruvn', 'liirn', 'erw', 'irgnz', 'ibrvn', 'birb', 'izni', 'kiren', 'irnay', 'ifdrn', 'garn', 'frnl', 'irnua', 'nhirn', 'iarjn', 'krnk', 'yiln', 'qirnm', 'vrd', 'iorg', 'wicrn', 'owrn', 'sirni', 'ior', 'firwn', 'uirh', 'sxirn', 'qirnp', 'wiron', 'brwn', 'con', 'qrzn', 'ikrnv', 'vrv', 'isrln', 'bixn', 'hirnb', 'ikkrn', 'qirny', 'irrns', 'urjn', 'irvnp', 'irnw', 'vfrn', 'ixern', 'yrnv', 'fwrn', 'xro', 'lirnc', 'iru', 'irvni', 'izri', 'arnh', 'iini', 'srirn', 'iwni', 'orrn', 'irnyy', 'iarzn', 'whrn', 'qijn', 'irngn', 'imrnj', 'nirnc', 'xirnj', 'irnbt', 'innd', 'ixwrn', 'riurn', 'kisrn', 'irvkn', 'igrnb', 'itrx', 'ifron', 'irlk', 'eqirn', 'girni', 'icrqn', 'nidrn', 'iinw', 'dirln', 'zirjn', 'ibrnz', 'iirn', 'qiqrn', 'ipln', 'ixrd', 'mrzn', 'irbnz', 'irvfn', 'irnyr', 'ixran', 'hirnp', 'hpirn', 'oiron', 'cxirn', 'irnlq', 'krvn', 'iynd', 'zign', 'liin', 'sin', 'jyrn', 'irnox', 'irtng', 'irnnu', 'urpn', 'iwvrn', 'ybirn', 'irnqh', 'oro', 'iod', 'irinw', 'zirin', 'jirnj', 'virqn', 'isan', 'biren', 'girk', 'girnc', 'lirmn', 'sirk', 'isdn', 'iirk', 'trzn', 'igrgn', 'ciwrn', 'jjirn', 'prrn', 'arnx', 'imh', 'iwun', 'ixryn', 'ijrtn', 'piron', 'igan', 'icrnm', 'irnrt', 'dicrn', 'rrt', 'ina', 'irenb', 'yisn', 'irnzg', 'tiqn', 'xen', 'lirw', 'pro', 'irejn', 'tirgn', 'ilnn', 'iiin', 'irxon', 'urr', 'ienf', 'ypn', 'itbrn', 'tra', 'iwrnh', 'iarx', 'irmnw', 'iwrsn', 'ify', 'jorn', 'iobrn', 'ivrs', 'iqan', 'fihn', 'xion', 'nqirn', 'irana', 'licn', 'mln', 'mirrn', 'brd', 'irvns', 'ihl', 'rjn', 'irnva', 'ijw', 'igrn', 'ionb', 'irngw', 'ipnb', 'xiln', 'gren', 'cnrn', 'iret', 'irtq', 'ilrnn', 'diern', 'wrfn', 'isxrn', 'hrr', 'ibrc', 'iqrqn', 'ircc', 'mhrn', 'pwn', 'grnl', 'ligrn', 'dnr', 'icrf', 'zrc', 'lrrn', 'wtn', 'iornj', 'drpn', 'oirr', 'eimrn', 'irxxn', 'izm', 'lrsn', 'irqw', 'qyirn', 'izc', 'iprw', 'stirn', 'girl', 'bnirn', 'eisrn', 'mhn', 'irfln', 'iont', 'irlz', 'fiun', 'irnms', 'mirnq', 'rih', 'airne', 'ixq', 'girz', 'imyn', 'irngr', 'iwcn', 'sirj', 'iqnc', 'xrnx', 'vrsn', 'jihrn', 'irebn', 'rein', 'ixrdn', 'nrpn', 'iwzrn', 'irsyn', 'ipg', 'icw', 'irpjn', 'irkun', 'irpnc', 'krnl', 'fmn', 'irnsh', 'urnn', 'pirnl', 'wrnu', 'irynm', 'jicn', 'iroy', 'irqen', 'gfrn', 'iop', 'girqn', 'irgnr', 'qibrn', 'ihorn', 'nirrn', 'iwrnw', 'ggn', 'igrln', 'irbj', 'gihn', 'nrq', 'jnirn', 'irvm', 'ims', 'liorn', 'ceirn', 'irxtn', 'ikrnm', 'jrnq', 'igne', 'arnp', 'vorn', 'irgc', 'mirc', 'imnp', 'iruny', 'eian', 'qixn', 'irjnn', 'inzrn', 'idsrn', 'jxn', 'amirn', 'firng', 'irzp', 'nro', 'izrnf', 'igmn', 'mn', 'mirbn', 'mivrn', 'ztrn', 'iusn', 'cirng', 'imrcn', 'karn', 'igsrn', 'hirnd', 'brl', 'irrin', 'ilnm', 'rc', 'kiirn', 'fun', 'irvk', 'srl', 'diwrn', 'qxirn', 'ikns', 'erpn', 'eirn', 'iurp', 'witn', 'iurnl', 'fibn', 'dirpn', 'itrw', 'qrnz', 'qrdn', 'firnq', 'teirn', 'iman', 'trnb', 'kirnl', 'firhn', 'nrgn', 'irbfn', 'rtin', 'iane', 'irneq', 'tiun', 'krgn', 'cirgn', 'qiwn', 'firm', 'hiorn', 'iwrs', 'ignz', 'yiren', 'irnts', 'rpin', 'pibrn', 'iwvn', 'ibno', 'inkn', 'dkirn', 'yrrn', 'ihrx', 'idgn', 'fign', 'ifnz', 'ivv', 'iwgn', 'evirn', 'rirl', 'lqn', 'irpyn', 'ikzrn', 'pzrn', 'ilrny', 'ivryn', 'iqern', 'tinn', 'frhn', 'nan', 'iqrmn', 'hird', 'lrnr', 'iarr', 'irlno', 'mwirn', 'gkrn', 'isrnb', 'imarn', 'pirno', 'trnp', 'hmn', 'gdirn', 'irctn', 'ernf', 'irjns', 'ickn', 'iqj', 'irph', 'miin', 'irdv', 'iqkn', 'irngq', 'irqu', 'irnao', 'icrnl', 'prng', 'irik', 'isrg', 'oisrn', 'ivrnm', 'ieno', 'ivni', 'airnd', 'hidrn', 'irniz', 'hrb', 'imnt', 'idrna', 'imnl', 'igrv', 'iqrnb', 'iwrz', 'ipt', 'iqna', 'hrs', 'izrrn', 'oirrn', 'krns', 'nirnq', 'irsqn', 'rirx', 'irbns', 'itrno', 'irq', 'lzirn', 'rrzn', 'vrnj', 'iixrn', 'drm', 'virv', 'nirny', 'ivnl', 'iqrv', 'ixrxn', 'kron', 'imfn', 'iuv', 'ifns', 'drcn', 'jisrn', 'gibn', 'ierne', 'ihnw', 'iuln', 'srp', 'irrx', 'enr', 'irat', 'niren', 'jrnp', 'irmc', 'wirnt', 'irjan', 'zrq', 'wn', 'hirvn', 'lirnl', 'mzn', 'irnnw', 'isin', 'irjcn', 'ikdrn', 'qiyn', 'qizn', 'miri', 'irwh', 'ipyn', 'pitrn', 'frni', 'izrnj', 'ikl', 'imq', 'birt', 'irqqn', 'idhn', 'drv', 'tirj', 'inrqn', 'gijrn', 'igrnz', 'irej', 'iord', 'irjnu', 'ieran', 'nrc', 'ivzn', 'kirnk', 'fmirn', 'ieren', 'iqirn', 'nrx', 'xirzn', 'gifn', 'iruni', 'irao', 'irlxn', 'irnrf', 'ilrne', 'dirf', 'mrk', 'uinn', 'ivfrn', 'srnk', 'itry', 'cirne', 'iwjrn', 'arc', 'irnvm', 'kiorn', 'itru', 'eirnz', 'aimrn', 'irfe', 'iwnp', 'uirnz', 'dcn', 'rrnw', 'ihyn', 'ironl', 'iarnj', 'nrfn', 'icg', 'giln', 'jirnw', 'iiren', 'irgnc', 'arns', 'sirh', 'iiln', 'kirv', 'cirnh', 'ornn', 'ixrcn', 'krh', 'irnmo', 'ilfn', 'icrnx', 'wwrn', 'iivrn', 'igw', 'uon', 'irdkn', 'fjrn', 'yru', 'tirno', 'icri', 'pru', 'jrm', 'fcrn', 'jrk', 'irnoo', 'idrp', 'jirkn', 'firnz', 'myn', 'irvbn', 'tmirn', 'ijz', 'igk', 'miran', 'iyzn', 'pgirn', 'iurnh', 'pixn', 'khrn', 'irdi', 'cirun', 'ibnt', 'prkn', 'vxirn', 'hn', 'irpni', 'iccn', 'bry', 'irad', 'igrnx', 'wign', 'mrx', 'virun', 'oihn', 'icrsn', 'airs', 'lrnt', 'irgnt', 'iavn', 'hgrn', 'kiro', 'vro', 'hre', 'idrr', 'irbsn', 'ieni', 'izrpn', 'prnq', 'isrnd', 'zfirn', 'dipn', 'jirnc', 'idry', 'irzgn', 'ffn', 'idno', 'yrni', 'irznz', 'aircn', 'irntq', 'mxrn', 'firon', 'zxirn', 'krnx', 'crgn', 'fiprn', 'wiryn', 'irjyn', 'iejn', 'yrkn', 'zirnz', 'ernm', 'irdnd', 'iyh', 'ifrrn', 'ifq', 'isv', 'irjng', 'fgrn', 'irnoj', 'irnmv', 'idvrn', 'irmyn', 'vigrn', 'kirpn', 'vinr', 'ere', 'irhnk', 'fivrn', 'irlq', 'xrln', 'igrnp', 'nir', 'inru', 'tirk', 'hirny', 'ivqrn', 'pmn', 'pirne', 'tbrn', 'ifna', 'orz', 'yibrn', 'iqrt', 'ipnd', 'icrny', 'isc', 'rikrn', 'irnlv', 'gmn', 'gry', 'irlkn', 'pirt', 'girln', 'eirxn', 'jrnr', 'uirln', 'uvn', 'irof', 'zrnp', 'qirnv', 'urtn', 'hrnm', 'grno', 'imrx', 'iqrkn', 'iqzn', 'fdn', 'irtan', 'icrfn', 'idw', 'aern', 'xhirn', 'ibrk', 'ihrnu', 'piorn', 'irean', 'hirb', 'mirwn', 'irnke', 'cru', 'imrp', 'cirg', 'ikrn', 'mivn', 'wirg', 'irir', 'lirtn', 'isrbn', 'lwrn', 'sirzn', 'ilno', 'imrjn', 'tri', 'irnwu', 'iten', 'rnv', 'iuryn', 'iaj', 'irlbn', 'lirnu', 'irtp', 'ireny', 'iex', 'ilo', 'ixnt', 'khirn', 'iyrnm', 'viran', 'zirzn', 'ihdrn', 'girsn', 'ixrmn', 'ilrnd', 'ibnb', 'iqq', 'isnb', 'rtirn', 'ijron', 'qiren', 'uibn', 'iqpn', 'irrl', 'irvnd', 'lirnq', 'irsan', 'airnv', 'ivran', 'wirp', 'itg', 'jzirn', 'eron', 'srnr', 'ivun', 'lsn', 'izrd', 'irrnu', 'ifirn', 'ihrnz', 'iony', 'irosn', 'nmirn', 'irax', 'imrh', 'zyrn', 'xrin', 'ilorn', 'irinh', 'irnkx', 'irre', 'xrni', 'ihrdn', 'iio', 'aiprn', 'kgn', 'grw', 'lrz', 'iirqn', 'iasn', 'yirln', 'irip', 'ibz', 'kirnj', 'xicrn', 'yrnr', 'ijfn', 'ivrpn', 'tcirn', 'puirn', 'ppirn', 'irpf', 'irgg', 'itkn', 'uirz', 'cirs', 'fjirn', 'iqrh', 'ivq', 'iirny', 'ifrq', 'iranz', 'irnzb', 'inm', 'irgkn', 'irta', 'rio', 'wiarn', 'ihtn', 'ihrnq', 'irknj', 'iardn', 'irinx', 'mirk', 'irncu', 'ijrns', 'irnmn', 'wirn', 'ni', 'irsnt', 'idrc', 'gan', 'virf', 'ilvn', 'ienv', 'ibi', 'rirfn', 'xron', 'ink', 'alirn', 'erdn', 'mrz', 'hrvn', 'ifrnm', 'lran', 'vird', 'qirr', 'dirng', 'rrnm', 'alrn', 'kikrn', 'pzirn', 'drnf', 'hun', 'xirun', 'irnmm', 'ilirn', 'vnirn', 'iernn', 'iers', 'jirrn', 'ixrv', 'iwq', 'xiru', 'irtc', 'irybn', 'myrn', 'xirm', 'trnv', 'ibkn', 'zrd', 'irtnd', 'jlrn', 'ihyrn', 'iryon', 'firi', 'oirns', 'drl', 'irrq', 'irbjn', 'irknk', 'lrnk', 'eirs', 'itrnz', 'dryn', 'idrnz', 'hrcn', 'irnwh', 'xrt', 'irmxn', 'zirnr', 'idrny', 'gmrn', 'zirn', 'irns', 'hirnq', 'irnkp', 'mrna', 'ircsn', 'irsy', 'ksirn', 'iyun', 'non', 'jirnb', 'idrxn', 'irkrn', 'iixn', 'iwtrn', 'irono', 'irpnw', 'irun', 'irnja', 'iercn', 'wyirn', 'iwu', 'iirrn', 'iurjn', 'iranp', 'simrn', 'ixrhn', 'irunq', 'irmln', 'slirn', 'xiry', 'irbh', 'srpn', 'qairn', 'ieb', 'riz', 'qirnq', 'irnqg', 'cern', 'icrnt', 'obrn', 'krrn', 'twirn', 'iwrxn', 'lpn', 'ylirn', 'mjn', 'tird', 'itb', 'ilgrn', 'xirne', 'edirn', 'itrnp', 'ora', 'rb', 'nrny', 'ihg', 'vrtn', 'iwcrn', 'rnc', 'int', 'hilrn', 'irnpx', 'izrx', 'imrwn', 'girkn', 'irgmn', 'qyn', 'fron', 'inbr', 'iporn', 'qrln', 'ibnh', 'idrne', 'krng', 'irdj', 'iii', 'nirzn', 'try', 'oirnq', 'irid', 'fxrn', 'sirn', 'wirnd', 'iurnq', 'iana', 'ivk', 'iarnv', 'irlx', 'irvh', 'qirni', 'iranl', 'urh', 'drp', 'irukn', 'inrpn', 'qkirn', 'gifrn', 'nrnb', 'iwrg', 'vrng', 'iurnr', 'iunk', 'drh', 'iain', 'ijrb', 'ircnl', 'hrnx', 'zxn', 'iraqn', 'irdna', 'irneb', 'pire', 'ixan', 'iyt', 'ierh', 'krzn', 'ornd', 'qrnp', 'igns', 'ingr', 'ixrt', 'ienn', 'wirpn', 'irnel', 'mirh', 'iorp', 'itrl', 'jrf', 'irdnf', 'dvrn', 'krna', 'fhn', 'iznj', 'ioen', 'iunu', 'pirin', 'iq', 'jirne', 'xrd', 'krg', 'iyrkn', 'irnip', 'hire', 'kirn', 'citrn', 'wrnn', 'sijrn', 'dzn', 'yirz', 'vrj', 'ikrnr', 'ircv', 'birp', 'irenc', 'ivqn', 'xird', 'ixrzn', 'irov', 'irav', 'irnfg', 'irfnu', 'bixrn', 'jrnb', 'inrnt', 'mrng', 'iknn', 'irncn', 'irdg', 'sqirn', 'iork', 'btirn', 'irti', 'ibarn', 'ifsrn', 'igirn', 'irynf', 'yiwn', 'ciprn', 'irsm', 'mirf', 'zrr', 'hfrn', 'iner', 'itn', 'arfn', 'iug', 'ean', 'tbn', 'iodn', 'rvirn', 'fisn', 'ibnv', 'rzn', 'eirk', 'ifrnu', 'jren', 'irntt', 'irnyj', 'iurni', 'vrnr', 'irnxm', 'iqrw', 'vien', 'xirgn', 'krnq', 'irgm', 'ciln', 'ixnl', 'srh', 'irnex', 'czirn', 'ierdn', 'iesrn', 'is', 'irnio', 'idrnf', 'irdnc', 'siwrn', 'nirs', 'irman', 'ijkrn', 'gir', 'iernh', 'irwnk', 'jirxn', 'irrgn', 'pqn', 'bidrn', 'irbw', 'iubrn', 'hrmn', 'ixpn', 'dirb', 'igkn', 'airun', 'irnxv', 'prcn', 'vrzn', 'dign', 'zirgn', 'ibrt', 'oin', 'iqrns', 'ihno', 'erv', 'jire', 'ohirn', 'ilin', 'iqfrn', 'filrn', 'crnu', 'iernm', 'igrni', 'imrg', 'irqnv', 'ile', 'kiln', 'rrng', 'iurkn', 'isyn', 'iirkn', 'irnfo', 'mrsn', 'irxny', 'yiin', 'ikgrn', 'irond', 'irrd', 'zivn', 'irpg', 'irgf', 'itron', 'fifn', 'irynu', 'irnaa', 'idrsn', 'bicn', 'sirf', 'ihhn', 'bxn', 'irnns', 'sqn', 'titn', 'itrfn', 'yrnd', 'ipnz', 'irnhc', 'jirnk', 'aifrn', 'iarwn', 'yirmn', 'ibr', 'qnr', 'liyrn', 'wnn', 'crd', 'ionv', 'izrns', 'yrgn', 'strn', 'irunf', 'npirn', 'irab', 'ikrno', 'eion', 'nn', 'irqna', 'itnh', 'itrj', 'irntr', 'irnwc', 'ilrmn', 'disrn', 'girn', 'xrno', 'rhn', 'inrnc', 'icrmn', 'eirnj', 'izrtn', 'ilnx', 'iripn', 'firnf', 'aqn', 'ijbn', 'iowrn', 'drng', 'irxy', 'idnl', 'ikwrn', 'oxrn', 'rins', 'ursn', 'ije', 'ktrn', 'hirnk', 'ifrr', 'iunh', 'ayn', 'idmn', 'cirjn', 'dvn', 'irwj', 'kgirn', 'idr', 'iraen', 'yirwn', 'msn', 'ibnf', 'ipwrn', 'lnrn', 'irsr', 'izrg', 'glrn', 'prd', 'izna', 'irnnl', 'rqrn', 'irneu', 'wr', 'ibrnm', 'irniv', 'irnfw', 'tirnb', 'ekn', 'iaz', 'hhrn', 'iqrnf', 'tirx', 'irwne', 'icmrn', 'ran', 'irdd', 'nbrn', 'pirpn', 'irdnq', 'irru', 'yisrn', 'ircw', 'yrnx', 'dry', 'airh', 'uizrn', 'iregn', 'irmi', 'ienu', 'mrfn', 'drrn', 'fr', 'pion', 'ijnn', 'lrm', 'iwrbn', 'uizn', 'irnzk', 'ihfn', 'vrw', 'jrnh', 'dinrn', 'vzrn', 'eiron', 'iwx', 'wjirn', 'nirl', 'dikrn', 'libn', 'qln', 'irfna', 'irawn', 'iirna', 'uwrn', 'irnkt', 'fira', 'vijn', 'ivrnh', 'qirnu', 'iank', 'irnti', 'irwrn', 'nhn', 'ciry', 'irnhx', 'ivre', 'cirvn', 'firnh', 'iing', 'mrnf', 'iqro', 'nlirn', 'yirl', 'girm', 'iox', 'biry', 'cprn', 'iyj', 'vire', 'iwne', 'lri', 'jfn', 'drzn', 'ijrnz', 'tirhn', 'gcrn', 'exirn', 'airgn', 'krin', 'eirm', 'iyz', 'irank', 'irntb', 'irnqr', 'erin', 'irnki', 'iiwn', 'bqn', 'iuvn', 'yirfn', 'irqnz', 'pirz', 'krfn', 'tiri', 'irkln', 'iwrw', 'iqne', 'irenj', 'ifrzn', 'likrn', 'ilro', 'niron', 'iernb', 'pfn', 'yrz', 'iirne', 'iznq', 'dhrn', 'ixcn', 'gln', 'irlcn', 'iua', 'kixrn', 'brmn', 'mr', 'xiprn', 'xiin', 'irqh', 'vbn', 'ignm', 'wihn', 'syn', 'ivgrn', 'eir', 'tryn', 'biirn', 'cirnf', 'ihran', 'irndw', 'grnd', 'orbn', 'ridrn', 'igpn', 'iwern', 'pirnq', 'morn', 'irztn', 'orqn', 'yrt', 'mrxn', 'tin', 'irac', 'isrc', 'wxrn', 'ihvrn', 'aan', 'irdnb', 'jrnz', 'kru', 'livrn', 'xirdn', 'dirvn', 'yirtn', 'iarnm', 'mirnk', 'iqmn', 'jirl', 'riy', 'qirj', 'iorjn', 'nrno', 'ljirn', 'iworn', 'iui', 'uqrn', 'ierns', 'iretn', 'trd', 'irtln', 'wirnk', 'miqn', 'ircnt', 'sirx', 'irhj', 'irnan', 'mirt', 'koirn', 'irfnp', 'ignr', 'miern', 'zirnh', 'irnxd', 'irnzu', 'irnej', 'yrp', 'meirn', 'irnsu', 'itnn', 'ifrnl', 'irfy', 'ikp', 'aen', 'girnr', 'eirq', 'rira', 'iez', 'jgirn', 'ipnu', 'sirt', 'iaf', 'jrc', 'oiun', 'irncd', 'iwa', 'iiy', 'lizrn', 'rrny', 'yrd', 'irsne', 'birne', 'oirnv', 'ikrng', 'iry', 'wwn', 'irujn', 'ticrn', 'irlen', 'irncz', 'harn', 'yrnt', 'iinp', 'iruns', 'zprn', 'igarn', 'viryn', 'ixyrn', 'qin', 'liru', 'nirb', 'ixl', 'shirn', 'nrnm', 'qirnx', 'rqirn', 'heirn', 'oir', 'uirny', 'irifn', 'irtb', 'pdrn', 'cgirn', 'xjirn', 'igrnn', 'irwxn', 'irwbn', 'bibrn', 'mtirn', 'rq', 'tzirn', 'uirqn', 'brnt', 'iprny', 'irjny', 'ifny', 'irnyf', 'nren', 'ifrn', 'ipn', 'qxrn', 'ifgn', 'sirbn', 'jiran', 'drbn', 'mcirn', 'ejrn', 'rrnu', 'izrqn', 'irjon', 'lirnf', 'ixtrn', 'iyrne', 'airno', 'farn', 'uiin', 'ilzrn', 'wrb', 'trnt', 'kqrn', 'rirnp', 'irnwr', 'bimn', 'ikzn', 'iidn', 'ihrnh', 'iku', 'qkn', 'brr', 'jrh', 'pizn', 'irby', 'hirnj', 'ar', 'ircz', 'irhxn', 'irrvn', 'inrgn', 'ikrmn', 'izwrn', 'irli', 'aiun', 'igln', 'iprnw', 'iyru', 'bjn', 'dikn', 'ukirn', 'irsnu', 'drw', 'pitn', 'uiirn', 'vbrn', 'jirx', 'irhnm', 'ijrm', 'llirn', 'yirnu', 'irenq', 'mra', 'vrnc', 'uirnk', 'ibrnp', 'ozrn', 'iwyrn', 'irtnr', 'pirq', 'ninn', 'aitn', 'ionx', 'incr', 'izrr', 'smrn', 'irki', 'ngirn', 'iurnp', 'irmnc', 'irxin', 'oizrn', 'iqnp', 'irtmn', 'xfrn', 'irjn', 'ijrc', 'igrf', 'idrun', 'irzcn', 'imrzn', 'xarn', 'trg', 'iyrln', 'iunj', 'trc', 'kidrn', 'iirc', 'piwn', 'yirnr', 'irnmp', 'zrhn', 'iirjn', 'omirn', 'ilrbn', 'virnm', 'snr', 'idrbn', 'eyn', 'irgy', 'vjn', 'xrrn', 'gwrn', 'iroln', 'irbne', 'ircnh', 'irkc', 'irrnr', 'iwrln', 'trf', 'kirnv', 'irpm', 'piro', 'iokrn', 'lrnn', 'irpun', 'ivry', 'innw', 'ionr', 'icnu', 'apirn', 'vbirn', 'eiin', 'birn', 'kun', 'iqw', 'rp', 'iqwn', 'irhnj', 'hivrn', 'ksrn', 'jirnx', 'leirn', 'hrno', 'igf', 'birnx', 'crhn', 'krnw', 'irmy', 'jrnk', 'iruxn', 'ilng', 'iqnv', 'isnu', 'iernt', 'irbl', 'irvyn', 'ivrnw', 'vrun', 'juirn', 'inrnr', 'grpn', 'jan', 'icrs', 'irden', 'trwn', 'gnrn', 'kifn', 'ivrv', 'ijo', 'irmnj', 'viern', 'uqirn', 'xrc', 'iranm', 'ufirn', 'iisrn', 'trv', 'ifyn', 'hrv', 'rrd', 'fmrn', 'ihrnf', 'insr', 'lrna', 'irzvn', 'orl', 'iarw', 'lmn', 'ncn', 'irnih', 'zird', 'rrf', 'dmrn', 'fihrn', 'ihru', 'qirnr', 'hkn', 'dirx', 'irnpt', 'oxirn', 'ivrny', 'xian', 'irwhn', 'etn', 'irxwn', 'ifrt', 'bzn', 'irvnb', 'iprrn', 'ijyn', 'ginrn', 'lbirn', 'if', 'tairn', 'zrrn', 'jirr', 'iajrn', 'irzkn', 'irig', 'wmn', 'insn', 'eiwn', 'irqnt', 'prnk', 'mira', 'idrl', 'brm', 'itrrn', 'oirq', 'qigrn', 'iovn', 'ijnc', 'irwsn', 'yinn', 'iyrnk', 'iurcn', 'irlyn', 'ilns', 'isrnf', 'jbn', 'rinm', 'eiurn', 'ism', 'irgvn', 'orne', 'min', 'urnb', 'nirnb', 'irznc', 'era', 'zr', 'izrgn', 'rirnb', 'ifbn', 'dirp', 'ixlrn', 'inir', 'lorn', 'ircl', 'fen', 'wcn', 'sirin', 'irg', 'osn', 'imrnk', 'hon', 'miro', 'nrna', 'jjn', 'eeirn', 'xtn', 'tiryn', 'fitrn', 'irvnu', 'nirnx', 'iyrsn', 'irzdn', 'igqn', 'irhnv', 'irinl', 'icrnd', 'irfp', 'xira', 'ison', 'bern', 'iiyn', 'ornb', 'rvn', 'wirc', 'irgcn', 'cirdn', 'itc', 'cirin', 'uifrn', 'mrnz', 'yirjn', 'irpfn', 'mvrn', 'ipprn', 'irkns', 'imryn', 'iblrn', 'inrsn', 'ovn', 'uiurn', 'skirn', 'wmrn', 'ikna', 'ivbrn', 'irdr', 'irtne', 'irhgn', 'sinr', 'ann', 'irqnj', 'dilrn', 'iray', 'ilnc', 'ihrnp', 'kihn', 'iwnw', 'iupn', 'ebirn', 'pirx', 'irngy', 'irunx', 'vsirn', 'ivrh', 'irrne', 'vairn', 'idxrn', 'ikb', 'imhn', 'irnnj', 'nirq', 'xxirn', 'lirno', 'irpnk', 'czn', 'iwrq', 'irnxf', 'irzwn', 'iirx', 'vicn', 'ixd', 'rlin', 'irnnk', 'kirnf', 'irnqf', 'idi', 'irpt', 'ysn', 'birng', 'iagn', 'mirnf', 'bird', 'oirv', 'srnd', 'kbirn', 'wnr', 'yrirn', 'aiin', 'iprnc', 'ioyrn', 'ikrnh', 'irjvn', 'irfm', 'ainrn', 'sr', 'rnm', 'xwirn', 'irpr', 'irvrn', 'irezn', 'fsrn', 'jbirn', 'xln', 'irgny', 'kzrn', 'tirf', 'inrnn', 'icni', 'kirnt', 'iirvn', 'lgn', 'yinr', 'idnu', 'irhnu', 'jir', 'iog', 'ittrn', 'iyfrn', 'irnnp', 'brgn', 'irdo', 'ipr', 'ifern', 'irhnq', 'ikrnf', 'ivd', 'jidrn', 'wiwrn', 'irnvv', 'uirp', 'oiryn', 'iprnu', 'yrnm', 'indr', 'irgnu', 'iirhn', 'ifrnn', 'irnus', 'isnw', 'rg', 'irhen', 'imrnl', 'iryt', 'trpn', 'hlrn', 'ish', 'isrp', 'ignw', 'ptrn', 'urqn', 'ifrtn', 'irnl', 'wsirn', 'irknm', 'eire', 'lrnj', 'virn', 'ifnf', 'wirw', 'bvrn', 'ihrf', 'iaon', 'zorn', 'cirns', 'rxirn', 'virnp', 'ijnf', 'tirny', 'yiyn', 'kimrn', 'kirj', 'difrn', 'irqvn', 'hjn', 'bdrn', 'irjun', 'irlf', 'izr', 'yun', 'ioc', 'iurhn', 'iuni', 'iarun', 'ergn', 'hirv', 'lnn', 'girzn', 'ilcn', 'virxn', 'grz', 'mvn', 'kirzn', 'irsc', 'irkjn', 'idnn', 'pirnk', 'irwn', 'irndq', 'byrn', 'gikn', 'hiprn', 'irunl', 'ito', 'rmin', 'iryzn', 'irlnm', 'dira', 'uisrn', 'inp', 'frnb', 'zirtn', 'piryn', 'ivh', 'nirp', 'ifrc', 'iid', 'picrn', 'frfn', 'girr', 'nirdn', 'nivn', 'iyk', 'unirn', 'iyrpn', 'ignj', 'lmrn', 'qrbn', 'nircn', 'elrn', 'mhirn', 'arj', 'oiqn', 'xsrn', 'iynm', 'irncr', 'iznx', 'xmirn', 'jirqn', 'icz', 'ievn', 'lron', 'ibrns', 'iwrmn', 'frna', 'wrs', 'kren', 'mifrn', 'vrnd', 'irniw', 'arun', 'inhn', 'vxn', 'csirn', 'irynl', 'imz', 'irgnb', 'irds', 'ynr', 'iyrs', 'yixrn', 'lcrn', 'qrnh', 'yirnb', 'tnn', 'irwf', 'irwnv', 'itdn', 'iil', 'idrnk', 'mijn', 'cirw', 'ijzrn', 'inrcn', 'irzno', 'siryn', 'ihlrn', 'iyrny', 'irfc', 'irssn', 'iryni', 'icrnu', 'yihrn', 'irpnd', 'ies', 'lirnx', 'irqnd', 'ikrnu', 'krz', 'inmrn', 'weirn', 'qmn', 'irwt', 'irjl', 'nirns', 'ihwn', 'hrna', 'byn', 'fion', 'qirwn', 'mrnv', 'mirvn', 'iewrn', 'yrnz', 'ixnj', 'ipni', 'irdx', 'jn', 'ixna', 'iznd', 'isrdn', 'nihn', 'ivrnb', 'iul', 'omrn', 'ixrnw', 'iruqn', 'iqv', 'ixrb', 'iinv', 'irknc', 'brcn', 'grx', 'ioan', 'rrne', 'yri', 'ifrnw', 'iebn', 'qirw', 'mirnp', 'irgon', 'iknz', 'igrhn', 'igen', 'dren', 'iiw', 'iorh', 'ient', 'irjnx', 'bnrn', 'irnbf', 'sirno', 'irqnu', 'agirn', 'idrj', 'krbn', 'idnd', 'bigrn', 'ifnn', 'itsrn', 'irnxt', 'iqrzn', 'ihrb', 'igrng', 'kyrn', 'ijrwn', 'irnfr', 'irinz', 'wrh', 'irec', 'irnzm', 'trn', 'iurun', 'kairn', 'zrirn', 'oryn', 'sigrn', 'irnpo', 'frnq', 'ivrzn', 'irnfl', 'erny', 'ibrqn', 'irgq', 'rj', 'hirk', 'oln', 'tifrn', 'iprnr', 'irygn', 'iwrnn', 'iiwrn', 'crnt', 'siran', 'nzirn', 'rinc', 'crnz', 'ignu', 'fqrn', 'irel', 'awirn', 'nifrn', 'irzon', 'iinn', 'roirn', 'irie', 'oiern', 'iargn', 'irh', 'dcrn', 'oirz', 'irnpc', 'prk', 'ivy', 'ibrnu', 'rnin', 'iryc', 'irneo', 'isrw', 'lvn', 'iwrnk', 'rihn', 'ioren', 'irvg', 'ifcn', 'eirnc', 'ifmn', 'irktn', 'grwn', 'riro', 'xdrn', 'irnaw', 'irkqn', 'wvrn', 'dmirn', 'iwprn', 'jrn', 'fzirn', 'mimrn', 'zirqn', 'iarnq', 'xirny', 'itrn', 'iory', 'diln', 'airfn', 'iurg', 'wirqn', 'wiyrn', 'aixn', 'jixrn', 'irhb', 'irnxp', 'ixrf', 'irnqt', 'irnji', 'ccrn', 'porn', 'vrna', 'bpn', 'jrnv', 'cirno', 'ziren', 'imjn', 'irxn', 'ifyrn', 'ilrb', 'srnj', 'ivyrn', 'epn', 'prh', 'irrr', 'hln', 'irtnp', 'irzq', 'irenk', 'mrny', 'iwf', 'sicn', 'crirn', 'zirj', 'iafn', 'jxirn', 'rirk', 'hixn', 'iqtrn', 'icvn', 'fryn', 'mrl', 'ircy', 'irznv', 'itrnf', 'brnq', 'ijgn', 'iqrvn', 'irqnc', 'inry', 'hirno', 'icn', 'lrjn', 'biqrn', 'imnrn', 'qrd', 'irnma', 'inna', 'iazrn', 'idrng', 'ibrnk', 'zjrn', 'irini', 'imne', 'iruv', 'ironm', 'irncl', 'ziurn', 'pxn', 'ilyrn', 'kcn', 'ivrfn', 'qrrn', 'irxq', 'dirc', 'drnc', 'mgn', 'iron', 'frbn', 'iynu', 'igren', 'xmn', 'nrnv', 'litrn', 'irndp', 'ifrnq', 'uirnc', 'ietn', 'ipyrn', 'crln', 'pyrn', 'bfn', 'irfq', 'bnr', 'rwin', 'irpb', 'ifni', 'irym', 'iprp', 'irran', 'wdrn', 'hirl', 'iqf', 'tirne', 'birnm', 'urmn', 'trny', 'irnqj', 'irnos', 'zrnn', 'lkirn', 'firyn', 'pjirn', 'irant', 'idnt', 'oiqrn', 'srln', 'irnpq', 'srni', 'crno', 'orkn', 'drnj', 'mrtn', 'srnz', 'irmdn', 'xrny', 'ivu', 'ige', 'iernq', 'crpn', 'rirnn', 'airnq', 'virt', 'iernl', 'nin', 'umrn', 'axirn', 'irll', 'trnc', 'kihrn', 'iyrnz', 'izrmn', 'yiun', 'sirnm', 'iriin', 'orvn', 'irnqm', 'virnw', 'rina', 'tirnu', 'frnr', 'jiqrn', 'wrk', 'isbn', 'irqr', 'irfv', 'irpbn', 'gjn', 'ixgrn', 'cdrn', 'yiqn', 'ywirn', 'irkvn', 'hirnx', 'lien', 'igxn', 'wrg', 'wirbn', 'pun', 'drln', 'vryn', 'dirg', 'ignf', 'ibp', 'jmrn', 'zrno', 'iyrnu', 'jun', 'prno', 'oirjn', 'gon', 'tirb', 'ivs', 'iyna', 'itrm', 'ilry', 'irb', 'itrns', 'ivrg', 'grnn', 'trnr', 'ilrnf', 'tyn', 'irfnf', 'idjrn', 'ijrj', 'irja', 'irvnf', 'iwfn', 'wre', 'bira', 'xrx', 'bihrn', 'iprnj', 'zrnr', 'irjfn', 'hiurn', 'kirni', 'twrn', 'ircb', 'jrz', 'iurny', 'irnzi', 'iwrnu', 'xirnw', 'ovirn', 'sirhn', 'imw', 'isrun', 'irlnt', 'dlirn', 'icrns', 'ipron', 'tiyrn', 'isnq', 'ozn', 'hqrn', 'din', 'wrnq', 'icrnf', 'itno', 'vcirn', 'ziun', 'idln', 'ciri', 'ijrny', 'uyn', 'carn', 'icnt', 'irar', 'iyfn', 'ijrnk', 'itrqn', 'ijrne', 'ipcn', 'ibw', 'ert', 'ixrin', 'cirr', 'qirh', 'irnks', 'rfn', 'yrno', 'piyn', 'ifrpn', 'gbirn', 'pn', 'ysirn', 'irapn', 'hxrn', 'firni', 'ifrnz', 'lrns', 'irspn', 'isrzn', 'mirhn', 'iahn', 'jiri', 'dfn', 'oiran', 'nizrn', 'irxqn', 'iurln', 'imrvn', 'iyorn', 'liln', 'irlni', 'ijrs', 'mrwn', 'irpv', 'iprtn', 'nipn', 'irgnl', 'ixnd', 'kivn', 'riyn', 'vkrn', 'htrn', 'irvsn', 'rrln', 'iurng', 'ckrn', 'arjn', 'irjnj', 'frh', 'girin', 'qivn', 'uign', 'ginn', 'irga', 'neirn', 'hirw', 'virnt', 'wirnp', 'virk', 'qirp', 'itrtn', 'ken', 'pirxn', 'iyrj', 'pcrn', 'eirzn', 'iws', 'iria', 'irhcn', 'irnne', 'irkni', 'irmbn', 'marn', 'irvin', 'ivrln', 'irpnm', 'mien', 'tirzn', 'ijrf', 'ixnb', 'cinr', 'innl', 'irt', 'vra', 'ifno', 'eiro', 'idrm', 'wird', 'mikrn', 'ivvn', 'ijrno', 'trz', 'oibn', 'iig', 'vrkn', 'jirna', 'isrnk', 'irhwn', 'iqcn', 'iknrn', 'wprn', 'iplrn', 'irsnh', 'xire', 'nrun', 'qinr', 'xrbn', 'irfnd', 'iunc', 'yn', 'irnly', 'klrn', 'irnnt', 'ihrbn', 'wdirn', 'iryhn', 'rrr', 'ixnk', 'isun', 'mrj', 'cirbn', 'imno', 'iruln', 'iuhn', 'zairn', 'irayn', 'inyn', 'piln', 'oirun', 'zirrn', 'iqrun', 'ibh', 'yirnl', 'iktrn', 'ifrun', 'itrnv', 'rrmn', 'lrnc', 'ivrbn', 'firnx', 'xpn', 'irgnp', 'mrnh', 'birwn', 'hfn', 'icyn', 'aprn', 'irrnf', 'iornp', 'ciarn', 'iinrn', 'arrn', 'rirne', 'sjirn', 'itrkn', 'cirnn', 'dirin', 'bkrn', 'pon', 'fiirn', 'girq', 'sirl', 'ironx', 'irdcn', 'iurx', 'sipn', 'inon', 'irani', 'jcn', 'xrnn', 'lihrn', 'itzrn', 'oiyn', 'sirln', 'irnbr', 'ziin', 'wrxn', 'iyrjn', 'zirvn', 'irmns', 'jirg', 'ioon', 'iprnf', 'wren', 'iaren', 'irnid', 'oon', 'szrn', 'drq', 'krn', 'icrq', 'iawrn', 'hirnv', 'iemrn', 'ifra', 'vcrn', 'ihc', 'birk', 'znrn', 'oirvn', 'ltn', 'idryn', 'sfn', 'ieg', 'wrgn', 'ihny', 'ipnw', 'eirb', 'zrb', 'wzirn', 'irpp', 'inng', 'sien', 'qfirn', 'nirnh', 'dirfn', 'durn', 'irqv', 'izrk', 'itu', 'rrbn', 'jirhn', 'imni', 'iwy', 'tirl', 'uirvn', 'ircn', 'irdns', 'qirng', 'xiryn', 'ijrl', 'ijfrn', 'zirnb', 'ciqrn', 'wiun', 'irbnk', 'ihfrn', 'xirni', 'irnea', 'irink', 'otn', 'trr', 'ihrun', 'icrtn', 'hrjn', 'wrpn', 'iryf', 'zran', 'ilhrn', 'idp', 'uird', 'iql', 'irzan', 'tirr', 'hirh', 'irnvk', 'iwbn', 'qiln', 'iiru', 'qzrn', 'kirf', 'iuern', 'ikarn', 'ciyn', 'rl', 'yrnq', 'ifrne', 'irjo', 'rron', 'girv', 'wryn', 'urwn', 'ibrw', 'cvrn', 'orgn', 'lirwn', 'tiprn', 'iud', 'irnic', 'kwn', 'srnu', 'kpirn', 'ivin', 'gjrn', 'lxrn', 'irxnn', 'org', 'iond', 'imqrn', 'sirny', 'zgirn', 'emirn', 'iasrn', 'sry', 'vtrn', 'izhn', 'irinm', 'ipnc', 'irngf', 'cisrn', 'liprn', 'jrna', 'irdnh', 'bgn', 'firen', 'irgz', 'wirkn', 'ibrz', 'ihen', 'wirh', 'cirp', 'niqrn', 'ixa', 'izrnk', 'irgna', 'itrz', 'igy', 'iprne', 'zirnk', 'imny', 'ibd', 'irnul', 'aicn', 'ikrgn', 'iot', 'odn', 'irnbc', 'iuru', 'iani', 'irbd', 'iwrm', 'jirng', 'vrln', 'iaern', 'iiran', 'irwjn', 'lxn', 'ahirn', 'rixrn', 'irwng', 'vnr', 'itvrn', 'irnei', 'djn', 'dimrn', 'lvrn', 'isirn', 'idru', 'iirz', 'ixnx', 'ise', 'isz', 'irrnj', 'ooirn', 'ifg', 'ierqn', 'irdrn', 'irqnx', 'ilrm', 'uirnm', 'tirkn', 'iba', 'irson', 'irwnu', 'arnv', 'oimrn', 'iurs', 'iruan', 'ipv', 'uifn', 'irjw', 'oirnk', 'nirnd', 'injrn', 'irqyn', 'irtwn', 'izvrn', 'irwnh', 'iuzn', 'irgnv', 'urzn', 'irvnt', 'ierng', 'drnl', 'ianp', 'xfn', 'cirf', 'ibm', 'iknc', 'ixrnu', 'irna', 'idrrn', 'gfirn', 'frw', 'lirsn', 'ifnk', 'isrnx', 'umirn', 'ilnd', 'ain', 'ipw', 'irbnj', 'aoirn', 'itrk', 'igrnl', 'kirnr', 'mry', 'tsrn', 'irdnj', 'irvdn', 'qrpn', 'iirwn', 'irvcn', 'sihn', 'zizn', 'xiri', 'itne', 'ure', 'irqnq', 'iqrq', 'wen', 'virnx', 'ihk', 'hdrn', 'iol', 'irenf', 'ilw', 'irnyw', 'iimrn', 'rinw', 'birnz', 'miru', 'ipmrn', 'imrj', 'ilrs', 'rrnh', 'tirna', 'iurwn', 'iprqn', 'yrjn', 'isrq', 'zon', 'ircny', 'iob', 'zibrn', 'zixrn', 'ixrfn', 'nimrn', 'ixk', 'izen', 'izfrn', 'lrj', 'yirnk', 'irxf', 'giri', 'girgn', 'iznv', 'irgk', 'isren', 'uirw', 'xinr', 'sirnt', 'pxirn', 'izrnz', 'dron', 'iarnf', 'ioun', 'iprnk', 'icern', 'fnirn', 'urbn', 'ilwn', 'urn', 'piern', 'cran', 'efrn', 'irlnj', 'icxrn', 'irqmn', 'hrd', 'irpnh', 'yiri', 'yitrn', 'irxc', 'rcirn', 'iszn', 'ircnw', 'irlwn', 'isrmn', 'lirf', 'imwn', 'jrjn', 'irnsk', 'ijrnb', 'mrjn', 'den', 'hzn', 'udirn', 'irntj', 'nicn', 'irnug', 'iiorn', 'iirin', 'ijmrn', 'irccn', 'mian', 'miron', 'fbrn', 'nri', 'irdnm', 'irrnl', 'jrd', 'iure', 'irvnn', 'rrin', 'rilrn', 'irnqa', 'piqrn', 'pqrn', 'rxin', 'iznh', 'ivr', 'en', 'irnik', 'hrpn', 'qirnb', 'znirn', 'rkrn', 'zrs', 'ildrn', 'ivrvn', 'irlvn', 'irnli', 'kvrn', 'hiru', 'ijqrn', 'ngn', 'ritrn', 'hkirn', 'trun', 'iarnn', 'iznm', 'mqirn', 'hnrn', 'irnmi', 'ihr', 'irnss', 'ikmrn', 'iqrd', 'qfrn', 'iwrun', 'iown', 'irxz', 'euirn', 'yipn', 'zidrn', 'uiry', 'crnq', 'ifri', 'irfbn', 'kirh', 'ijrin', 'ipy', 'qern', 'xrnl', 'virw', 'itf', 'irkxn', 'dmn', 'ixorn', 'awn', 'wrnj', 'iwv', 'sibrn', 'irnco', 'irck', 'vtirn', 'iyryn', 'ifrh', 'dirjn', 'ikre', 'cmirn', 'ibrpn', 'icne', 'irjy', 'iulrn', 'gzirn', 'erna', 'iwnb', 'irncp', 'srm', 'idwn', 'plirn', 'yzn', 'imrnh', 'inbn', 'irznw', 'mizrn', 'jon', 'irpqn', 'irnar', 'irlna', 'yirrn', 'oixn', 'oibrn', 'iuxrn', 'ilrv', 'iurnm', 'ikurn', 'izrp', 'virbn', 'iarna', 'idn', 'irjnf', 'virb', 'hrsn', 'lrnd', 'srnv', 'idron', 'irnnf', 'frnv', 'yirkn', 'hrirn', 'virnn', 'airin', 'iqbrn', 'ilzn', 'irnvq', 'jairn', 'iern', 'irenp', 'lirzn', 'ils', 'irjdn', 'iirni', 'mren', 'hern', 'irang', 'piran', 'itrnd', 'lurn', 'ikrnz', 'rinh', 'irian', 'ibrx', 'idorn', 'pen', 'dirbn', 'ighn', 'opirn', 'isnt', 'jern', 'irwqn', 'brnk', 'iribn', 'jdn', 'uirv', 'izfn', 'enrn', 'rns', 'nry', 'iinq', 'crr', 'irgno', 'iono', 'irnjs', 'byirn', 'irfnn', 'ilern', 'iknj', 'irzo', 'viyrn', 'fyn', 'irnsq', 'ikrqn', 'yirb', 'ksn', 'iryh', 'jrcn', 'irca', 'gtrn', 'wiru', 'mixn', 'irvxn', 'irrjn', 'ivrni', 'irkwn', 'bfrn', 'irknl', 'eirnq', 'qzirn', 'ixri', 'itrng', 'xirqn', 'zgrn', 'iernp', 'jirq', 'irndh', 'igb', 'diri', 'drgn', 'irif', 'irwo', 'dirl', 'orm', 'irwna', 'ixrtn', 'virnj', 'zbn', 'iimn', 'irfni', 'izbn', 'hxirn', 'xyrn', 'jirno', 'isrnl', 'liri', 'iurgn', 'xirnb', 'tirz', 'ruin', 'krjn', 'wrnl', 'aran', 'knirn', 'eign', 'irv', 'fnrn', 'sirz', 'tircn', 'xrcn', 'pbrn', 'iarnc', 'ihnl', 'izrnx', 'trng', 'ihnq', 'qirq', 'iirzn', 'irnvw', 'crnw', 'irnzf', 'uhn', 'yrnp', 'icb', 'iyan', 'iorna', 'iarln', 'cire', 'ixnm', 'ike', 'mryn', 'ijrd', 'vran', 'mpirn', 'iwe', 'winrn', 'mirqn', 'cirnt', 'srb', 'irnpw', 'fixrn', 'imtrn', 'gzn', 'wivrn', 'igrun', 'irone', 'ipnm', 'oirfn', 'rirbn', 'ibnk', 'ivc', 'nrmn', 'isnc', 'divrn', 'riq', 'knr', 'iirs', 'prnl', 'zicn', 'ihrnm', 'kon', 'irjnd', 'pcirn', 'trj', 'lirxn', 'izrny', 'tiron', 'ianw', 'migrn', 'birv', 'fire', 'iine', 'irzx', 'iorrn', 'frirn', 'cdirn', 'ivrng', 'zirmn', 'ico', 'hien', 'irgdn', 'crnp', 'vibn', 'jirsn', 'birhn', 'iijrn', 'larn', 'irwnd', 'ynrn', 'siyrn', 'ibtrn', 'irud', 'irzhn', 'igrbn', 'lrf', 'ort', 'isnl', 'imnm', 'iljn', 'izne', 'isyrn', 'girng', 'irgo', 'ijp', 'ihn', 'ihryn', 'iyrni', 'pirh', 'tizrn', 'riron', 'diryn', 'iknh', 'irymn', 'cln', 'irlny', 'xnirn', 'isron', 'irngk', 'ivhn', 'iurpn', 'mrin', 'lirhn', 'irung', 'irak', 'oijrn', 'inrjn', 'qron', 'xiqn', 'irvun', 'vtn', 'inx', 'virpn', 'mrnj', 'jirmn', 'iivn', 'rirns', 'pirg', 'dsirn', 'cmrn', 'hrnb', 'irnnc', 'wiqrn', 'jzrn', 'iqrnk', 'irhm', 'iwns', 'idyrn', 'irvnc', 'trw', 'ilnz', 'ifxn', 'wqn', 'zitn', 'arxn', 'ibra', 'irins', 'izxrn', 'niurn', 'irihn', 'iirg', 'jirdn', 'irxp', 'iromn', 'zira', 'idrzn', 'muirn', 'ivnm', 'sdrn', 'fqirn', 'vmrn', 'cirnd', 'ieryn', 'icnv', 'bnn', 'xiirn', 'etirn', 'iarv', 'crj', 'xirmn', 'irnlw', 'sirnp', 'itrc', 'hirq', 'vrnt', 'irngi', 'rimn', 'virl', 'gsn', 'qirjn', 'irned', 'nrrn', 'imri', 'lren', 'irfnz', 'imgrn', 'rip', 'lirjn', 'iurt', 'mifn', 'irytn', 'iye', 'inern', 'ihd', 'oirj', 'irjzn', 'ivpn', 'azirn', 'irbna', 'irogn', 'iurl', 'ary', 'iqrnt', 'iqyrn', 'ircns', 'iynk', 'inne', 'yrin', 'irvnj', 'ivo', 'irmno', 'erqn', 'intr', 'srna', 'wrrn', 'dan', 'nirf', 'ijrq', 'jird', 'gru', 'vihrn', 'irce', 'qirnz', 'iirnh', 'ihv', 'xirnc', 'ifnx', 'erun', 'itrjn', 'wron', 'tirfn', 'iwpn', 'sign', 'cnirn', 'ijtrn', 'iyxrn', 'zirhn', 'kmirn', 'irbnw', 'firu', 'irknn', 'mirnc', 'gxn', 'errn', 'ikne', 'doirn', 'ieorn', 'ircg', 'vhn', 'ivrmn', 'irnyo', 'mirng', 'jra', 'icwrn', 'iprnl', 'gian', 'qdn', 'irff', 'iarnk', 'igng', 'nirmn', 'vrz', 'iornh', 'irpc', 'yirnw', 'qwirn', 'urln', 'yryn', 'arna', 'iris', 'airnm', 'wirtn', 'irufn', 'cizn', 'uprn', 'yirny', 'rna', 'inlrn', 'viyn', 'irnqp', 'uian', 'irnee', 'iryk', 'irmne', 'inrni', 'biri', 'pirnr', 'irnjz', 'wlrn', 'prna', 'ikvrn', 'tilrn', 'icrgn', 'ipng', 'imran', 'incn', 'szirn', 'djrn', 'irtbn', 'iie', 'irem', 'pirgn', 'mrnw', 'eirnp', 'lion', 'ibnz', 'ndn', 'ziern', 'irven', 'ifrm', 'irunz', 'idnv', 'airl', 'brnn', 'ijren', 'izkrn', 'hira', 'idh', 'iiprn', 'oirnw', 'yibn', 'tmn', 'wfrn', 'vimrn', 'irnae', 'irjnw', 'gn', 'izru', 'ierxn', 'ixin', 'iarl', 'ijnt', 'irjnp', 'ilne', 'kidn', 'rnl', 'kbrn', 'emn', 'irwni', 'irnix', 'diran', 'jifn', 'uirun', 'yigrn', 'irmsn', 'zvirn', 'irnv', 'ylrn', 'wrnh', 'mtn', 'rikn', 'ubrn', 'rt', 'itnc', 'ogn', 'gicrn', 'iros', 'hrw', 'rxn', 'zrnx', 'ipnj', 'mjrn', 'rrnp', 'iruen', 'iven', 'irpnb', 'inor', 'ierb', 'irjmn', 'xir', 'irnqd', 'iwln', 'mircn', 'iqrln', 'kra', 'arnt', 'rrnt', 'rrh', 'irzu', 'izrcn', 'itrzn', 'xirj', 'kwirn', 'kircn', 'irx', 'irqx', 'iranb', 'bfirn', 'irjno', 'binr', 'irony', 'uuirn', 'ivorn', 'crh', 'idnb', 'siwn', 'dirgn', 'vdn', 'irahn', 'ixrnn', 'zrnm', 'sirw', 'ipran', 'tvn', 'wln', 'ijdrn', 'zirkn', 'girpn', 'idq', 'irstn', 'hirnu', 'zfn', 'drne', 'irrxn', 'jrv', 'irnnv', 'vrp', 'lirnh', 'bian', 'iarny', 'nirnw', 'qqirn', 'lrnw', 'uirn', 'irngm', 'ivnp', 'nnn', 'izrb', 'ioarn', 'airx', 'ino', 'piqn', 'ijrt', 'iam', 'irqj', 'iqrnm', 'sirne', 'kire', 'dion', 'imkrn', 'ijro', 'misn', 'irxnu', 'yian', 'inrfn', 'iinh', 'iyrhn', 'iyg', 'imorn', 'kirvn', 'ipnp', 'ibrnh', 'airnj', 'iybn', 'wan', 'jen', 'ijrnf', 'prnu', 'rinz', 'wiprn', 'zirne', 'jiern', 'iwnc', 'firb', 'mrr', 'zivrn', 'rrrn', 'zirc', 'jion', 'iprv', 'iij', 'dtn', 'ixnw', 'ipry', 'rrvn', 'irhno', 'ibnu', 'irlc', 'yvn', 'inb', 'vian', 'frz', 'arbn', 'irhc', 'irqfn', 'hwn', 'yairn', 'frdn', 'irtyn', 'irnmd', 'itv', 'irrsn', 'cirn', 'yvrn', 'ihkrn', 'irnjc', 'jirwn', 'oyrn', 'lrh', 'iprna', 'irjnb', 'avn', 'iyrzn', 'uirq', 'ixrbn', 'ierkn', 'ifcrn', 'hizn', 'widn', 'vrnk', 'igcrn', 'uicrn', 'oiren', 'irpxn', 'prns', 'uirnh', 'eiun', 'iacn', 'brfn', 'ikrp', 'iroj', 'qrnc', 'giran', 'crnx', 'zrt', 'igrna', 'mirl', 'iqorn', 'girun', 'prs', 'uarn', 'wirln', 'irhln', 'tibn', 'jijn', 'bizn', 'krnf', 'izra', 'sivn', 'ibrnf', 'vqirn', 'kiern', 'diyn', 'iykn', 'icrnb', 'irnsm', 'drt', 'irmnn', 'fern', 'uirnr', 'irnqs', 'irbp', 'orirn', 'igg', 'yire', 'irnwf', 'irznl', 'aibrn', 'iriv', 'ires', 'yoirn', 'crg', 'iirnc', 'ijf', 'wxirn', 'itrdn', 'birj', 'brnf', 'iarns', 'brbn', 'ifk', 'uirng', 'iknl', 'dn', 'xurn', 'vrin', 'irnho', 'irho', 'irqz', 'grv', 'imrq', 'nirz', 'rrno', 'grbn', 'ifrxn', 'xgirn', 'src', 'irnuo', 'ing', 'qirbn', 'miorn', 'iuqn', 'idre', 'iarno', 'sifrn', 'iravn', 'bqirn', 'enn', 'zirwn', 'irnfm', 'mxirn', 'irnp', 'ivrnc', 'iurc', 'iwrnr', 'irydn', 'srno', 'irbnp', 'iphn', 'irfns', 'bign', 'zisn', 'hian', 'srnq', 'oiarn', 'gvrn', 'nijrn', 'ihrt', 'cbrn', 'uiun', 'eirgn', 'iznc', 'drvn', 'lirnr', 'ymrn', 'gyirn', 'cnn', 'itre', 'kfirn', 'irwfn', 'cwn', 'ivnx', 'zinr', 'ilrnk', 'mijrn', 'irnjl', 'imrng', 'crq', 'ilryn', 'irqnp', 'qrnd', 'irnyk', 'tcn', 'ircnv', 'jirnp', 'nrnz', 'vrc', 'jiarn', 'iartn', 'irxpn', 'iqnr', 'hrnl', 'ilrqn', 'girvn', 'wrjn', 'prnh', 'yiern', 'tign', 'iawn', 'ifrjn', 'ivan', 'irign', 'dirnu', 'iwkn', 'imhrn', 'jrnd', 'rifrn', 'ixrm', 'irfu', 'irxnx', 'tirtn', 'xirb', 'irnra', 'qrv', 'wikn', 'bjrn', 'grjn', 'iorv', 'dirny', 'kiri', 'eijn', 'ilh', 'ihs', 'irnrm', 'qdrn', 'irnt', 'izrvn', 'mirnn', 'kbn', 'iyrnw', 'iho', 'lfirn', 'ifj', 'iwhrn', 'irno', 'sren', 'abirn', 'sdirn', 'ijrr', 'irnrj', 'arnl', 'iyrk', 'rnq', 'ilrvn', 'ixjn', 'ktn', 'iuh', 'irbin', 'irsns', 'irnwb', 'rqin', 'airln', 'iizrn', 'cirz', 'wcirn', 'bmn', 'idrqn', 'san', 'ihrh', 'iomn', 'ircln', 'nvrn', 'ivrne', 'iinl', 'iar', 'iorw', 'kicn', 'przn', 'gixn', 'irnn', 'uirm', 'xrs', 'crns', 'irmb', 'cimn', 'irndr', 'hirs', 'hairn', 'irwnb', 'irudn', 'uurn', 'ilkrn', 'irdz', 'hnirn', 'kryn', 'ijnq', 'iclrn', 'insrn', 'iicrn', 'iynn', 'ofirn', 'wrnp', 'irlon', 'irnql', 'ufrn', 'ioro', 'knrn', 'pirnf', 'hrnr', 'irtnu', 'rrg', 'itarn', 'irrfn', 'dfrn', 'rihrn', 'ivmn', 'ikrin', 'iaron', 'rmrn', 'firnj', 'iiqrn', 'srq', 'orjn', 'imon', 'qiorn', 'iroun', 'igyn', 'jrnn', 'isrl', 'qrny', 'izxn', 'hrl', 'iqru', 'smirn', 'irqnm', 'zinrn', 'inrne', 'irons', 'ierc', 'cirnz', 'uire', 'irazn', 'ixrw', 'irycn', 'iqm', 'birtn', 'firno', 'imf', 'irkw', 'bren', 'nra', 'vifn', 'nrm', 'xiqrn', 'urhn', 'ixrnh', 'tirnr', 'irnrl', 'uiprn', 'mdrn', 'kiru', 'tirnt', 'ihrs', 'irunm', 'idu', 'irlu', 'iirno', 'crnc', 'eibn', 'irjen', 'icurn', 'iqy', 'mkirn', 'zien', 'iirb', 'irc', 'iaqn', 'irnpj', 'imrnb', 'lrnp', 'irkny', 'ziwrn', 'urb', 'ifjrn', 'irxbn', 'librn', 'rrq', 'uihn', 'jirc', 'iint', 'krnu', 'qrnq', 'ormn', 'ilp', 'isnf', 'girnd', 'izran', 'rii', 'aian', 'ipnk', 'irshn', 'zrh', 'irhjn', 'iormn', 'ignx', 'ikrnc', 'iuarn', 'yirni', 'idnr', 'ijnl', 'irqnf', 'izzn', 'ilcrn', 'isry', 'eivrn', 'indn', 'icrnq', 'brhn', 'irinb', 'innc', 'irnza', 'mrdn', 'iqprn', 'mlirn', 'iydrn', 'irlnw', 'idurn', 'irunn', 'prnv', 'ficn', 'izzrn', 'irau', 'oifrn', 'vzn', 'nwrn', 'trnh', 'ixwn', 'iart', 'irnsr', 'irtnx', 'ggirn', 'nxn', 'krdn', 'ika', 'iwg', 'dirnv', 'cirnr', 'xjrn', 'iaa', 'scirn', 'iun', 'igrs', 'givn', 'iuon', 'ironf', 'girbn', 'ikron', 'krw', 'virs', 'vrr', 'buirn', 'irnfb', 'iwen', 'kcirn', 'fxn', 'irbnf', 'krm', 'ijrrn', 'ikf', 'irqjn', 'iral', 'irxkn', 'imxrn', 'xrtn', 'ifnm', 'eirc', 'iuf', 'ivra', 'cirqn', 'iirpn', 'aiyrn', 'rirna', 'izvn', 'igrqn', 'irnck', 'iozrn', 'iertn', 'prr', 'itrvn', 'irgnj', 'grs', 'qrb', 'kinr', 'igz', 'grl', 'mfrn', 'vwn', 'bihn', 'iwnv', 'irqny', 'kirrn', 'ihrni', 'ihrp', 'yirc', 'aien', 'iarh', 'oisn', 'irsh', 'gxirn', 'einn', 'rirng', 'airnl', 'hirdn', 'irnrp', 'prsn', 'ezn', 'iju', 'irany', 'grnf', 'rzirn', 'drnk', 'iacrn', 'kirnu', 'irsnf', 'qdirn', 'iprn', 'iwnu', 'zzn', 'ifmrn', 'eiru', 'iuirn', 'myirn', 'wrtn', 'irmnk', 'irnah', 'izny', 'irnhl', 'iknt', 'irtnv', 'ixarn', 'mrnm', 'irano', 'ojn', 'mirtn', 'uren', 'xirc', 'irfi', 'drr', 'in', 'xrnu', 'crnh', 'lirj', 'itnd', 'irnxq', 'ilrnz', 'viorn', 'hnn', 'itny', 'srw', 'rrj', 'mipn', 'irui', 'ixrnl', 'eijrn', 'ijnw', 'ziyrn', 'gixrn', 'ixxrn', 'ifrnr', 'virnl', 'or', 'grnk', 'jrp', 'rinrn', 'erq', 'inu', 'hirna', 'irxgn', 'irnvn', 'tirt', 'ihrv', 'aiwrn', 'gnirn', 'lrpn', 'rrxn', 'uien', 'idqrn', 'firx', 'uion', 'irmnf', 'trgn', 'iuan', 'zrna', 'urnr', 'ricn', 'irwc', 'ikran', 'zilrn', 'oqirn', 'ijryn', 'irvj', 'aira', 'irxnl', 'irknw', 'hbrn', 'irnhb', 'iaen', 'iore', 'binrn', 'iuo', 'irnxn', 'iraz', 'ikrq', 'iut', 'brin', 'vrl', 'imlrn', 'rird', 'iqvn', 'intn', 'iojn', 'iurne', 'ibryn', 'icsn', 'jkrn', 'ixrn', 'ite', 'irnjh', 'coirn', 'ijrbn', 'isrni', 'niwrn', 'iv', 'iwzn', 'cirq', 'krf', 'uirnj', 'ijun', 'hrx', 'dzrn', 'ciorn', 'ikng', 'vrnw', 'ireu', 'ianc', 'kirne', 'irxx', 'izl', 'iraln', 'uirfn', 'girx', 'sirpn', 'eirnn', 'ljrn', 'irtj', 'uan', 'uru', 'gjirn', 'vgrn', 'idrcn', 'inarn', 'nigrn', 'an', 'girnh', 'torn', 'gtn', 'riryn', 'uira', 'iryan', 'trrn', 'irka', 'fuirn', 'iwnt', 'cin', 'jrnt', 'ircqn', 'irke', 'aqrn', 'irbkn', 'ivl', 'iptrn', 'ilrpn', 'hirr', 'irhyn', 'ofn', 'idrnm', 'dirv', 'wirzn', 'nrnn', 'irxng', 'vixrn', 'ziirn', 'airon', 'itjn', 'air', 'irrwn', 'ierna', 'iwrk', 'iqhn', 'iitn', 'bibn', 'izrdn', 'blirn', 'ctrn', 'dirxn', 'irzsn', 'imnd', 'iny', 'ianv', 'irrnz', 'dixn', 'izrnl', 'rirnm', 'cqn', 'frwn', 'biwrn', 'ztirn', 'pron', 'idrnj', 'ioi', 'xiwn', 'ipryn', 'iolrn', 'rizn', 'rpn', 'krnv', 'irsk', 'idrdn', 'isrnn', 'wrno', 'krnp', 'nirnn', 'iroan', 'dra', 'irwnc', 'timrn', 'ixqrn', 'riqn', 'urnd', 'irnin', 'drnw', 'irdn', 'givrn', 'vrh', 'irnot', 'ilna', 'ory', 'lirnk', 'iarnb', 'irbnl', 'irfnj', 'eirdn', 'aarn', 'jry', 'wimn', 'qyrn', 'tfrn', 'iec', 'ri', 'grun', 'lirc', 'lire', 'irqng', 'inkrn', 'irnil', 'lrvn', 'ibrln', 'nrnk', 'hirmn', 'hirf', 'iirln', 'iibn', 'birz', 'kirnp', 'cibrn', 'tir', 'ngrn', 'fird', 'wrn', 'bairn', 'drirn', 'aire', 'iarnh', 'zirnl', 'rd', 'kiurn', 'lrt', 'irrnk', 'irqbn', 'ysrn', 'iiern', 'iutrn', 'wirm', 'zisrn', 'icrnn', 'inrno', 'irnch', 'srns', 'wrna', 'purn', 'irnkw', 'jrt', 'iurbn', 'pdirn', 'irhng', 'iwrx', 'xrna', 'ibf', 'iere', 'crw', 'mrnq', 'ixt', 'imt', 'kijrn', 'qrc', 'iqbn', 'wrun', 'eirnw', 'ifnp', 'rirkn', 'drx', 'acn', 'rinv', 'twn', 'dwn', 'ihrd', 'iwron', 'inhr', 'sprn', 'irknd', 'iranc', 'ibk', 'arz', 'iwnm', 'tiarn', 'pirun', 'ierl', 'kirc', 'fkn', 'ithrn', 'irinc', 'pijrn', 'miren', 'ifun', 'xixrn', 'dnirn', 'irsbn', 'irtnk', 'irkdn', 'irnje', 'hir', 'irfnc', 'cryn', 'irxfn', 'inrng', 'idrt', 'iylrn', 'ixrnk', 'lirb', 'ikh', 'lrxn', 'qrns', 'iic', 'frg', 'igno', 'gcn', 'parn', 'inpn', 'ucn', 'ukrn', 'yiirn', 'irnnq', 'iakrn', 'cirb', 'irwmn', 'jru', 'dbn', 'vrg', 'hrns'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Candidate tokens\n",
        "\n",
        "The two `generate_edits*` functions produce lots of possible tokens, but we know only a few are actually known tokens. And by known tokens, we mean tokens that we have seen in our Reddit post dataset.\n",
        "\n",
        "**Exercise:** Using the `generate_edits*` functions above, write a function `get_candidate_tokens` that given a token and the unigram counts, returns a **set** of candidate tokens that are within two edit distance and appear in the corpus.\n",
        "\n",
        "Specifically the candidate tokens should be:\n",
        "- Only the input token if it is in our corpus\n",
        "- All the tokens that are 1 or 2 edits away **and** are in our corpus\n",
        "- Only the input token if there are no other candidate tokens\n",
        "\n",
        "**Note:** If the input token is in the corpus, it should only return that token so that we don't try to correct it to something else. And if there are no tokens within two edit distances and appear , it should still return the token so that a spelling corrector is given one option to use."
      ],
      "metadata": {
        "id": "MwSJiVJBMhI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_candidate_tokens(token, unigram_counts):\n",
        "  # your code!\n",
        "  if token in unigram_counts:\n",
        "        return {token}\n",
        "\n",
        "  candidates = set()\n",
        "\n",
        "  # 1-edit-distance candidates\n",
        "  for t in generate_edits1(token):\n",
        "        if t in unigram_counts:\n",
        "            candidates.add(t)\n",
        "\n",
        "  # 2-edit-distance candidates\n",
        "  for t in generate_edits2(token):\n",
        "        if t in unigram_counts:\n",
        "            candidates.add(t)\n",
        "\n",
        "  # If no candidates found, return the original token\n",
        "  if not candidates:\n",
        "        return {token}\n",
        "\n",
        "  return candidates\n",
        "\n",
        "get_candidate_tokens('hellp', {'hello':1,'hi':1,'bye':1,'ahoy':1})"
      ],
      "metadata": {
        "id": "bd4jNiSDZb_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91bd09bb-cef6-4f8f-e932-a29222683b24"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hello'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(get_candidate_tokens)"
      ],
      "metadata": {
        "id": "bmFHfJxLML86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10744d3d-7b40-42ad-922f-86e9593ebde2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 6 testcases\n",
            "----------------------------\n",
            "Input: ('tey', {'me': 1, 'sun': 3, 'heavy': 1, 'sea': 2, 'her': 1}). Running... \n",
            "Output: {'sea', 'her', 'me'}\n",
            "OK.\n",
            "\n",
            "Input: ('cofee', {'typical': 2, 'will': 2, 'come': 3, 'codes': 1}). Running... \n",
            "Output: {'come', 'codes'}\n",
            "OK.\n",
            "\n",
            "Input: ('coffee', {'spent': 3, 'coffee': 1, 'offer': 1, 'coffees': 2, 'color': 2}). Running... \n",
            "Output: {'coffee'}\n",
            "OK.\n",
            "\n",
            "Input: ('spda', {'pc': 2, 'spin': 1, 'pad': 1}). Running... \n",
            "Output: {'pad', 'spin'}\n",
            "OK.\n",
            "\n",
            "Input: ('brw', {'arm': 1, 'mystery': 2, 'dew': 3, 'filled': 2}). Running... \n",
            "Output: {'arm', 'dew'}\n",
            "OK.\n",
            "\n",
            "Input: ('cofee', {}). Running... \n",
            "Output: {'cofee'}\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "6 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what the candidates are for 'brp' using the Reddit data"
      ],
      "metadata": {
        "id": "LMuZg9X1N2TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_candidate_tokens('brp', posts_unigram_counts)"
      ],
      "metadata": {
        "id": "BFol2PBWjEH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4a3492-32f7-43da-86b7-ad49c7f824b1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'amp',\n",
              " 'ap',\n",
              " 'app',\n",
              " 'are',\n",
              " 'arm',\n",
              " 'art',\n",
              " 'b',\n",
              " 'bad',\n",
              " 'bag',\n",
              " 'ban',\n",
              " 'bao',\n",
              " 'bar',\n",
              " 'bare',\n",
              " 'bark',\n",
              " 'barq',\n",
              " 'bars',\n",
              " 'bat',\n",
              " 'bay',\n",
              " 'bbc',\n",
              " 'bc',\n",
              " 'bd',\n",
              " 'be',\n",
              " 'bed',\n",
              " 'beg',\n",
              " 'bet',\n",
              " 'bf',\n",
              " 'bg',\n",
              " 'big',\n",
              " 'bin',\n",
              " 'bird',\n",
              " 'bit',\n",
              " 'biz',\n",
              " 'bkf',\n",
              " 'bl',\n",
              " 'blu',\n",
              " 'bob',\n",
              " 'bog',\n",
              " 'boo',\n",
              " 'born',\n",
              " 'bot',\n",
              " 'box',\n",
              " 'boy',\n",
              " 'bpm',\n",
              " 'br',\n",
              " 'brew',\n",
              " 'brim',\n",
              " 'brit',\n",
              " 'bros',\n",
              " 'brow',\n",
              " 'bru',\n",
              " 'bs',\n",
              " 'btw',\n",
              " 'bud',\n",
              " 'bug',\n",
              " 'burn',\n",
              " 'burr',\n",
              " 'bury',\n",
              " 'bus',\n",
              " 'but',\n",
              " 'buy',\n",
              " 'bw',\n",
              " 'bww',\n",
              " 'by',\n",
              " 'cap',\n",
              " 'cp',\n",
              " 'crop',\n",
              " 'cry',\n",
              " 'cup',\n",
              " 'dr',\n",
              " 'drip',\n",
              " 'drm',\n",
              " 'drop',\n",
              " 'drs',\n",
              " 'dry',\n",
              " 'earp',\n",
              " 'edp',\n",
              " 'era',\n",
              " 'erh',\n",
              " 'erm',\n",
              " 'fp',\n",
              " 'frc',\n",
              " 'fro',\n",
              " 'fry',\n",
              " 'gr',\n",
              " 'grd',\n",
              " 'grip',\n",
              " 'hop',\n",
              " 'hr',\n",
              " 'hrs',\n",
              " 'ip',\n",
              " 'ir',\n",
              " 'irc',\n",
              " 'irn',\n",
              " 'isp',\n",
              " 'jp',\n",
              " 'lp',\n",
              " 'map',\n",
              " 'mbp',\n",
              " 'mp',\n",
              " 'mr',\n",
              " 'ncp',\n",
              " 'nrs',\n",
              " 'op',\n",
              " 'or',\n",
              " 'ori',\n",
              " 'p',\n",
              " 'pb',\n",
              " 'pbr',\n",
              " 'pop',\n",
              " 'pre',\n",
              " 'pro',\n",
              " 'pry',\n",
              " 'psp',\n",
              " 'pvp',\n",
              " 'qr',\n",
              " 'r',\n",
              " 'rc',\n",
              " 're',\n",
              " 'rep',\n",
              " 'rf',\n",
              " 'rm',\n",
              " 'rn',\n",
              " 'rpg',\n",
              " 'rt',\n",
              " 'rx',\n",
              " 'sip',\n",
              " 'sp',\n",
              " 'sup',\n",
              " 'tap',\n",
              " 'tbsp',\n",
              " 'tip',\n",
              " 'top',\n",
              " 'tp',\n",
              " 'tpp',\n",
              " 'tr',\n",
              " 'trap',\n",
              " 'tri',\n",
              " 'trip',\n",
              " 'try',\n",
              " 'up',\n",
              " 'ur',\n",
              " 'ura',\n",
              " 'vip',\n",
              " 'vr',\n",
              " 'vrr',\n",
              " 'xr',\n",
              " 'yep',\n",
              " 'yr',\n",
              " 'yrs'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using a language model for ranking candidates\n",
        "\n",
        "For a given misspelt token, we can now get a list of plausible tokens. We need to rank them to choose the likeliest.\n",
        "\n",
        "Enter the language model! It can give us the probability of a token, potentially taking the context into account. In the case of the unigram model, it ignores previous tokens but we know that a language model can factor in previous tokens. Let's try with the unigram model first.\n",
        "\n",
        "**Exercise:** Write a function `unigram_spelling_correct` that given a misspelled token (and unigram information), gets a list of candidate tokens, calculates their unigram probabilities and returns the candidate with the highest likelihood.\n",
        "\n",
        "You will want to use `get_candidate_tokens` and `unigram_token_prob` from before."
      ],
      "metadata": {
        "id": "rWMyslE2OALs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unigram_spelling_correct(token, unigram_counts, unigram_N):\n",
        "  # your code!\n",
        "    candidates = get_candidate_tokens(token, unigram_counts)\n",
        "\n",
        "    best_token = None\n",
        "    best_prob = 0.0\n",
        "\n",
        "    for cand in candidates:\n",
        "        prob = unigram_token_prob(cand, unigram_counts, unigram_N)\n",
        "        if prob > best_prob:\n",
        "            best_prob = prob\n",
        "            best_token = cand\n",
        "\n",
        "    return best_token\n",
        "unigram_spelling_correct('gmaig', posts_unigram_counts, posts_unigram_N)"
      ],
      "metadata": {
        "id": "qzdW5CUBauxi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d28c271c-0a82-4bad-f995-450eb02b01de"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gaming'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(unigram_spelling_correct)"
      ],
      "metadata": {
        "id": "Mtl0LTwlkwC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3a80cd-09a5-413b-ea3f-d595218d4621"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('tey', {'heavy': 1, 'sun': 3, 'her': 1, 'sea': 2, 'me': 1}, 8). Running... \n",
            "Output: sea\n",
            "OK.\n",
            "\n",
            "Input: ('cofee', {'will': 2, 'codes': 2, 'come': 3, 'typical': 1}, 8). Running... \n",
            "Output: come\n",
            "OK.\n",
            "\n",
            "Input: ('coffee', {'offer': 3, 'coffee': 1, 'coffees': 1, 'spent': 2, 'color': 2}, 9). Running... \n",
            "Output: coffee\n",
            "OK.\n",
            "\n",
            "Input: ('spda', {'spin': 2, 'pad': 1, 'pc': 1}, 4). Running... \n",
            "Output: spin\n",
            "OK.\n",
            "\n",
            "Input: ('brw', {'mystery': 1, 'filled': 2, 'dew': 3, 'arm': 2}, 8). Running... \n",
            "Output: dew\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnLb1hI4cyYi"
      },
      "source": [
        "Excellent, now let's step through how the spelling correction is being done for an example token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRV-SUcO6DJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9d8506-674e-4971-ee90-9b4a7c404b67"
      },
      "source": [
        "token = \"gmaig\"\n",
        "#token = TRY YOUR WORD\n",
        "\n",
        "candidates = get_candidate_tokens(token, posts_unigram_counts)\n",
        "print(\"Spelling candidates for:\", token)\n",
        "for candidate in candidates:\n",
        "  p = unigram_token_prob(candidate, posts_unigram_counts, posts_unigram_N)\n",
        "  print(f\"{candidate}\\t{p:.7f}\")\n",
        "\n",
        "# The correction takes the token that has the highest probability (occurs most often).\n",
        "correction = unigram_spelling_correct(token, posts_unigram_counts, posts_unigram_N)\n",
        "print(f\"\\nSelected correction: {correction}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spelling candidates for: gmaig\n",
            "main\t0.0002376\n",
            "gain\t0.0000211\n",
            "gaming\t0.0005015\n",
            "mail\t0.0001214\n",
            "gang\t0.0000053\n",
            "gtaiv\t0.0000106\n",
            "grain\t0.0000053\n",
            "email\t0.0000686\n",
            "\n",
            "Selected correction: gaming\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rrpbrcXecGz"
      },
      "source": [
        "Woohoo! We have a very basic reddit spelling corrector.\n",
        "Try it yourself on other words.\n",
        "\n",
        "However, as we'll see it's not perfect.  Let's look at a few sequences below and see what it does to each token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6fMOvSyCJL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59003199-c732-44f5-8c14-ca991c0967dd"
      },
      "source": [
        "strings = [\"it is amazon\", \"http www amazin\"]\n",
        "for s in strings:\n",
        "  tokens = text_pipeline_spacy_special(s)\n",
        "  corrections = []\n",
        "  for t in tokens:\n",
        "    correction = unigram_spelling_correct(t, posts_unigram_counts, posts_unigram_N)\n",
        "    corrections.append(correction)\n",
        "  print(s, corrections)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it is amazon ['it', 'is', 'amazon']\n",
            "http www amazin ['help', 'was', 'again']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbC0-w0et6F"
      },
      "source": [
        "Not so 'amazing'. In both of these cases, we estimated the likelihood of spelling correcting each word on its own,  independently.  This fails in obvious cases where the correct word should be apparent given the sequence.\n",
        "\n",
        "We can do better by taking two factors into account:\n",
        "\n",
        "1. Computing the probability of the whole sequence of token (in case there are multiple spelling mistakes)\n",
        "2. Using token context (bi-grams and trigrams) to improve the token probability estimate\n",
        "\n",
        "We'll look at the second idea in the following sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRslwUFqDn_t"
      },
      "source": [
        "## N-Gram Language Models\n",
        "\n",
        "The unigram model isn't a very good one - it doesn't model any previous context. On the other hand, we can't model _all_ of the preceding tokens, because that history will get prohibitively long and extremely sparse. As a compromise, we make a _Markov assumption_ and limit ourselves to a finite history of $n$ tokens.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OpxWsOoFf1F"
      },
      "source": [
        "### Constructing a bigram model\n",
        "\n",
        "For now, we'll build a bigram model, which considers only the preceding token:\n",
        "\n",
        "$$ P(w_i\\ |\\ w_{0}, ..., w_{i-1}) \\approx P(w_i\\ |\\ w_{i-1}) $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC5tanICEigU"
      },
      "source": [
        "\n",
        "We want to calculate the probability of one token following the other using the counts of that bigram $C_{ab}$ and the count of the first token $C_a$.\n",
        "\n",
        "$$  P_{ab} = P(w_i = b\\ |\\ w_{i-1} = a) = \\frac{C_{ab}}{C_{a}} $$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we can generate probabilities from bigrams, we need to know the frequency that bigrams appear in our data.\n",
        "\n",
        "**Exercise:** Write a function `count_bigrams` that given a flattened list of tokens returns a [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) mapping tuples (pairs of neighbouring tokens) to their count in the tokens.\n",
        "\n",
        "For example `count_bigrams(['a','b','c'])` should give a Counter with values `{ ('a','b'):1, ('b','c'):1 }`"
      ],
      "metadata": {
        "id": "ObV3pvpupK47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_bigrams(flattened):\n",
        "  # your code!\n",
        "    bigrams = Counter()\n",
        "    for i in range(len(flattened) - 1):\n",
        "        bigrams[(flattened[i], flattened[i + 1])] += 1\n",
        "    return bigrams\n",
        "count_bigrams(['<START>','irn','bru','is','great','<START>','i','dislike','irn','bru'])"
      ],
      "metadata": {
        "id": "n4EmDhxjfAc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bbda65e-210f-48c5-f8ca-537cb2dcdcb3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({('<START>', 'irn'): 1,\n",
              "         ('irn', 'bru'): 2,\n",
              "         ('bru', 'is'): 1,\n",
              "         ('is', 'great'): 1,\n",
              "         ('great', '<START>'): 1,\n",
              "         ('<START>', 'i'): 1,\n",
              "         ('i', 'dislike'): 1,\n",
              "         ('dislike', 'irn'): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(count_bigrams)"
      ],
      "metadata": {
        "id": "lDDFIxos7NMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1a495e-2dc5-41e5-9494-e1347d528b1f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: (['accidentally', 'halo', 'halo', 'halo'],). Running... \n",
            "Output: {('accidentally', 'halo'): 1, ('halo', 'halo'): 2}\n",
            "OK.\n",
            "\n",
            "Input: (['teavana', 'teavana', 'order'],). Running... \n",
            "Output: {('teavana', 'teavana'): 1, ('teavana', 'order'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['started', 'enough', 'enough', 'started', 'enough', 'enough'],). Running... \n",
            "Output: {('started', 'enough'): 2, ('enough', 'enough'): 2, ('enough', 'started'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['hario', 'hario', 'lead'],). Running... \n",
            "Output: {('hario', 'hario'): 1, ('hario', 'lead'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['similar', 'college', 'similar'],). Running... \n",
            "Output: {('similar', 'college'): 1, ('college', 'similar'): 1}\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get the bigrams of our mini corpus:"
      ],
      "metadata": {
        "id": "X4yuV3JI7Pko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_bigrams(mini_flattened)"
      ],
      "metadata": {
        "id": "qUfyE6K6h-E6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d24081a-cc3b-4216-d0a1-1a5f40d371ba"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({('<START>', 'my'): 1,\n",
              "         ('my', 'favourite'): 1,\n",
              "         ('favourite', 'soft'): 1,\n",
              "         ('soft', 'drink'): 2,\n",
              "         ('drink', 'is'): 1,\n",
              "         ('is', 'apple'): 1,\n",
              "         ('apple', 'tango'): 1,\n",
              "         ('tango', 'but'): 1,\n",
              "         ('but', 'i'): 1,\n",
              "         ('i', 'also'): 1,\n",
              "         ('also', 'love'): 1,\n",
              "         ('love', 'irn'): 1,\n",
              "         ('irn', 'bru'): 5,\n",
              "         ('bru', '<START>'): 1,\n",
              "         ('<START>', 'irn'): 3,\n",
              "         ('bru', 'is'): 3,\n",
              "         ('is', 'a'): 2,\n",
              "         ('a', 'great'): 1,\n",
              "         ('great', 'drink'): 1,\n",
              "         ('drink', '<START>'): 1,\n",
              "         ('<START>', 'i'): 1,\n",
              "         ('i', 'once'): 1,\n",
              "         ('once', 'found'): 1,\n",
              "         ('found', 'a'): 1,\n",
              "         ('a', 'can'): 1,\n",
              "         ('can', 'of'): 1,\n",
              "         ('of', 'irn'): 1,\n",
              "         ('bru', 'in'): 1,\n",
              "         ('in', 'st'): 1,\n",
              "         ('st', 'petersburg'): 1,\n",
              "         ('petersburg', '<START>'): 1,\n",
              "         ('a', 'soft'): 1,\n",
              "         ('drink', 'launched'): 1,\n",
              "         ('launched', 'in'): 1,\n",
              "         ('in', '1901'): 1,\n",
              "         ('1901', 'by'): 1,\n",
              "         ('by', 'ag'): 1,\n",
              "         ('ag', 'barr'): 2,\n",
              "         ('barr', '<START>'): 1,\n",
              "         ('is', 'made'): 1,\n",
              "         ('made', 'at'): 1,\n",
              "         ('at', 'ag'): 1,\n",
              "         ('barr', 'in'): 1,\n",
              "         ('in', 'cumbernauld'): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate the bigrams for our Reddit posts. This will be useful!"
      ],
      "metadata": {
        "id": "KXKcWmzG7UL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "posts_bigram_counts = count_bigrams(posts_flattened_tokens)"
      ],
      "metadata": {
        "id": "UlF914RYkEp4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have a method for bigram counts, we can calculate the probability of a next word, given the previous token:\n",
        "\n",
        "$$ P(w_i \\ |\\ w_{i-1} ) $$\n",
        "\n",
        "Specifically for the probability for token $b$ following token $a$:\n",
        "\n",
        "$$  P_{ab} = P(w_i = b\\ |\\ w_{i-1} = a) = \\frac{C_{ab}}{C_{a}} $$\n",
        "\n",
        "where $C_{ab}$ is the bigram count of $(a,b)$ and $C_a$ is the unigram count of $a$.\n",
        "\n",
        "**Exercise:** Write a function `bigram_token_prob` that takes in the previous token, the next token and the unigram and bigram counts and calculates the conditional probability of the next token given the previous token."
      ],
      "metadata": {
        "id": "hbfJQJU27Xrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_token_prob(prev_token, next_token, unigram_counts, bigram_counts):\n",
        "  # your code!\n",
        "    if prev_token not in unigram_counts:\n",
        "        return 0.0\n",
        "\n",
        "    bigram = (prev_token, next_token)\n",
        "\n",
        "    # If the bigram never appeared, probability is zero\n",
        "    if bigram not in bigram_counts:\n",
        "        return 0.0\n",
        "\n",
        "    return bigram_counts[bigram] / unigram_counts[prev_token]\n",
        "\n",
        "bigram_token_prob('irn', 'bru', posts_unigram_counts, posts_bigram_counts)"
      ],
      "metadata": {
        "id": "eEn6cYwVj9Ou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98863bdb-8f39-4e3c-84b9-6132152847fc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(bigram_token_prob)"
      ],
      "metadata": {
        "id": "DwHbsQOoBnY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e9303b-26f9-484a-b182-fdd53491d453"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('a', 'b', {'a': 8, 'b': 7}, {('a', 'a'): 2, ('a', 'b'): 2, ('b', 'a'): 4, ('b', 'b'): 3}). Running... \n",
            "Output: 0.25\n",
            "OK.\n",
            "\n",
            "Input: ('b', 'b', {'a': 8, 'b': 9}, {('a', 'a'): 1, ('a', 'b'): 2, ('b', 'a'): 1, ('b', 'b'): 4}). Running... \n",
            "Output: 0.44444\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'b', {'a': 7, 'b': 6}, {('a', 'a'): 3, ('a', 'b'): 1, ('b', 'a'): 1, ('b', 'b'): 1}). Running... \n",
            "Output: 0.14286\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'b', {'a': 7, 'b': 6}, {('a', 'a'): 1, ('a', 'b'): 3, ('b', 'a'): 4, ('b', 'b'): 2}). Running... \n",
            "Output: 0.42857\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'b', {'a': 5, 'b': 5}, {('a', 'a'): 1, ('a', 'b'): 2, ('b', 'a'): 2, ('b', 'b'): 1}). Running... \n",
            "Output: 0.4\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using bigrams for spelling correction\n",
        "\n",
        "We'll use our bigram model to improve our spelling correction model. This time it will use the prior token to give some context to the probability calculations.\n",
        "\n",
        "**Exercise:** Write a function `bigram_spelling_correct` that takes in the previous token, the token to be spell-checked, the unigram/bigram counts and uses the bigram probability function (from above) to find the most likely token. Look back at your `unigram_spelling_correct` function."
      ],
      "metadata": {
        "id": "Za8mdM5c8xQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_spelling_correct(prev_token, token, unigram_counts, bigram_counts):\n",
        "    candidates = get_candidate_tokens(token, unigram_counts)\n",
        "\n",
        "    best_token = None\n",
        "    best_prob = 0.0\n",
        "\n",
        "    for cand in candidates:\n",
        "        prob = bigram_token_prob(prev_token, cand,\n",
        "                                 unigram_counts, bigram_counts)\n",
        "        if prob > best_prob:\n",
        "            best_prob = prob\n",
        "            best_token = cand\n",
        "\n",
        "    if best_token is None:\n",
        "        return unigram_spelling_correct(token, unigram_counts)\n",
        "\n",
        "    return best_token\n",
        "  # your code!\n",
        "\n",
        "bigram_spelling_correct('irn', 'burp', posts_unigram_counts, posts_bigram_counts)"
      ],
      "metadata": {
        "id": "WmZv74ZXl6Tj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "78711a4d-3d2c-4cec-c15d-9ded50ca54c0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bru'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(bigram_spelling_correct)"
      ],
      "metadata": {
        "id": "OuipSIjJ-rdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edfd6cf1-e0c1-4f0c-a0eb-3cd0a060ad0a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('i', 'hcacn', Counter({'where': 7, 'i': 6, 'can': 6}), Counter({('i', 'can'): 4, ('where', 'i'): 3})). Running... \n",
            "Output: can\n",
            "OK.\n",
            "\n",
            "Input: ('the', 'owvnyr', Counter({'the': 9, 'and': 8, 'owner': 5}), Counter({('and', 'the'): 2, ('the', 'owner'): 1})). Running... \n",
            "Output: owner\n",
            "OK.\n",
            "\n",
            "Input: ('life', 'gtze', Counter({'life': 7, 'her': 6, 'the': 6}), Counter({('her', 'life'): 3, ('life', 'the'): 1})). Running... \n",
            "Output: the\n",
            "OK.\n",
            "\n",
            "Input: ('it', 's', Counter({'it': 8, 'is': 7, 'says': 5}), Counter({('it', 'is'): 2, ('says', 'it'): 1})). Running... \n",
            "Output: is\n",
            "OK.\n",
            "\n",
            "Input: ('as', 'hmcin', Counter({'main': 9, 'linked': 8, 'as': 6}), Counter({('as', 'main'): 1, ('linked', 'as'): 1})). Running... \n",
            "Output: main\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try the 'gmaig' example from before (which previously was corrected to 'gaming'). What if we give it another context. Maybe the token before it is 'e'? How does that change it?"
      ],
      "metadata": {
        "id": "reOHTEDz-sa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_spelling_correct('e', 'gmaig', posts_unigram_counts, posts_bigram_counts)"
      ],
      "metadata": {
        "id": "tKwzswAm-sh4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab6c7942-ec88-4ba9-e3bd-9a512ee93389"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mail'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neat! With a different context, the most likely token changes.\n",
        "\n",
        "A bigram model gave some context. Maybe a trigram model would be better. Well, we're going to look at trigrams, but for a different problem!"
      ],
      "metadata": {
        "id": "0NbFZUbM_C1h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZbqWAJFJ_qP"
      },
      "source": [
        "## Application: Generating fake Reddit posts\n",
        "\n",
        "Language models are *generative*.  They model the probability of generating a sequence of tokens. The probabilities can be used in interesting ways, for example to score sequences or even to generate made up text sequences iteratively.\n",
        "\n",
        "We're going to use trigrams to capture a bit more about language and use them to generate some fake Reddit posts. To get started, we need to calculate trigram counts.\n",
        "\n",
        "**Exercise:** Write a function `count_trigrams` that returns a Counter that contains the counts of all trigrams from the input text.\n",
        "\n",
        "For example `count_trigrams(['a','b','c','d'])` should give a Counter with values `{ ('a','b','c'):1, ('b','c','d'):1 }`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_trigrams(flattened):\n",
        "  # your code!\n",
        "    trigrams = Counter()\n",
        "    for i in range(len(flattened) - 2):\n",
        "        trigrams[(flattened[i], flattened[i + 1], flattened[i + 2])] += 1\n",
        "    return trigrams\n",
        "\n",
        "count_trigrams(['<START>','irn','bru','is','great','<START>','i','dislike','irn','bru'])"
      ],
      "metadata": {
        "id": "Ixlhi6djoZZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b51ed328-e57d-4c85-9c9d-c43916c3e54e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({('<START>', 'irn', 'bru'): 1,\n",
              "         ('irn', 'bru', 'is'): 1,\n",
              "         ('bru', 'is', 'great'): 1,\n",
              "         ('is', 'great', '<START>'): 1,\n",
              "         ('great', '<START>', 'i'): 1,\n",
              "         ('<START>', 'i', 'dislike'): 1,\n",
              "         ('i', 'dislike', 'irn'): 1,\n",
              "         ('dislike', 'irn', 'bru'): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(count_trigrams)"
      ],
      "metadata": {
        "id": "uTORvdhFFUD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cb325c-f02d-42c7-8e4d-139f3aa079cc"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: (['accidentally', 'halo', 'halo', 'halo'],). Running... \n",
            "Output: {('accidentally', 'halo', 'halo'): 1, ('halo', 'halo', 'halo'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['teavana', 'teavana', 'order'],). Running... \n",
            "Output: {('teavana', 'teavana', 'order'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['started', 'enough', 'enough', 'started', 'enough', 'enough'],). Running... \n",
            "Output: {('started', 'enough', 'enough'): 2, ('enough', 'enough', 'started'): 1, ('enough', 'started', 'enough'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['hario', 'hario', 'lead'],). Running... \n",
            "Output: {('hario', 'hario', 'lead'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['similar', 'college', 'similar'],). Running... \n",
            "Output: {('similar', 'college', 'similar'): 1}\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get the trigrams from our Reddit posts:"
      ],
      "metadata": {
        "id": "doh2Tc-8Fc-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "posts_trigram_counts = count_trigrams(posts_flattened_tokens)"
      ],
      "metadata": {
        "id": "Xn79VVtzqPDF"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need a function that gets us the conditional trigram probability. What is the probability of a token given the two previous tokens?\n",
        "\n",
        "$$ P(w_i \\ |\\ w_{i-1}, w_{i-2} ) $$\n",
        "\n",
        "In this case, we want to calculate the probability of a trigram using the trigram count for that triple and the bigram count of the first two tokens.\n",
        "\n",
        "**Exercise:** Write a function `trigram_token_prob` that takes in the two previous tokens, the next token and the bigram & trigram count data. It should output the probability of the next token given the two prior tokens using the bigram and trigram counts."
      ],
      "metadata": {
        "id": "SsvdRnxpFiIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trigram_token_prob(prev_prev_token, prev_token, next_token, bigram_counts, trigram_counts):\n",
        "  # your code!\n",
        "    if (prev_prev_token, prev_token) not in bigram_counts:\n",
        "        return 0.0\n",
        "\n",
        "    trigram = (prev_prev_token,prev_token, next_token)\n",
        "\n",
        "    # If the bigram never appeared, probability is zero\n",
        "    if trigram not in trigram_counts:\n",
        "        return 0.0\n",
        "\n",
        "    return trigram_counts[trigram] / bigram_counts[(prev_prev_token,prev_token)]\n",
        "\n",
        "trigram_token_prob('i', 'walk', 'around', posts_bigram_counts, posts_trigram_counts)"
      ],
      "metadata": {
        "id": "7KuBiHmspmox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a08ec8-4154-4c0f-d5c1-507bc8f46e49"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(trigram_token_prob)"
      ],
      "metadata": {
        "id": "ZUr1JeDLojR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2704120-4b26-49b6-baf8-6a513392967c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('c', 'a', 'a', Counter({('a', 'a'): 5, ('c', 'a'): 3, ('c', 'c'): 3}), Counter({('c', 'a', 'a'): 1, ('c', 'c', 'a'): 1})). Running... \n",
            "Output: 0.33333\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'c', 'a', Counter({('a', 'a'): 4, ('a', 'c'): 4, ('c', 'a'): 4}), Counter({('a', 'a', 'c'): 1, ('a', 'c', 'a'): 1})). Running... \n",
            "Output: 0.25\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'b', 'c', Counter({('a', 'a'): 5, ('a', 'b'): 4, ('b', 'c'): 4, ('c', 'a'): 4}), Counter({('a', 'b', 'c'): 2, ('c', 'a', 'a'): 2, ('a', 'a', 'b'): 1})). Running... \n",
            "Output: 0.5\n",
            "OK.\n",
            "\n",
            "Input: ('c', 'b', 'b', Counter({('a', 'a'): 5, ('a', 'c'): 4, ('c', 'b'): 4, ('b', 'b'): 3}), Counter({('a', 'c', 'b'): 2, ('c', 'b', 'b'): 2, ('a', 'a', 'c'): 1})). Running... \n",
            "Output: 0.5\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'b', 'b', Counter({('a', 'b'): 5, ('b', 'b'): 3}), Counter({('a', 'b', 'b'): 2})). Running... \n",
            "Output: 0.4\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to get the probability of all possible tokens after two previous tokens. We'll store this probability distribution as a dictionary mapping a potential token to its probabilities.\n",
        "\n",
        "The `get_trigram_distribution` below iterates through all the possible tokens (which are all the unigrams) and calculates their conditional trigram probability."
      ],
      "metadata": {
        "id": "JVpnGeevGFH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trigram_distribution(prev_prev_token, prev_token, unigram_counts, bigram_counts, trigram_counts):\n",
        "  prob_distribution = {}\n",
        "  for token in unigram_counts:\n",
        "    p = trigram_token_prob(prev_prev_token, prev_token, token, bigram_counts, trigram_counts)\n",
        "    prob_distribution[token] = p\n",
        "  return prob_distribution"
      ],
      "metadata": {
        "id": "j1taysLdrMVM"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what the distribution looks like for a sequence starting \"i like\":"
      ],
      "metadata": {
        "id": "fDDdhGm1HFcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_trigram_distribution('i','like', posts_unigram_counts, posts_bigram_counts, posts_trigram_counts)"
      ],
      "metadata": {
        "id": "UFp-8T6vGypx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c7c4d6-e6bd-480e-88bb-7d92b53bc2f3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<START>': 0.0,\n",
              " 'anyone': 0.0,\n",
              " 'tried': 0.0,\n",
              " 'irn': 0.0,\n",
              " 'bru': 0.0,\n",
              " 'it': 0.0784313725490196,\n",
              " '’s': 0.0,\n",
              " 'a': 0.058823529411764705,\n",
              " 'scottish': 0.0,\n",
              " 'drink': 0.0,\n",
              " 'and': 0.0,\n",
              " 'banned': 0.0,\n",
              " 'some': 0.0,\n",
              " 'countries': 0.0,\n",
              " 'i': 0.0196078431372549,\n",
              " 'was': 0.0,\n",
              " 'wondering': 0.0,\n",
              " 'if': 0.0,\n",
              " 'here': 0.0,\n",
              " 'has': 0.0,\n",
              " 'quite': 0.0,\n",
              " 'unique': 0.0,\n",
              " 'taste': 0.0,\n",
              " 'not': 0.0,\n",
              " 'something': 0.0,\n",
              " 'you': 0.0,\n",
              " '’d': 0.0,\n",
              " 'forget': 0.0,\n",
              " 'quickly': 0.0,\n",
              " 'either': 0.0,\n",
              " 'love': 0.0,\n",
              " 'or': 0.0,\n",
              " 'hate': 0.0,\n",
              " 'think': 0.0,\n",
              " 'what': 0.0196078431372549,\n",
              " 'is': 0.0,\n",
              " 'the': 0.13725490196078433,\n",
              " 'worst': 0.0,\n",
              " 'of': 0.0,\n",
              " 'sodas': 0.0,\n",
              " 'have': 0.0,\n",
              " 'drunk': 0.0,\n",
              " 'absolute': 0.0,\n",
              " 'soda': 0.0,\n",
              " 've': 0.0,\n",
              " 'ever': 0.0,\n",
              " 'had': 0.0,\n",
              " 'that': 0.0,\n",
              " 'can': 0.0,\n",
              " 'remember': 0.0,\n",
              " 'probaly': 0.0,\n",
              " 'new': 0.0196078431372549,\n",
              " 'mystery': 0.0,\n",
              " 'fanta': 0.0,\n",
              " 'watermelon+strawberry': 0.0,\n",
              " 'tango': 0.0,\n",
              " 'other': 0.0,\n",
              " 'ones': 0.0,\n",
              " 'include': 0.0,\n",
              " 'mango': 0.0,\n",
              " 'coke': 0.0,\n",
              " 'sugar': 0.0,\n",
              " 'free': 0.0,\n",
              " 'but': 0.0,\n",
              " 'xtra': 0.0,\n",
              " 'nice': 0.0,\n",
              " 'once': 0.0,\n",
              " 'box': 0.0,\n",
              " 'tea': 0.0196078431372549,\n",
              " 'believe': 0.0,\n",
              " 'highland': 0.0,\n",
              " 'black': 0.0196078431372549,\n",
              " 'recommend': 0.0,\n",
              " 'me': 0.0,\n",
              " 'along': 0.0,\n",
              " 'those': 0.0,\n",
              " 'lines': 0.0,\n",
              " \"'d\": 0.0,\n",
              " 'like': 0.0,\n",
              " 'to': 0.17647058823529413,\n",
              " 'repurchase': 0.0,\n",
              " 'this': 0.0196078431372549,\n",
              " 'find': 0.0,\n",
              " 'exact': 0.0,\n",
              " 'do': 0.0,\n",
              " \"n't\": 0.0,\n",
              " 'want': 0.0,\n",
              " 'buy': 0.0,\n",
              " 'am': 0.0,\n",
              " 'sure': 0.0,\n",
              " 'will': 0.0,\n",
              " 'be': 0.0,\n",
              " 'good': 0.0,\n",
              " \"ddos'd\": 0.0,\n",
              " 'my': 0.0,\n",
              " 'city': 0.0,\n",
              " 'named': 0.0,\n",
              " 'kicked': 0.0,\n",
              " 'from': 0.0,\n",
              " 'party': 0.0,\n",
              " 'by': 0.0,\n",
              " 'person': 0.0,\n",
              " 'who': 0.0,\n",
              " 'leader': 0.0,\n",
              " 'nor': 0.0,\n",
              " 'he': 0.0,\n",
              " 'in': 0.0,\n",
              " 'hi': 0.0,\n",
              " 'question': 0.0,\n",
              " 'someone': 0.0,\n",
              " 'joined': 0.0,\n",
              " 'our': 0.0,\n",
              " '1': 0.0,\n",
              " 'said': 0.0,\n",
              " 'state': 0.0,\n",
              " 'live': 0.0,\n",
              " 'smaller': 0.0,\n",
              " 'goes': 0.0,\n",
              " 'big': 0.0,\n",
              " 'so': 0.0,\n",
              " 'name': 0.0,\n",
              " 'specific': 0.0,\n",
              " 'scary': 0.0,\n",
              " 'say': 0.0,\n",
              " 'least': 0.0,\n",
              " '2': 0.0,\n",
              " 'kept': 0.0,\n",
              " 'kicking': 0.0,\n",
              " 'us': 0.0,\n",
              " 'out': 0.0,\n",
              " 'despite': 0.0,\n",
              " 'fact': 0.0,\n",
              " 'most': 0.0,\n",
              " 'definitely': 0.0,\n",
              " 'being': 0.0,\n",
              " 'done': 0.0,\n",
              " 'kid': 0.0,\n",
              " 'supposed': 0.0,\n",
              " 'when': 0.0,\n",
              " 'happens': 0.0,\n",
              " 'than': 0.0,\n",
              " 'report': 0.0,\n",
              " 'there': 0.0,\n",
              " 'any': 0.0,\n",
              " 'recourse': 0.0,\n",
              " 'hun': 0.0,\n",
              " 'really': 0.0,\n",
              " 'running': 0.0,\n",
              " 'small': 0.0,\n",
              " 'business': 0.0,\n",
              " 'then': 0.0,\n",
              " 'surely': 0.0,\n",
              " 'they': 0.0,\n",
              " 'comply': 0.0,\n",
              " 'with': 0.0,\n",
              " 'gdpr': 0.0,\n",
              " 'which': 0.0,\n",
              " 'means': 0.0,\n",
              " 'no': 0.0,\n",
              " 'contact': 0.0,\n",
              " 'unless': 0.0,\n",
              " 'previously': 0.0,\n",
              " 'stipulated': 0.0,\n",
              " 'help': 0.0,\n",
              " \"'m\": 0.0,\n",
              " 'super': 0.0196078431372549,\n",
              " 'dehydrated': 0.0,\n",
              " 'ca': 0.0,\n",
              " 'fet': 0.0,\n",
              " 'myself': 0.0,\n",
              " 'more': 0.0,\n",
              " 'used': 0.0,\n",
              " 'specialized': 0.0,\n",
              " 'scale': 0.0,\n",
              " 'only': 0.0,\n",
              " '54': 0.0,\n",
              " 'water': 0.0,\n",
              " 'instead': 0.0,\n",
              " '70': 0.0,\n",
              " 'how': 0.0196078431372549,\n",
              " 'force': 0.0,\n",
              " 'where': 0.0,\n",
              " 'source': 0.0,\n",
              " \"pu'er\": 0.0,\n",
              " 'early': 0.0,\n",
              " '90': 0.0,\n",
              " \"'s\": 0.0,\n",
              " 'found': 0.0,\n",
              " 'lots': 0.0,\n",
              " 'apparently': 0.0,\n",
              " 'online': 0.0,\n",
              " 'however': 0.0,\n",
              " 'know': 0.0,\n",
              " 'sites': 0.0,\n",
              " 'companies': 0.0,\n",
              " 'trust': 0.0,\n",
              " 'looking': 0.0,\n",
              " 'for': 0.0,\n",
              " 'an': 0.0,\n",
              " 'anniversary': 0.0,\n",
              " 'present': 0.0,\n",
              " 'would': 0.0,\n",
              " 'grown': 0.0,\n",
              " 'processed': 0.0,\n",
              " '1991': 0.0,\n",
              " 'as': 0.0,\n",
              " 'close': 0.0,\n",
              " 'possible': 0.0,\n",
              " 'advice': 0.0,\n",
              " 'on': 0.0,\n",
              " 'helpful': 0.0,\n",
              " 'based': 0.0,\n",
              " 'uk': 0.0,\n",
              " 'ship': 0.0,\n",
              " 'without': 0.0,\n",
              " 'too': 0.0,\n",
              " 'much': 0.0,\n",
              " 'trouble': 0.0,\n",
              " 'great': 0.0,\n",
              " 'thanks': 0.0,\n",
              " 'day': 0.0,\n",
              " 'tapping': 0.0,\n",
              " 'tapir': 0.0,\n",
              " '\\u200b': 0.0,\n",
              " '12': 0.0,\n",
              " 'flavours': 0.0,\n",
              " 'sparkling': 0.0,\n",
              " 'tasted': 0.0,\n",
              " 'amazing': 0.0,\n",
              " 'artwork': 0.0,\n",
              " 'design': 0.0,\n",
              " 'these': 0.0196078431372549,\n",
              " 'cans': 0.0,\n",
              " 'are': 0.0,\n",
              " 'did': 0.0,\n",
              " 'opened': 0.0,\n",
              " 'each': 0.0,\n",
              " 'yet': 0.0,\n",
              " 'hibiscus': 0.0,\n",
              " 'lime': 0.0,\n",
              " 'flower': 0.0,\n",
              " 'flavour': 0.0,\n",
              " 'please': 0.0,\n",
              " 'game': 0.0,\n",
              " '10': 0.0,\n",
              " 'years': 0.0,\n",
              " 'ago': 0.0,\n",
              " 'loved': 0.0,\n",
              " 'n’t': 0.0,\n",
              " 'now': 0.0,\n",
              " 'show': 0.0,\n",
              " 'battle': 0.0,\n",
              " 'royale': 0.0,\n",
              " 'thing': 0.0,\n",
              " 'all': 0.0392156862745098,\n",
              " 'contestants': 0.0,\n",
              " 'killed': 0.0,\n",
              " 'prize': 0.0,\n",
              " 'characters': 0.0,\n",
              " 'naked': 0.0,\n",
              " 'lady': 0.0,\n",
              " 'purple': 0.0,\n",
              " 'penguin': 0.0,\n",
              " 'eugene': 0.0,\n",
              " 'little': 0.0,\n",
              " 'rich': 0.0,\n",
              " 'girl': 0.0,\n",
              " 'charity': 0.0,\n",
              " 'just': 0.0,\n",
              " 'need': 0.0,\n",
              " 'thank': 0.0,\n",
              " 'got': 0.0,\n",
              " 'xbox': 0.0,\n",
              " 'series': 0.0,\n",
              " 's': 0.0,\n",
              " 'type': 0.0,\n",
              " 'since': 0.0,\n",
              " '360': 0.0,\n",
              " 'pretty': 0.0,\n",
              " 'make': 0.0,\n",
              " 'account': 0.0,\n",
              " 'before': 0.0,\n",
              " 'even': 0.0,\n",
              " 'turn': 0.0,\n",
              " 'system': 0.0,\n",
              " 'could': 0.0,\n",
              " 'go': 0.0,\n",
              " 'website': 0.0,\n",
              " '’m': 0.0,\n",
              " 'bottle': 0.0,\n",
              " 'get': 0.0,\n",
              " 'mine': 0.0,\n",
              " 'cheap': 0.0,\n",
              " 'broken': 0.0,\n",
              " 'caffeine': 0.0,\n",
              " 'shortage': 0.0,\n",
              " 'nos': 0.0,\n",
              " 'certain': 0.0,\n",
              " 'drinks': 0.0,\n",
              " 'stock': 0.0,\n",
              " 'started': 0.0,\n",
              " 'over': 0.0,\n",
              " 'labor': 0.0,\n",
              " 'holiday': 0.0,\n",
              " 'visiting': 0.0,\n",
              " 'parents': 0.0,\n",
              " 'two': 0.0,\n",
              " 'separate': 0.0,\n",
              " 'royal': 0.0,\n",
              " 'farms': 0.0,\n",
              " 'convenience': 0.0,\n",
              " 'stores': 0.0,\n",
              " 'went': 0.0,\n",
              " 'turbo': 0.0,\n",
              " 'available': 0.0,\n",
              " 'shelves': 0.0,\n",
              " 'flavors': 0.0,\n",
              " 'varieties': 0.0,\n",
              " 'were': 0.0,\n",
              " 'empty': 0.0,\n",
              " 'caused': 0.0,\n",
              " 'look': 0.0,\n",
              " 'notice': 0.0,\n",
              " 'several': 0.0,\n",
              " 'open': 0.0196078431372549,\n",
              " 'slots': 0.0,\n",
              " 'around': 0.0,\n",
              " 'refrigerator': 0.0,\n",
              " 'case': 0.0,\n",
              " 'peninsula': 0.0,\n",
              " 'at': 0.0,\n",
              " 'beach': 0.0,\n",
              " 'chalked': 0.0,\n",
              " 'up': 0.0,\n",
              " 'distribution': 0.0,\n",
              " 'issues': 0.0,\n",
              " 'locally': 0.0,\n",
              " 'back': 0.0,\n",
              " 'home': 0.0,\n",
              " 'still': 0.0,\n",
              " 'seeing': 0.0,\n",
              " 'rows': 0.0,\n",
              " 'local': 0.0,\n",
              " 'sheetz': 0.0,\n",
              " 'longer': 0.0,\n",
              " 'pick': 0.0,\n",
              " '8': 0.0,\n",
              " 'pack': 0.0,\n",
              " 'grocery': 0.0,\n",
              " 'store': 0.0,\n",
              " 'granted': 0.0,\n",
              " 'always': 0.0,\n",
              " 'been': 0.0,\n",
              " 'hit': 0.0,\n",
              " 'miss': 0.0,\n",
              " 'about': 0.0196078431372549,\n",
              " 'keeping': 0.0,\n",
              " 'poor': 0.0,\n",
              " 'inventory': 0.0,\n",
              " 'management': 0.0,\n",
              " 'symptom': 0.0,\n",
              " 'supply': 0.0,\n",
              " 'chain': 0.0,\n",
              " 'issue': 0.0,\n",
              " 'happened': 0.0,\n",
              " 'gsync': 0.0,\n",
              " 'monitors': 0.0,\n",
              " 'going': 0.0,\n",
              " 'released': 0.0,\n",
              " 'seems': 0.0,\n",
              " 'we': 0.0,\n",
              " 'heard': 0.0,\n",
              " 'them': 0.0392156862745098,\n",
              " 'months': 0.0,\n",
              " 'forward': 0.0,\n",
              " 'getting': 0.0,\n",
              " 'one': 0.0,\n",
              " 'dark': 0.0,\n",
              " 'their': 0.0,\n",
              " 'release': 0.0,\n",
              " 'dates': 0.0,\n",
              " 'kit': 0.0,\n",
              " 'because': 0.0,\n",
              " '$': 0.0,\n",
              " '100': 0.0,\n",
              " 'waited': 0.0,\n",
              " 'official': 0.0,\n",
              " 'worth': 0.0,\n",
              " 'scored': 0.0,\n",
              " 'bunch': 0.0,\n",
              " 'syrup': 0.0,\n",
              " 'month': 0.0,\n",
              " 'purchased': 0.0,\n",
              " 'stream': 0.0,\n",
              " 'machine': 0.0,\n",
              " \"'ve\": 0.0,\n",
              " 'having': 0.0,\n",
              " 'fun': 0.0,\n",
              " 'yesterday': 0.0,\n",
              " 'work': 0.0,\n",
              " 'decided': 0.0,\n",
              " 'rid': 0.0,\n",
              " 'fountain': 0.0,\n",
              " 'setup': 0.0,\n",
              " 'leftover': 0.0,\n",
              " 'syrups': 0.0,\n",
              " '5': 0.0,\n",
              " 'gallons': 0.0,\n",
              " 'cherry': 0.0,\n",
              " 'pepsi': 0.0,\n",
              " 'diet': 0.0,\n",
              " 'yuck': 0.0,\n",
              " 'gallon': 0.0,\n",
              " 'mountain': 0.0,\n",
              " 'dew': 0.0,\n",
              " 'sierra': 0.0,\n",
              " 'mist': 0.0,\n",
              " 'figured': 0.0,\n",
              " 'ratio': 0.0,\n",
              " 'liter': 0.0,\n",
              " 'bottles': 0.0,\n",
              " 'seem': 0.0,\n",
              " 'take': 0.0,\n",
              " '1/2': 0.0,\n",
              " '3/4': 0.0,\n",
              " 'cup': 0.0,\n",
              " 'retailers': 0.0,\n",
              " 'put': 0.0,\n",
              " 'queues': 0.0,\n",
              " 'x': 0.0,\n",
              " 'does': 0.0,\n",
              " 'queue': 0.0,\n",
              " 'reason': 0.0,\n",
              " 'unreleastic': 0.0,\n",
              " 'times': 0.0,\n",
              " 'last': 0.0,\n",
              " 'using': 0.0,\n",
              " 'walmart': 0.0,\n",
              " 'plus': 0.0,\n",
              " 'paid': 0.0,\n",
              " 'version': 0.0,\n",
              " 'trial': 0.0,\n",
              " 'best': 0.0,\n",
              " 'brand': 0.0,\n",
              " 'milk': 0.0,\n",
              " 'w/': 0.0,\n",
              " 'boba': 0.0,\n",
              " 'gon': 0.0,\n",
              " 'na': 0.0,\n",
              " 'give': 0.0,\n",
              " 'making': 0.0,\n",
              " 'try': 0.0,\n",
              " 'brands': 0.0,\n",
              " 'breakfast': 0.0,\n",
              " 'use': 0.0,\n",
              " 'preferably': 0.0,\n",
              " 'amazon': 0.0,\n",
              " 'shipping': 0.0,\n",
              " 'tips': 0.0,\n",
              " 'r': 0.0,\n",
              " 'hydrohomies': 0.0,\n",
              " 'community': 0.0,\n",
              " 'fundraiser': 0.0,\n",
              " 'homies': 0.0,\n",
              " 'long': 0.0,\n",
              " 'time': 0.0,\n",
              " '’ve': 0.0,\n",
              " 'asking': 0.0,\n",
              " 'potential': 0.0,\n",
              " 'starting': 0.0,\n",
              " 'your': 0.0,\n",
              " 'own': 0.0,\n",
              " 'posted': 0.0,\n",
              " 'survey': 0.0,\n",
              " 'interest': 0.0,\n",
              " 'amount': 0.0,\n",
              " 'responses': 0.0,\n",
              " 'proud': 0.0,\n",
              " 'announce': 0.0,\n",
              " 'first': 0.0,\n",
              " 'purpose': 0.0,\n",
              " 'bring': 0.0,\n",
              " 'almost': 0.0196078431372549,\n",
              " 'million': 0.0,\n",
              " 'members': 0.0,\n",
              " 'together': 0.0,\n",
              " 'people': 0.0,\n",
              " 'proper': 0.0,\n",
              " 'access': 0.0,\n",
              " 'doing': 0.0,\n",
              " 'through': 0.0,\n",
              " 'water.org': 0.0,\n",
              " 'money': 0.0,\n",
              " 'straight': 0.0,\n",
              " 'also': 0.0,\n",
              " 'launching': 0.0,\n",
              " 'merch': 0.0,\n",
              " 'shop': 0.0,\n",
              " 'profit': 0.0,\n",
              " 'sales': 0.0,\n",
              " 'towards': 0.0,\n",
              " 'run': 0.0,\n",
              " 'until': 0.0,\n",
              " 'july': 0.0,\n",
              " '15th': 0.0,\n",
              " 'initial': 0.0,\n",
              " 'goal': 0.0,\n",
              " '1,000': 0.0,\n",
              " 'raised': 0.0,\n",
              " 'link': 0.0,\n",
              " 'ac': 0.0,\n",
              " 'valhalla': 0.0,\n",
              " 'pc': 0.0,\n",
              " 'performance': 0.0,\n",
              " 'experience': 0.0,\n",
              " 'mods': 0.0,\n",
              " 'auto': 0.0,\n",
              " 'removing': 0.0,\n",
              " 'comments': 0.0,\n",
              " 'regarding': 0.0,\n",
              " 'sub': 0.0,\n",
              " 'share': 0.0,\n",
              " 'concerns': 0.0,\n",
              " 'ubisoft': 0.0,\n",
              " 'customer': 0.0,\n",
              " 'blown': 0.0,\n",
              " 'away': 0.0,\n",
              " '30': 0.0,\n",
              " 'fps': 0.0,\n",
              " 'high': 0.0,\n",
              " 'medium': 0.0,\n",
              " 'settings': 0.0,\n",
              " 'gtx1080': 0.0,\n",
              " 'stuttering': 0.0,\n",
              " 'terrible': 0.0,\n",
              " 'detail': 0.0,\n",
              " 'levels': 0.0,\n",
              " 'bad': 0.0,\n",
              " 'played': 0.0,\n",
              " 'legion': 0.0,\n",
              " 'ran': 0.0,\n",
              " 'better': 0.0,\n",
              " 'thought': 0.0,\n",
              " 'incase': 0.0,\n",
              " 'wanted': 0.0,\n",
              " 'avoid': 0.0,\n",
              " 'launch': 0.0,\n",
              " 'edit': 0.0,\n",
              " 'everyone': 0.0,\n",
              " 'cpu': 0.0,\n",
              " 'resolution': 0.0,\n",
              " 'i7': 0.0,\n",
              " '8700k': 0.0,\n",
              " '3440x1440': 0.0,\n",
              " 'ultrawide': 0.0,\n",
              " 'already': 0.0,\n",
              " 'knew': 0.0,\n",
              " 'end': 0.0,\n",
              " 'coming': 0.0,\n",
              " 'memory': 0.0,\n",
              " 'bottleneck': 0.0,\n",
              " 'add': 0.0,\n",
              " 'fan': 0.0,\n",
              " 'changes': 0.0,\n",
              " 'made': 0.0,\n",
              " 'far': 0.0,\n",
              " 'favorite': 0.0,\n",
              " 'pulled': 0.0,\n",
              " 'into': 0.0,\n",
              " 'insurance': 0.0,\n",
              " 'mlm': 0.0,\n",
              " 'licensed': 0.0,\n",
              " 'producer': 0.0,\n",
              " 'off': 0.0,\n",
              " 'tail': 0.0,\n",
              " 'medicare': 0.0,\n",
              " 'annual': 0.0,\n",
              " 'enrollment': 0.0,\n",
              " 'another': 0.0,\n",
              " 'position': 0.0,\n",
              " 'actively': 0.0,\n",
              " 'applying': 0.0,\n",
              " 'indeed': 0.0,\n",
              " 'contacted': 0.0,\n",
              " 'hart': 0.0,\n",
              " 'group': 0.0,\n",
              " 'dug': 0.0,\n",
              " 'applied': 0.0,\n",
              " 'jobs': 0.0,\n",
              " 'perplexed': 0.0,\n",
              " 'nothing': 0.0,\n",
              " 'under': 0.0,\n",
              " 'uncommon': 0.0,\n",
              " 'receive': 0.0,\n",
              " 'outbound': 0.0,\n",
              " 'contacts': 0.0,\n",
              " 'agencies': 0.0,\n",
              " 'especially': 0.0,\n",
              " 'prior': 0.0,\n",
              " 'accepting': 0.0,\n",
              " 'today': 0.0,\n",
              " 'realized': 0.0,\n",
              " 'mistake': 0.0,\n",
              " 'never': 0.0,\n",
              " 'should': 0.0,\n",
              " 'red': 0.0,\n",
              " 'flag': 0.0,\n",
              " 'logged': 0.0,\n",
              " 'onto': 0.0,\n",
              " 'overview': 0.0,\n",
              " 'zoom': 0.0,\n",
              " 'call': 0.0,\n",
              " 'given': 0.0,\n",
              " 'american': 0.0,\n",
              " 'income': 0.0,\n",
              " 'life': 0.0196078431372549,\n",
              " 'immediately': 0.0,\n",
              " 'set': 0.0,\n",
              " 'alarm': 0.0,\n",
              " 'bells': 0.0,\n",
              " 'head': 0.0,\n",
              " 'research': 0.0,\n",
              " 'pertaining': 0.0,\n",
              " 'accident': 0.0,\n",
              " 'health': 0.0,\n",
              " 'license': 0.0,\n",
              " 'few': 0.0,\n",
              " 'pyramid': 0.0,\n",
              " 'schemes': 0.0,\n",
              " 'deeper': 0.0,\n",
              " 'flags': 0.0,\n",
              " 'promised': 0.0,\n",
              " 'major': 0.0,\n",
              " 'commission': 0.0,\n",
              " '80k+': 0.0,\n",
              " 'year': 0.0,\n",
              " 'vacations': 0.0,\n",
              " 'rewards': 0.0,\n",
              " 'sock': 0.0,\n",
              " 'reviews': 0.0,\n",
              " 'talking': 0.0,\n",
              " 'pay': 0.0,\n",
              " 'boss': 0.0,\n",
              " 'every': 0.0,\n",
              " 'statement': 0.0,\n",
              " 'promise': 0.0,\n",
              " 'textbook': 0.0,\n",
              " 'recruitment': 0.0,\n",
              " 'garbage': 0.0,\n",
              " 'shocked': 0.0,\n",
              " 'recruited': 0.0,\n",
              " 'defeated': 0.0,\n",
              " 'left': 0.0,\n",
              " 'told': 0.0,\n",
              " 'interested': 0.0,\n",
              " 'wholeheartedly': 0.0,\n",
              " 'believed': 0.0,\n",
              " 'fell': 0.0,\n",
              " 'tactics': 0.0,\n",
              " 'let': 0.0,\n",
              " 'foot': 0.0,\n",
              " 'door': 0.0,\n",
              " 'staunch': 0.0,\n",
              " 'roles': 0.0,\n",
              " 'doubt': 0.0,\n",
              " 'sunk': 0.0,\n",
              " 'teeth': 0.0,\n",
              " 'cold': 0.0,\n",
              " 'world': 0.0,\n",
              " 'stay': 0.0,\n",
              " 'alert': 0.0,\n",
              " 'gongfu': 0.0,\n",
              " 'western': 0.0,\n",
              " 'wanna': 0.0,\n",
              " 'maximize': 0.0,\n",
              " 'cups': 0.0,\n",
              " 'buying': 0.0,\n",
              " 'higher': 0.0,\n",
              " 'quality': 0.0,\n",
              " 'loose': 0.0,\n",
              " 'leaf': 0.0,\n",
              " 'teas': 0.0,\n",
              " 'sample': 0.0,\n",
              " 'different': 0.0,\n",
              " 'g': 0.0,\n",
              " 'diff': 0.0,\n",
              " 'kinds': 0.0,\n",
              " 'oolongs': 0.0,\n",
              " 'jin': 0.0,\n",
              " 'xuan': 0.0,\n",
              " 'tgy': 0.0,\n",
              " 'dried': 0.0,\n",
              " 'chamomile': 0.0,\n",
              " 'brew': 0.0,\n",
              " 'style': 0.0,\n",
              " '3': 0.0,\n",
              " 'max': 0.0,\n",
              " 'doctor': 0.0,\n",
              " 'recommendation': 0.0,\n",
              " 'same': 0.0,\n",
              " '+': 0.0,\n",
              " 'save': 0.0,\n",
              " 'leftovers': 0.0,\n",
              " 're': 0.0,\n",
              " 'infusion': 0.0,\n",
              " 'leaves': 0.0,\n",
              " 'stick': 0.0,\n",
              " 'roasted': 0.0,\n",
              " 'oolong': 0.0,\n",
              " 'lasted': 0.0,\n",
              " '4': 0.0,\n",
              " 'infusions': 0.0,\n",
              " 'stored': 0.0,\n",
              " 'bowl': 0.0,\n",
              " 'lined': 0.0,\n",
              " 'paper': 0.0,\n",
              " 'towels': 0.0,\n",
              " 'counter': 0.0,\n",
              " 'top': 0.0,\n",
              " 'idk': 0.0,\n",
              " 'optimal': 0.0,\n",
              " 'request': 0.0,\n",
              " 'flairs': 0.0,\n",
              " 'pre': 0.0,\n",
              " 'orders': 0.0,\n",
              " 'begun': 0.0,\n",
              " 'ordered': 0.0,\n",
              " 'xsx': 0.0,\n",
              " 'india': 0.0,\n",
              " 'xss': 0.0,\n",
              " 'why': 0.0,\n",
              " '60fps': 0.0,\n",
              " 'watching': 0.0,\n",
              " 'youtube': 0.0,\n",
              " '60': 0.0,\n",
              " 'videos': 0.0,\n",
              " 'weird': 0.0,\n",
              " 'smooth': 0.0,\n",
              " 'gta': 0.0,\n",
              " 'v': 0.0,\n",
              " 'video': 0.0,\n",
              " 'looked': 0.0,\n",
              " 'play': 0.0,\n",
              " 'games': 0.0,\n",
              " 'anything': 0.0,\n",
              " 'ideas': 0.0,\n",
              " 'u.s.': 0.0,\n",
              " 'switch': 0.0,\n",
              " 'owners': 0.0,\n",
              " 'minecraft': 0.0,\n",
              " 'u.k.': 0.0,\n",
              " 'eshop': 0.0,\n",
              " 'roughly': 0.0,\n",
              " 'cheaper': 0.0,\n",
              " '£': 0.0,\n",
              " '19.99': 0.0,\n",
              " 'unhappy': 0.0,\n",
              " 'price': 0.0,\n",
              " 'tag': 0.0,\n",
              " 'q': 0.0,\n",
              " 'fruit': 0.0,\n",
              " 'flavored': 0.0,\n",
              " 'strawberry': 0.0,\n",
              " 'lemon': 0.0,\n",
              " 'echinachea': 0.0,\n",
              " 'etc': 0.0,\n",
              " 'advertise': 0.0,\n",
              " 'omit': 0.0,\n",
              " 'chai': 0.0,\n",
              " 'gives': 0.0,\n",
              " 'coffee': 0.0,\n",
              " 'post': 0.0,\n",
              " 'cafe': 0.0,\n",
              " 'stages': 0.0,\n",
              " 'designing': 0.0,\n",
              " 'café': 0.0,\n",
              " 'inspiration': 0.0,\n",
              " ':p': 0.0,\n",
              " 'somewhere': 0.0,\n",
              " 'designs': 0.0,\n",
              " 'browse': 0.0,\n",
              " 'and/or': 0.0,\n",
              " 'recommendations': 0.0,\n",
              " 'gladly': 0.0,\n",
              " 'welcome': 0.0,\n",
              " 'bunn': 0.0,\n",
              " 'sticker': 0.0,\n",
              " 'burr': 0.0,\n",
              " 'upgrade': 0.0,\n",
              " 'noticed': 0.0,\n",
              " 'electrical': 0.0,\n",
              " 'info': 0.0,\n",
              " 'serial': 0.0,\n",
              " 'number': 0.0,\n",
              " 'wh': 0.0,\n",
              " 'numbers': 0.0,\n",
              " 'correlate': 0.0,\n",
              " 'confirm': 0.0,\n",
              " 'way': 0.0,\n",
              " 'many': 0.0,\n",
              " 'stickers': 0.0,\n",
              " 'seen': 0.0,\n",
              " 'gifted': 0.0,\n",
              " 'refurbished': 0.0,\n",
              " 'looks': 0.0,\n",
              " 'says': 0.0,\n",
              " '1117': 0.0,\n",
              " 'nov': 0.0,\n",
              " '2017': 0.0,\n",
              " 'unit': 0.0,\n",
              " 'hot': 0.0,\n",
              " 'dog': 0.0,\n",
              " 'burrs': 0.0,\n",
              " 'nt': 0.0,\n",
              " 'ditting': 0.0,\n",
              " 'wonder': 0.0,\n",
              " 'its': 0.0,\n",
              " '430': 0.0,\n",
              " 'discerning': 0.0,\n",
              " 'plate': 0.0,\n",
              " 'days': 0.0,\n",
              " 'less': 0.0196078431372549,\n",
              " 'ek43': 0.0,\n",
              " 'obvious': 0.0,\n",
              " 'dooo': 0.0,\n",
              " 'gosh': 0.0,\n",
              " 'seriously': 0.0,\n",
              " 'known': 0.0,\n",
              " 'avid': 0.0,\n",
              " 'hater': 0.0,\n",
              " 'visit': 0.0,\n",
              " '2x': 0.0,\n",
              " 'friend': 0.0,\n",
              " 'yl': 0.0,\n",
              " 'shiller': 0.0,\n",
              " 'whose': 0.0,\n",
              " 'fb': 0.0,\n",
              " 'posts': 0.0,\n",
              " 'shared': 0.0,\n",
              " 'sent': 0.0,\n",
              " 'text': 0.0,\n",
              " 'she': 0.0,\n",
              " 'working': 0.0,\n",
              " 'episode': 0.0,\n",
              " 'workaholics': 0.0,\n",
              " 'distracted': 0.0,\n",
              " 'thinking': 0.0,\n",
              " 'invited': 0.0,\n",
              " 'page': 0.0,\n",
              " 'saw': 0.0,\n",
              " 'r+f': 0.0,\n",
              " 'see': 0.0,\n",
              " 'interesting': 0.0,\n",
              " 'leave': 0.0,\n",
              " 'asap': 0.0,\n",
              " 'lol': 0.0,\n",
              " 'dr': 0.0,\n",
              " 'pepper': 0.0,\n",
              " 'cream': 0.0,\n",
              " 'missing': 0.0,\n",
              " 'sold': 0.0,\n",
              " 'pennsylvania': 0.0,\n",
              " 'btw': 0.0,\n",
              " 'egg': 0.0,\n",
              " 'preorder': 0.0,\n",
              " 'start': 0.0,\n",
              " '/r': 0.0,\n",
              " 'teacup': 0.0,\n",
              " 'idea': 0.0,\n",
              " 'might': 0.0,\n",
              " 'guys': 0.0,\n",
              " 'subreddit': 0.0,\n",
              " 'teacups': 0.0,\n",
              " 'heavily': 0.0,\n",
              " 'promoted': 0.0,\n",
              " 'sidebar': 0.0,\n",
              " 'willing': 0.0,\n",
              " 'sell': 0.0,\n",
              " 'revenue': 0.0,\n",
              " 'paying': 0.0,\n",
              " 'coders': 0.0,\n",
              " 'awesome': 0.0,\n",
              " 'contests': 0.0,\n",
              " 'giveaways': 0.0,\n",
              " 'enough': 0.0,\n",
              " 'maybe': 0.0,\n",
              " 'able': 0.0,\n",
              " 'cool': 0.0,\n",
              " 'tldr': 0.0,\n",
              " 'monoprice': 0.0,\n",
              " 'reveals': 0.0,\n",
              " 'ips': 0.0,\n",
              " '11': 0.0,\n",
              " '2013': 0.0,\n",
              " 'listed': 0.0,\n",
              " 'after': 0.0,\n",
              " 'discontinuing': 0.0,\n",
              " 'older': 0.0,\n",
              " 'models': 0.0,\n",
              " 'word': 0.0,\n",
              " 'expect': 0.0,\n",
              " 'http://www.monoprice.com/product?c_id=113&cp_id=11307&cs_id=1130703&p_id=10734&seq=1&format=2': 0.0,\n",
              " 'led': 0.0,\n",
              " 'backlit': 0.0,\n",
              " 'specifically': 0.0,\n",
              " 'actually': 0.0,\n",
              " 'unlike': 0.0,\n",
              " 'complained': 0.0,\n",
              " 'tempted': 0.0,\n",
              " 'order': 0.0,\n",
              " 'display': 0.0,\n",
              " 'knows': 0.0,\n",
              " 'discount': 0.0,\n",
              " 'code': 0.0,\n",
              " 'speak': 0.0,\n",
              " 'forth': 0.0,\n",
              " 'opinions': 0.0,\n",
              " 'normal': 0.0,\n",
              " 'ps4': 0.0,\n",
              " 'trying': 0.0,\n",
              " 'grand': 0.0,\n",
              " 'theft': 0.0,\n",
              " 'playstation': 0.0,\n",
              " 'comes': 0.0,\n",
              " 'premium': 0.0,\n",
              " 'edition': 0.0,\n",
              " 'ons': 0.0,\n",
              " 'matcha': 0.0,\n",
              " 'lattes': 0.0,\n",
              " 'recently': 0.0,\n",
              " 'vanilla': 0.0,\n",
              " 'steamed': 0.0,\n",
              " 'coconut': 0.0,\n",
              " 'almond': 0.0,\n",
              " 'packet': 0.0,\n",
              " 'stevia': 0.0,\n",
              " 'school': 0.0,\n",
              " 'rotation': 0.0,\n",
              " 'read': 0.0,\n",
              " 'meant': 0.0,\n",
              " 'fast': 0.0,\n",
              " 'lot': 0.0,\n",
              " 'yours': 0.0,\n",
              " 'x.': 0.0,\n",
              " 'next': 0.0,\n",
              " 'gen': 0.0,\n",
              " 'point': 0.0,\n",
              " 'update': 0.0,\n",
              " 'specs': 0.0,\n",
              " 'stuff': 0.0,\n",
              " 'full': 0.0,\n",
              " 'consoles': 0.0,\n",
              " '17': 0.0,\n",
              " 'promotional': 0.0,\n",
              " 'posters': 0.0,\n",
              " 'promo': 0.0,\n",
              " 'mua3': 0.0,\n",
              " 'ssbu': 0.0,\n",
              " 'fortnite': 0.0,\n",
              " 'poster': 0.0,\n",
              " 'nintendo': 0.0,\n",
              " 'mall': 0.0,\n",
              " 'event': 0.0,\n",
              " 'summer': 0.0,\n",
              " 'gave': 0.0,\n",
              " 'nephew': 0.0,\n",
              " 'list': 0.0,\n",
              " 'advance': 0.0,\n",
              " 'converter': 0.0,\n",
              " 'between': 0.0,\n",
              " '3.5': 0.0,\n",
              " 'mm': 0.0,\n",
              " 'digital': 0.0,\n",
              " 'audio': 0.0,\n",
              " 'everything': 0.0,\n",
              " 'allows': 0.0,\n",
              " 'plug': 0.0,\n",
              " 'cable': 0.0,\n",
              " 'jack': 0.0,\n",
              " 'pluck': 0.0,\n",
              " 'dac': 0.0,\n",
              " \"y'\": 0.0,\n",
              " 'consignment': 0.0,\n",
              " 'things': 0.0,\n",
              " 'across': 0.0,\n",
              " 'rack': 0.0,\n",
              " 'skirts': 0.0,\n",
              " 'cheesy': 0.0,\n",
              " 'color': 0.0,\n",
              " 'combos': 0.0,\n",
              " 'felt': 0.0,\n",
              " 'tags': 0.0,\n",
              " 'lularoe': 0.0,\n",
              " 'picture': 0.0,\n",
              " 'mind': 0.0,\n",
              " 'hauling': 0.0,\n",
              " 'serious': 0.0,\n",
              " 'tasting': 0.0,\n",
              " 'corner': 0.0,\n",
              " 'apart': 0.0,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we wanted to generate text, we could choose the token with the highest probability. But that quickly generates boring text. Instead we are going to sample from this distribution, where tokens with higher probability have a higher chance of being chosen.\n",
        "\n",
        "The `sample_from_distribution` function takes a token distribution (like we've calculated above) and randomly chooses a token based on the probabilities."
      ],
      "metadata": {
        "id": "D0EGFXCYHKkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def sample_from_distribution(distribution):\n",
        "  population = list(distribution.keys())\n",
        "  probabilities = list(distribution.values())\n",
        "\n",
        "  choice, = random.choices(population, weights=probabilities, k=1)\n",
        "  return choice\n",
        "\n",
        "sample_from_distribution({'a':0.2,'b':0.5,'c':0.3})"
      ],
      "metadata": {
        "id": "CJQBr3DysMOL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b0dd94f-5c6c-47bb-cb81-33ba5c50b426"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'b'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's join our trigram distribution with the sampling code. This finds the trigram distribution that starts 'i like'. It then randomly picks a token weighted by the probabilities. Try running the cell a few times and you should get different results."
      ],
      "metadata": {
        "id": "WszeCNGiH8qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prev_prev_token, prev_token = 'i', 'like'\n",
        "trigram_distribution = get_trigram_distribution(prev_prev_token, prev_token, posts_unigram_counts, posts_bigram_counts, posts_trigram_counts)\n",
        "sample_from_distribution(trigram_distribution)"
      ],
      "metadata": {
        "id": "BRWHLDZJti-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5a3d88a-eeda-4f3d-d69b-0bb94486c42f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can put this together to generate a whole sequence of text.\n",
        "\n",
        "**Exercise:** Write a function `hallucinate_text` that takes an initial sequence of tokens, the desired length of the output sequence, and the uni/bi/trigram counts. It should calculate a trigram distribution based on the final two tokens of the sequence, sample from it to pick a new token (using `sample_from_distribution`) and add that to the list. It should then repeat this until the desired length is achieved.\n",
        "\n",
        "_Coding Tip:_ Your function should create a new list and not make edits to the input list. You may want to do `sequence = list(sequence)` to make a copy of it. Here's an [explainer](https://colab.research.google.com/drive/13DndtbgZbur0RSq2xcYOwxjdIw9LIX8E?usp=sharing) about this idea."
      ],
      "metadata": {
        "id": "vlIBAt0ZIQVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hallucinate_text(sequence, max_length, unigram_counts, bigram_counts, trigram_counts):\n",
        "  # your code!\n",
        "    \"\"\"\n",
        "    sequence: initial list of tokens\n",
        "    max_length: total length of output sequence\n",
        "    unigram_counts, bigram_counts, trigram_counts: Counters\n",
        "\n",
        "    returns: new list of tokens of length desired_length\n",
        "    \"\"\"\n",
        "    sequence = list(sequence)  # make a copy\n",
        "\n",
        "    while len(sequence) < max_length:\n",
        "        w1, w2 = sequence[-2], sequence[-1]\n",
        "        dist = {}\n",
        "\n",
        "        # Build trigram distribution P(w3 | w1, w2)\n",
        "        for (a, b, c), count in trigram_counts.items():\n",
        "            if a == w1 and b == w2:\n",
        "                dist[c] = count / bigram_counts[(w1, w2)]\n",
        "\n",
        "        # If no trigram data, stop generation\n",
        "        if not dist:\n",
        "            break\n",
        "\n",
        "        next_token = sample_from_distribution(dist)\n",
        "        sequence.append(next_token)\n",
        "\n",
        "    return sequence\n",
        "\n",
        "hallucinate_text(['i','like'], 10, posts_unigram_counts, posts_bigram_counts, posts_trigram_counts)"
      ],
      "metadata": {
        "id": "5tzedoaDtogX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40dc0959-0cec-48f8-adf0-222a932b6c93"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'like', 'rdr2', 'botw', 'and', 'fenyx', 'should', 'i', 'still', 'have']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(hallucinate_text)"
      ],
      "metadata": {
        "id": "EEcKbFsMJLLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63a6eed-9dc1-4ba1-e25f-0bf0302c36a3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 1 testcases\n",
            "----------------------------\n",
            "Input: (['i', 'like'], 3, Counter({'potatoes': 5, 'like': 4, 'i': 3}), Counter({('i', 'like'): 5}), Counter({('i', 'like', 'potatoes'): 5})). Running... \n",
            "Output: ['i', 'like', 'potatoes']\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "1 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can generate a bunch of hallucinated sentences!"
      ],
      "metadata": {
        "id": "vbTpQtCdJGIq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSI2dfh3e3q3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65603493-d649-426b-c998-40daeb68cdaa"
      },
      "source": [
        "# Maximum length of sequence to generate.\n",
        "max_length = 20\n",
        "\n",
        "# Number of sequences to generate\n",
        "num_sequences = 5\n",
        "\n",
        "start = [\"i\", \"like\"] # Needs to be an n-gram that occurs in our collection\n",
        "for _ in range(num_sequences):\n",
        "  sequence = hallucinate_text(start, max_length, posts_unigram_counts, posts_bigram_counts, posts_trigram_counts)\n",
        "  print (\" \".join(sequence))\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i like tea either grown or processed in 1991 or as close as possible any advice is appreciated <START> why\n",
            "i like less syrupy drinks what would be really slow and cause the tea we ordered revolution ginger peach tea\n",
            "i like a power a model thoughts <START> confused 1:2 ratio when doing a 1:17 ratio using about 54 g\n",
            "i like pg tips i have missed a hidden gem that deserves some love dogurai it was refurbished but it\n",
            "i like all my life who likes this soda and so begins the search for the week wanted y' all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4TLERMrKXj7"
      },
      "source": [
        "We now have a simple bot that can write reddit-like posts!  It sort-of-almost makes sense. Many naive spam bots work in a similar way by taking sample text and using it to generate made up auto-replies.\n",
        "\n",
        "Have fun with this example by modifying the starting sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buvdn5h1EGnw"
      },
      "source": [
        "## Language Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVHBk7zEo49K"
      },
      "source": [
        "Our model seems to capture some aspects of language. It often gets the idea of adjectives being before nouns, and subjects before verbs, etc. We know that it's using the probability of the token frequencies to do this. But how can we judge how well it has modelled the language?\n",
        "\n",
        "Let's evaluate our models by seeing how well they can predict real text.\n",
        "\n",
        "At this point, we are going to distinguish how well our model can predict the text it has been trained on (the **training performance**) from how well it can predict new unseen data (the **test performance**)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The novel token problem\n",
        "\n",
        "Any unseen data is very likely to have new tokens that we haven't seen before. English has a very large vocabulary, and we'd need to have a huge number of documents to contain every token. And then there are spelling mistakes, etc. So there will always be some new unknown tokens.\n",
        "\n",
        "All our language models (unigram, bigram, trigram) assume that the tokens have been seen before. How do we deal with new tokens so that our probabilities are not always zero for unseen text?\n",
        "\n",
        "For example, what's the unigram probability of 'abracadabra' which never appears in our Reddit posts."
      ],
      "metadata": {
        "id": "exYVpaioKURr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_token_prob('abracadabra', posts_unigram_counts, posts_unigram_N)"
      ],
      "metadata": {
        "id": "4X_e-l4qL_0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b9bda3-13fc-4e70-924b-dad72682ad66"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So any sequence containing that token would have a probability of zero. And that's true for any new token not in our original text data."
      ],
      "metadata": {
        "id": "WhJvxFqKMSBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Smoothing (Add-K / Laplace)\n",
        "\n",
        "Smoothing a language model gives some probability to unseen words, even if it is very little. This enables unseen text to not automatically have a zero probability.\n",
        "\n",
        "There were a few methods of smoothing mentioned in the lecture. We're going to implement Add-K / Laplacian Smoothing to our unigram model.\n",
        "\n",
        "The unigram probability is modified by effectively adding a value $k$ to the count of every possible token.\n",
        "\n",
        "$$ P(t) = \\frac{count(t) + k}{\\sum_{t' \\in V}{count(t') + k}} = \\frac{count(t) + k}{k|V| + \\sum_{t' \\in V}{count(t')}} $$\n",
        "\n",
        "This means that a token with a count of zero (e.g. any novel token) still has a non-zero value as the $k$ raises it up a little.\n",
        "\n",
        "**Exercise:** Write a function `unigram_token_prob_ksmooth` that implements Add-K smoothing for the unigram model. Refer to your `unigram_token_prob` function as it will be a modification of that."
      ],
      "metadata": {
        "id": "DyAk8vYEK0il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unigram_token_prob_ksmooth(next_token, unigram_counts, unigram_N, k):\n",
        "  # your code!\n",
        "    \"\"\"\n",
        "    next_token: token whose probability we want\n",
        "    unigram_counts: dict or Counter of unigram counts\n",
        "    unigram_N: total number of tokens in the corpus (sum of counts)\n",
        "    k: smoothing parameter\n",
        "\n",
        "    returns: smoothed unigram probability\n",
        "    \"\"\"\n",
        "    vocab_size = len(unigram_counts)\n",
        "    token_count = unigram_counts.get(next_token, 0)\n",
        "\n",
        "    return (token_count + k) / (unigram_N + k * vocab_size)\n",
        "\n",
        "unigram_token_prob_ksmooth('abracadabra', posts_unigram_counts, posts_unigram_N, 0.1)"
      ],
      "metadata": {
        "id": "LREfSI8ELyHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3868521c-246a-41be-ed93-6fe5b882ee53"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.245032167782285e-07"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labtest(unigram_token_prob_ksmooth)"
      ],
      "metadata": {
        "id": "e3IdeSR4OulG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f50a2c5-cb3e-4aa7-a522-e3af10b86f39"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('cup', {'cup': 2, 'spoon': 2, 'glass': 6, 'fork': 1}, 11, 0.1). Running... \n",
            "Output: 0.18421\n",
            "OK.\n",
            "\n",
            "Input: ('plate', {'plate': 2, 'cup': 2, 'fork': 5, 'spoon': 5}, 14, 0.1). Running... \n",
            "Output: 0.14583\n",
            "OK.\n",
            "\n",
            "Input: ('fork', {'bowl': 4, 'fork': 5, 'plate': 3, 'cup': 1}, 13, 0.1). Running... \n",
            "Output: 0.3806\n",
            "OK.\n",
            "\n",
            "Input: ('cup', {'plate': 2, 'glass': 3, 'fork': 1, 'cup': 1}, 7, 0.1). Running... \n",
            "Output: 0.14865\n",
            "OK.\n",
            "\n",
            "Input: ('glass', {'glass': 5, 'spoon': 3}, 8, 0.1). Running... \n",
            "Output: 0.62195\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIuLPUSIEyJa"
      },
      "source": [
        "### Splitting into training and test data\n",
        "\n",
        "We want to see how good our language model is modelling the language. We'll work with the Add-K smoothed unigram model.\n",
        "\n",
        "We'll split the data into two parts: train and test. We train our model (using counts) on the training sample of posts. This means that we fixed (or *fit* in sci-kit learn terminology) our vocabulary based on the words in *training* set.  We then evaluate on how well it can predict the new unseen test posts.  \n",
        "\n",
        "Let's first shuffle and split our posts into training and testing posts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcb0HYwKFQ9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac55c87-f5fe-4f83-a3fb-902119384ae8"
      },
      "source": [
        "random.seed(42)\n",
        "shuffled_posts = random.sample(posts, k=len(posts))\n",
        "\n",
        "# Split the data into 80% train, 20% test posts.\n",
        "train_frac = 0.8\n",
        "split_idx = int(train_frac * len(shuffled_posts))\n",
        "train_posts = shuffled_posts[:split_idx]\n",
        "test_posts = shuffled_posts[split_idx:]\n",
        "\n",
        "print (\"Training set size:\", len(train_posts))\n",
        "print (\"Test set size:\", len(test_posts))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1600\n",
            "Test set size: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we'll make the same flattened lists for the training and testing sets. We'll add `<START>` and `<END>` tokens to mark the start and end of posts."
      ],
      "metadata": {
        "id": "YNo0vNASPH7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_flattened_tokens = []\n",
        "for post in train_posts:\n",
        "  train_flattened_tokens += ['<START>'] + post['tokens'] + ['<END>']\n",
        "len(train_flattened_tokens)"
      ],
      "metadata": {
        "id": "p28M-hLMwR-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ce6dc3-4c01-426a-8d64-0b0387920f21"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "153987"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_flattened_tokens = []\n",
        "for post in test_posts:\n",
        "  test_flattened_tokens += ['<START>'] + post['tokens'] + ['<END>']\n",
        "len(test_flattened_tokens)"
      ],
      "metadata": {
        "id": "WhAvbCzq3G18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07df4289-2001-4837-d74e-2e0cdebab3b6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37441"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we'll calculate the unigram counts **for the training data** so that we can use our Add-K smoothed unigram model. Now recall, that without the smoothing, any new token in the test data with a probability of zero would cause the whole sequence to have a probability of zero."
      ],
      "metadata": {
        "id": "IRoCs64DPPev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_unigram_counts = Counter(train_flattened_tokens)\n",
        "train_unigram_N = len(train_flattened_tokens)"
      ],
      "metadata": {
        "id": "1RjwEQCM3OTX"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save you some time, here's an implementation of a function that calculates the log transformed probability of a sequence (similar to a method earlier in this lab) that uses our smoothed unigram model:"
      ],
      "metadata": {
        "id": "-mkVSrNcauh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def unigram_sequence_logprob_ksmooth(sequence, unigram_counts, unigram_N, k):\n",
        "  logprob = 0\n",
        "  for t in sequence:\n",
        "    logprob += math.log2(unigram_token_prob_ksmooth(t, unigram_counts, unigram_N, k))\n",
        "\n",
        "  return logprob\n",
        "\n",
        "unigram_sequence_logprob_ksmooth(['i', 'like', 'irn', 'moo'], posts_unigram_counts, posts_unigram_N, 0.1)"
      ],
      "metadata": {
        "id": "cnJvk7ktP50y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0abaa7c-9d2a-4103-ba24-b835ee853368"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-47.312934943431344"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJIm9npFP8FN"
      },
      "source": [
        "### Cross-Entropy Loss and Perplexity\n",
        "\n",
        "Now we can calculate the probability of our training data and our test data using a unigram model \"trained\" using the training data.\n",
        "\n",
        "We'll score our model using perplexity. Perplexity measures how \"surprised\" the model was (on average) when it came across a new token in the corpus. A model that has done a good job modelling a language dataset shouldn't be very surprised, so should have lower perplexity.\n",
        "\n",
        "As mentioned in lecture, we take $ 2^H $ (exponentiate it) to get the perplexity score, where $H$ is the cross-entropy. How do we get this?\n",
        "\n",
        "Running the `unigram_sequence_logprob_ksmooth` function computes the log-likelihood of our data:\n",
        "\n",
        "$$ Log P(w_1, ... w_N) = \\sum_{i=1}^N \\log_2 \\hat{p}(w_i) $$\n",
        "\n",
        "Which is very close to the cross-entropy loss:\n",
        "$$ \\text{H}_{\\text{total}}(y, \\hat{y}) = -1 \\sum_{i=1}^N \\frac{1}{N} \\log_2 \\hat{p}(w_i) $$\n",
        "\n",
        "The cross-entropy is equal to $-1$ times the log-likelihood of the data under our model, averaged by the total number of instances (tokens).\n",
        "\n",
        "Let's run it for the training data first.  We compute the probability of the whole collection as a sequence using our model.\n",
        "\n",
        "We've arbitrarily chosen $k = 0.1$ for the smoothing parameter. You could try different values and see how it changes the perplexity."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0.1\n",
        "train_logprob = unigram_sequence_logprob_ksmooth(train_flattened_tokens, train_unigram_counts, train_unigram_N, k)\n",
        "\n",
        "train_cross_entropy_loss = -train_logprob / len(train_flattened_tokens)\n",
        "\n",
        "train_perplexity = 2**train_cross_entropy_loss\n",
        "\n",
        "print(f\"Train Cross-entropy Loss:\\t{train_cross_entropy_loss:.4f}\")\n",
        "print(f\"Train Perplexity:\\t{train_perplexity:.4f}\")"
      ],
      "metadata": {
        "id": "tBH_ZOanwrku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed242c0-cfba-4678-b6e1-3d04f433e0c8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Cross-entropy Loss:\t9.6211\n",
            "Train Perplexity:\t787.5012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we can calculate the cross entropy loss and perplexity for the test set. Note that we still use the unigram counts from the training set as that's the data that the model has been \"trained\" on."
      ],
      "metadata": {
        "id": "Wj5bn5TCUOqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0.1\n",
        "test_logprob = unigram_sequence_logprob_ksmooth(test_flattened_tokens, train_unigram_counts, train_unigram_N, k)\n",
        "\n",
        "test_cross_entropy_loss = -test_logprob / len(test_flattened_tokens)\n",
        "\n",
        "test_perplexity = 2**test_cross_entropy_loss\n",
        "\n",
        "print(f\"Test Cross-entropy Loss:\\t{test_cross_entropy_loss:.4f}\")\n",
        "print(f\"Test Perplexity:\\t{test_perplexity:.4f}\")"
      ],
      "metadata": {
        "id": "cEQZtj-yRojJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fc53da-7a69-4005-d8e4-06bcc2e18308"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Cross-entropy Loss:\t9.9392\n",
            "Test Perplexity:\t981.7333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cross entropy loss and perplexity should be higher for the test set compared to the training set. This makes sense as the model should have learned patterns about words from the training set that apply to the test set (but marginally not as well)."
      ],
      "metadata": {
        "id": "QYdlHWc7Uk8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The perplexity is definitely high for our unigram model. It is constantly surprised by each token (because it's not taking context into account).\n",
        "\n",
        "Would you expect a bi-gram or a tri-gram model to have a higher or lower cross-entropy loss (& perplexity) than the unigram model?"
      ],
      "metadata": {
        "id": "XE3lWADmU3yr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93XMGHE-dCib"
      },
      "source": [
        "## End\n",
        "\n",
        "This is the end of Lab 3. Let us know if you encounter any issues! Remember we are here to help!\n",
        "\n",
        "In this lab, you...\n",
        "- built a unigram language model\n",
        "- applied it to a spelling correction problem\n",
        "- extended to n-gram language models\n",
        "- used a language model for text generation\n",
        "- examined evaluation methods for language models\n",
        "- learned to deal with the novel token problem with smoothing\n",
        "\n",
        "**Please submit your lab through Moodle. We don't mark the labs but it helps us to craft better labs in the future**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0ZpeD5vd_hc"
      },
      "source": [
        "## Optional Extras\n",
        "\n",
        "- Read about how shopping service Etsy uses language models in [spelling correction in search](https://codeascraft.com/2017/05/01/modeling-spelling-correction-for-search-at-etsy/).\n",
        "- Read more about training cool language systems directly from text data in [Chapter 14](http://norvig.com/ngrams/ch14.pdf) of Peter Norvig's [Natural Language Corpus Data: Beautiful Data](http://norvig.com/ngrams/).\n",
        "- Write a Trigram model for the spelling corrector\n",
        "- Make `sample_from_distribution` more efficient\n",
        "- Calculate perplexity for a bigram or trigram model with Add-K smoothing"
      ]
    }
  ]
}